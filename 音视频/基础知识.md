### 资料与博客
```
https://avdancedu.com/page/2/
```

### 音视频开发
```
音视频开发，就是要掌握图像、音频、视频的基础知识，并且学会如何对它们进行采集、渲染、处理、传输等一系列的开发和应用

具体的技术内容如下
采集：它解决的是，数据从哪里来的问题
渲染：它解决的是，数据怎么展现的问题
处理：它解决的是，数据怎么加工的问题
传输：它解决的是，数据怎么共享的问题
```

### 名词解释
```
IPC（网络摄像机）

DVS（视频编码器）

NVR（Network Video Recorder）又叫网络视频录像机，是一类视频录像设备，与网络摄像机或视频编码器配套使用，实现对通过网络传送过来的数字视频的记录。

DVR的英文全称是（Digital Video Recorder），即数字视频录像机，相对于传统的模拟视频录像机，采用硬盘录像，故常常被称为硬盘录像机

CVR的英文全称是（Central Video Recorder），即中心级视频网络存储设备，它是由标准的IPSAN/NAS网络存储设备，结合视频监控应用发展而来，近年来市场需求日渐强烈。

帧率：FPS（frame per second 每秒钟要多少帧画面）
采样率：每秒从连续信号中提取并组成离散信号的采样个数，它用赫兹（Hz）来表示。比如mpeg的pts、dts都是以90kHz来采样的，所以采样间隔就是1/900000秒
码率(比特率)：编码器每秒编出的数据大小，单位是kbps
    音频：CD音质，一般2通道，原始音频数据1秒钟的数据量是44.1k（采样率）*16（位深度）*2（声道数）=1411.2kbits，可求得整个音频文件的大小=时长（300s）*码率(1411.2)/1024/8=51.67M。压缩成128kbps的MP3，1秒钟数据就变成了128kbits了
    视频：图像原始的格式是RGB888，一秒钟的数据量就是30（帧率）*8（采样精度）*3（通道数）*1920*1080（1080P分辨率）= 1,492,992kbits。同样视频也存在压缩算法，如H.264，压缩完1秒钟的数据就叫码率。假设H.264压缩1080p的视频，码率是10Mbps，就是说1秒中的数据量为10*1024*1024= 10,485,760 bits。压缩比=压缩前的码率/压缩后的码率

DTS（Decoding Time Stamp）解码的时间
PTS（Presentation Time Stamp）显示的时间
```

### 码率控制
```
QP(量化参数) 控制着压缩大小。QP越大压缩率越高同时质量越低，QP越小压缩率越低同时质量越高

// 码率控制
CBR(固定码率) 
    恒定比特率
    由于码率恒定，只能通过增大QP来减少数据流量，图像质量变差，当场景静止时，图像质量又变好，因此图像质量不稳定
    优先考虑码率(带宽)
VBR(可变码率)
    动态比特率，其码率可以随着图像的复杂程度的不同而变化
    编码器在难编码的地方花费更多比特，在编码简单的地方花费更少比特
    优先考虑图像质量
AVBR()
FIXQP(固定Qp值)
```

### 视频流
```
经过压缩算法压缩的流数据，称为编码流，又因为目前压缩/编码算法以H264为主，因此也常常称为H264码流

未经压缩的流数据，是解码后的流数据，称为原始流，也常常称为YUV流
```

### HVS
```
// 人类视觉系统HVS特点
对高频信息不敏感
对高对比度更敏感
对亮度信息比色度信息更敏感
对运动的信息更敏感

// 针对HVS的特点，数字视频系统的设计应该考虑哪些因素？
丢弃高频信息，只编码低频信息
提高边缘信息的主观质量
降低色度的解析度
对感兴趣区域（Region of Interesting，ROI）进行特殊处理
```

### RGB YUV
```
// RGB色彩空间
三原色分别是红（R），绿（G），蓝（B）。任何颜色都可以通过按一定比例混合三原色产生
广泛用于BMP，TIFF，PPM等，每个色度成分通常用8bit表示[0,255]

// YUV色彩空间
YUV色彩空间是指，Y：亮度分量，UV：两个色度分量
YUV能更好的反映HVS特点

主流的编解码标准的压缩对象都是YUV图像

// YUV图像分量采样
Y表示明亮度，U和V则是色度
YUV图像可以根据HVS的特点，对色度进行分量采样，可以降低视频数据量
根据亮度和色度分量的采样比率，YUV图像通常有以下几种分量方式
YUV 4:4:4采样，每一个Y对应一组UV分量
YUV 4:2:2采样，每两个Y共用一组UV分量 
YUV 4:2:0采样，每四个Y共用一组UV分量 

// 常见的YUV格式
YUV420 NV12 NV21 i420 YV12

```

### RGB YUV 的转化
![YUV -> RGB](../../study/picture/v2-5cadb349c867fb8c1fcdebc2081bdcea_r.jpg)
![RGB -> YUV](../../study/picture/v2-7cb7c3b35a16cf92039f455e3eb88582_r.jpg)

### 视频编码-帧
```
帧是组成视频的基本单位
帧率是一秒播放的视频中有多少个帧
视频文件本身是由很多连续的帧图片组成，但是一帧数据不一定保存的是一个完成图片

编码器将多张图像进行编码后生产成一段一段的 GOP(Group of Pictures)

解码器在播放时则是读取一段一段的 GOP 进行解码后读取画面再渲染显示

// GOP(Group of Pictures)
GOP是一组连续的画面，由一张 I 帧和数张 B / P 帧组成，是视频图像编码器和解码器存取的基本单位
I 帧是内部编码帧(也称为关键帧)
P 帧是前向预测帧，B帧是双向内插帧
简单地讲，I 帧是一个完整的画面，而 P 帧和 B 帧记录的是相对于 I 帧的变化

I B B P B B P B B I B B P B B P B B I B B P B B P B B 

// I帧
I帧又称帧内编码帧，是一种自带全部信息的独立帧，无需参考其他图像便可独立进行解码，可以简单理解为一张静态画面
视频序列中的第一个帧始终都是I帧，因为它是关键帧

// P帧
P帧需要参考前面的I帧或P帧才能进行编码。表示的是当前帧画面与前一帧(前一帧可能是I帧也可能是P帧)的差别
解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面
与I帧相比，P帧通常占用更少的数据位，但不足是，由于P帧对前面的P和I参考帧有着复杂的依耐性，因此对传输错误非常敏感
I <- P <- P <- P <- P <- P  I
          ↑
        丢失           
            后面的P解码都会失败
            
// B帧
B帧又称双向预测编码帧，也就是B帧记录的是本帧与前后帧的差别
要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面
B帧压缩率高，但是对解码性能要求较高

P依赖于I或P，B依赖于I和P

B帧越多，视频越小，反之越大
B帧多的视频：抖音、苍老师视频
B帧少的视频：直播、实时监控

时间顺序: I B B P 
编码顺序: I P B B 

```

### 采集
```
// 系统的摄像头采集接口是什么
Windows：DirectShow
Linux：V4L2
Android：Camera
iOS：AVCaptureSession

// 系统的摄像头采集的参数怎么配置
比如：分辨率、帧率、预览方向、对焦、闪光灯 等

// 系统的摄像头输出的图像/视频数据，是什么格式
比如：图片：JPEG，视频数据：NV21，NV12，I420 等

// 系统的麦克风采集接口是什么
Windows：DirectShow
Linux：ALSA & OSS
Android：AudioRecord
iOS：Audio Unit

// 系统的麦克风采集参数怎么配置
比如：采样率，通道号，位宽 等

// 系统的麦克风输出的音频数据，是什么格式
比如：PCM
```

### 渲染
```
// 系统提供了哪些 API 可以绘制一张图片或者一帧 YUV 图像数据的
Windows：DirectDraw, Direct3D, GDI，OpenGL 等
Linux： GDI， OpenGL 等
Android：ImageView，SurfaceView，TextureView，OpenGL 等
iOS： CoreGraphics，OpenGL 等

// 系统提供了哪些 API 可以播放一个 mp3 或者 pcm 数据
Windows：DirectSound 等
Linux：ALSA & OSS 等
Android：AudioTrack 等
iOS： AudioQueue 等
```

### jpeg
```
https://www.cnblogs.com/Arvin-JIN/p/9133745.html
```

### H.264 结构
```
// 功能分两层
VCL (VideoCoding Layer，视频编码层)：负责高效的视频内容表示
NAL(NetworkAbstraction Layer，网络提取层)：负责以网络所要求的恰当的方式对数据进行打包和传送



https://juejin.cn/post/6860027904743604232 [推荐]
https://zhuanlan.zhihu.com/p/71928833
https://www.codenong.com/cs106197881/
https://www.jianshu.com/p/6fe07c318222
https://www.yuque.com/keith-an9fr/aab7xp/vng2pb

```

### NALU
```
NALU为压缩视频数据的基本单位，也是后续视频传输的基本单位
它由一组对应于视频编码数据的 NALU头信息和一个原始字节序列载荷（RBSP）组成
压缩视频比特流由一个个连续排列的NALU组成
```

### NALU startcode
```
// 用途
将相邻两个NALU划分开

// 两种形式(h264 标准 Annex B)
3字节的0x000001和4字节的0x00000001

// 防止竞争码
由于 startcode 0x000001的存在，导致如果 NALU 中如果也存在这些个字节会导致 NALU 分割错误
在它的前面插入一个新的字节0x03，0x000001将变成0x00000301

// 区别
包含sps,pps的NALU前面要加zero_byte（4字节）
当一帧被分为多个slice时，首个NALU前面要加4字节startcode，剩下的slice加3字节startcode

SPS(序列参数集) PPS(图像参数集)

SPS （4字节）
PPS （4字节）
SEI （4字节）
I0(slice0) （4字节）
I0(slice1) （3字节）
P1(slice0) （4字节）
P1(slice1) （3字节）
P2(slice0) （4字节）
P2(slice1) （3字节）

I0(slice0)是序列第一帧（I帧）的第一个slice，是当前Access Unit的首个nalu，所以是4字节头
I0(slice1)表示第一帧的第二个slice，所以是3字节头
```

### RAW data
```
RAW图像就是CMOS或者CCD图像感应器（sensor）将捕捉到的光源信号转化为数字信号的原始数据
```

### H.264
```
H.264 将构成一帧图像所有NALU的集合称为一个AU(Access Unit)

一个NALU即使是VCL NALU 也并不一定表示一个视频帧。因为一个帧的数据可能比较多，可以分片为多个NALU来储存。一个或者多个NALU组成一个访问单元AU，一个AU包含一个完整的帧

H264 编码结构 -> FLV 格式封装 -> RTMP 流格式分析

// H264码流结构，从大到小
H264视频序列、一帧图像、片组、片、NALU、宏块、像素



// 流的种类
Annex-B 格式是默认的输出格式。数据单元(NALU单元)的分割使用0x000001或0x00000001 作为起始码
RTP     使用长度+单元+长度+单元的方式，RTMP 协议(flv)采用的此方式

H264可以分为2层：视频编码层 VCL 和网络提取层 NAL

VCL层
    压缩: 预测（帧内预测和帧间预测）-> DCT变化和量化 -> 比特流编码
    切分数据: 切片(slice), 宏块(macroblock)等
    包装成NAL

    一帧个图像分成多个片(slice)，每个片由多个宏(macro)块组成，一个宏块由多个子块组成，一个子块是由多个像素组成(比如4x4，16x16，64x64)

    一帧图片经过 H.264 编码器之后，就被编码为一个或多个片(slice)，而装载着这些片(slice)的载体，就是 NALU

NAL -> slice -> 片头 + 片数据 -> 宏块 + 宏块 + 宏块...


NAL层
NALU
    NALU 由 head、body 组成
    head: 标志信息，譬如NALU的类型
    body: 存储了真正的数据
NALU Header
    占1个字节
    forbidden_zero_bit: 1 bit，禁止位，网络传输中发生错误会被置为1，告诉接收方丢掉该单元；否则为0
    nal_ref_idc: 2 bit，指示当前NALU的优先级，数值越大表明越重要
    nal_unit_type: 5 bit，表示NALU的类型


一帧图像就是一个Access unit

图像解码过程是按照slice进行解码，然后按照片组将解码宏块重组成图像
ffmpeg只需要将一个个的 NALU(header+EBSP)传入解码器即可

https://www.zybuluo.com/ltlovezh/note/1679860

3字节的0x000001只有⼀种场合下使⽤，就是⼀个完整的帧被编为多个slice（⽚）的时 候，包含这些slice的NALU 使⽤3字节起始码。其余场合都是4字节0x00000001的

参考帧数目
    在做视频解码时，需要将最近的若干幅参考帧缓存起来
    有效范围值1~16。该值越大，表明了压缩率越高，但但大于6后对压缩率的贡献很低
    H.264/H.265解码所需帧存个数为 参考帧 + 显示帧 + 1

```

### YUV存放格式
```
Packed      将 YUV 分量存放在同一个数组中, 通常是几个相邻的像素组成一个宏像素(macro-pixel)
Plannar     使用三个数组分开存放 YUV 三个分量
Semi-Planar 使用两个数组存放，Y存放一个，U、V是交叉存放另一个

// YUV420 示例
(1) packed
    每2X2的Y分量公用一个UV分量，并且将YUV打包到一个平面。存储在一个数组中
    Y1  U1 Y2  Y3  U2 Y4
    Y5  V1 Y6  Y7  V2 Y8
    Y9  U3 Y10 Y11 U4 Y12
    Y13 V3 Y14 Y15 V4 Y16

(2) Planner
    每2X2像素共用一个UV空间，Y分量后面根U分量，然后是V分量。存储在三个数组里
    Y1 Y2 Y3 Y4 Y5 Y6 Y7 Y8 Y9 Y10 Y11 Y12 Y13 Y14 Y15 Y16
    U1 U2 U3 U4
    V1 V2 V3 V4

(2) Semi-Planner
    每2X2像素共用一个UV空间，UV分量交错存放。存储在两个数组里
    Y1 Y2 Y3 Y4 Y5 Y6 Y7 Y8 Y9 Y10 Y11 Y12 Y13 Y14 Y15 Y16
    U1 V1 U2 V2 U3 V3 U4 V4
```

### 3A
```
AEC 回声抵消
ANR 语音降噪
AGC 自动增益控制
```

### 音视频QOS
```
网络传播的抖动，需要上行/下行端做出动态调整，分为音视频传输层Qos和音视频编码层Qos
```