
### 异步与非阻塞
```
1、讨论同步、异步、阻塞、非阻塞时，必须先明确是在哪个层次进行讨论
2、讨论究竟是异步还是同步，一定要严格说明说的是哪一部分
3、从Linux接口的角度说，处理IO的阻塞和非阻塞都是同步。libaio那些才是异步。真正异步接口一般是你提供一个缓冲区给接口，然后接口立即返回，在一段时间之后通过另一种机制(回调，消息，信号等)通知你完成，在通知完成之前缓冲区你不能碰，系统在读写
4、对unix来讲：阻塞式I/O(默认)，非阻塞式I/O(nonblock)，I/O复用(select/poll/epoll)都属于同步I/O，因为它们在数据由内核空间复制回进程缓冲区时都是阻塞的(不能干别的事)。只有异步I/O模型(linux的libaio)是符合异步I/O操作的含义的，即在1数据准备完成、2由内核空间拷贝回缓冲区后 通知进程，在等待通知的这段时间里可以干别的事。
5、阻塞与非阻塞
	进程/线程要访问的数据是否就绪，进程/线程是否需要等待
   同步与异步
   	访问数据的方式，同步需要主动读写数据，在读写数据的过程中还是会阻塞；异步只需要I/O操作完成的通知，并不主动读写数据，由操作系统内核完成数据的读写
6、[UNIX网络编程：卷一] 对unix的io讲得明明白白
7、说白了，同步需要从内核空间拷贝到用户空间，异步是内核帮你把数据拷贝到用户空间，所以异步需要底层api的支持。而阻塞和非阻塞是指进程访问的数据是否准备就绪，没有就绪则等待
8、异步有异步io和异步操作，异步io如第7条所述，而异步操作就多了，多线程、协程。。。，所以要根据软件的设计

```

### 异步的进化
```
1、远古时代
	回调函数
2、promise时代
	promise().then().then()
3、Generator生成器
	实现代码生成器，实现switch()类型的协程，异步(但不是真正异步)
    co(function *(){
        let db, collection, result; 
        let person = {name: "yika"};
        try{
            db = yield mongoDb.open();
            collection = yield db.collection("users");
            result = yield collection.insert(person);
        }catch(e){
            console.error(e.message);
        }
        console.log(result);
    });

4、async/await时代
	真正的协程，实现异步最优雅的方式，用同步的方式写异步！
    async function insertData(person){
        let db, collection, result; 
        try{
            db = await mongoDb.open();   //切出该协程，
            collection = await db.collection("users");
            result = await collection.insert(person);
        }catch(e){
            console.error(e.message);
        }
        console.log(result);
    } 

```

### 协程的相关
```
https://www.zhihu.com/question/65647171/answer/233495694
https://zhuanlan.zhihu.com/p/25964339

//对称与非对称
对称类似于生产者、消费者之间协程的切换，并不涉及栈空间的销毁
非对称类似于函数的调用

//有栈与无栈
有栈：比如ucontext中的，协程有自己的栈空间，协程的切换涉及寄存器的保存和栈内数据的恢复问题，所以性能一般
无栈：用this来索引对象的成员变量，上下文就是对象自己。访问上下文数据也就是成员变量的时候，我们无需显式的使用this+成员偏移量（或者变量名）来访问，而是直接访问变量名。
两种协程访问的上下文中的数据，生命周期都大于函数的返回：栈的生命周期晚于函数的返回，this对象的生命周期晚于函数的返回。后者更晚而且往往需要手工销毁。

//hook
协程的意义就是阻塞异步，所以一些io函数必须设计为，非阻塞异步

//switch语法糖的实现协程
注意：此种实现不能用于try catch、递归循环

#define BEGIN_CORO void operator()() { \
	switch(next_line) { \
		case 0:	

#define YIELD next_line=__LINE__; break; case __LINE__:

#define END_CORO }} int next_line=0

struct coroutine{
    int n_;
    coroutine(int n__):n_(n__){}
    void operator () (){
        case 0:
            cout << n_++ << end;
            next_line = __LINE__ + 2;
            break;
        case __LINE__:
            cout << n_++ << end;
            next_line = __LINE__ + 2;
            break;
        case __LINE__:
            cout << n_++ << end;
            next_line = __LINE__ + 2;
            break;
        case         
            next_line = 0;
    }
    int next_line;
}
    

async/await的出现，实现了基于stackless coroutine的完整coroutine
在特性上已经非常接近stackful coroutine了，不但可以嵌套使用也可以支持try catch。所以是不是可以认为async/await是一个更好的方案？

```

### c++异步编程
```
c++11的promise、async、future属于多线程异步，所以单线程异步只能用协程和异步callback
异步是协程的一种实现方式，协程是异步的封装方法
1、promise、async的多线程异步回调（异步工作流）
2、协程（更优雅）
```

### c++高性能网络库 
```
libevent、libev、boost::asio
```

### c++ asio
```
推荐boost::asio
c++20标准库网络部份将基于asio，c++ asio异步编程很重要
```

### c++协程相关库
```
云风的coroutine库
libgo
boost::asio
```

### 无栈协程相关库
```
c++20的coroutine(基于asio)
知乎朱元的库
Es6的async/wait模型
boost::asio
```

### 高性能服务器程序框架
```
https://blog.csdn.net/enlyhua/article/details/81024206

服务器程序通常要处理三类事情：IO事件，信号，以及定时事件

(1) 服务器模型
	1) C/S 模型
	2) P2P 模型
 
(2) 服务器编程框架
	1) IO处理单元 : 
		> 处理用户连接，读写网络数据(单机)
		> 作为接入服务器，实现负载均衡(集群)
	2) 请求队列
		> 各个单元之间通信的抽象，通常被实现为池的一部分；
		> 一个单元通知另外一个单元，或者多个单元访问同一个存储单元时，竞争的协调；
		> 对于集群来说，请求队列是预先建立的
	3) 逻辑单元
		> 一个进程或者线程(单机)
		> 一台逻辑服务器(集群)
	4) 网络存储单元
		> 数据库，文件，缓存(单机)
		> 数据库服务器(集群)
 
(3) I/O 模型
	1) 阻塞IO
	2) 非阻塞IO
	3) IO复用(IO通知机制)
		> select, poll, epoll_wait
		> 应用程序通过IO复用函数向内核注册一组事件，内核通过IO复用函数把其中准备就绪的事件通知给应用程序
		> IO复用本身是阻塞的，高效的原因是它同时监听多个IO事件的能力
	4) SIGIO 
		可以用来报告IO事件, 将一个目标文件描述符指定为宿主进程，被指定的进程将捕获到SIGIO事件，这样就可以在信号处理函数中对目标文件描述符执行非阻塞IO操作了
	5) 异步IO
		libaio
	6) 注意	
		理论上说，阻塞IO、IO复用、信号驱动IO都是同步IO模型。因为这3种IO模型，IO的读写，都在IO事件发生以后，由应用程序自己完成
		对异步IO而言，用户可以直接对IO执行读写操作，这些操作告诉内核用户读写缓冲区的位置，以及IO完成后内核通知应用程序的方式，总是立即返回，真正的读写已经由内核接管。
		同步IO模型要求用户自行执行IO操作，异步IO则由内核来执行IO操作
		同步IO向应用程序通知的是IO就绪事件，异步IO向应用程序通知的是IO完成事件
 
(4) 两种高效的事件处理模式
	1) Reactor(同步IO模型)
		要求主线程只负责监听文件描述符上是否有事件发生，有的话通知工作线程读写数据，接受新的连接，以及处理客户请求均在工作线程中完成
		> 主线程往epoll内核事件注册socket上的'读就绪事件'
		> 主线程调用epoll_wait等待socket上有数据可读
		> 当socket上有数据可读时，epoll_wait通知主线程，主线程将socket可读线程事件放入请求队列
		> 睡眠在请求队列上的某个工作线程被唤醒，然后工作线程从socket上读取数据，并处理客户请求，然后往epoll内核事件表中注册该socket上的写就绪事件
		> 主线程调用epoll_wait等待socket可写
		> 当socket可写时，epoll_wait通知主线程，主线程将socket可写事件放入请求队列
		> 睡眠在请求队列上的某个工作线程被唤醒，它往socket上写入服务器处理客户端请求的结果

	2) Proactor(异步IO模型)
		与Reactor模式不同，Proactor模式将所有的IO操作都交给'主线程和内核来处理'，'工作线程'仅仅负责业务逻辑
		> 主线程调用aio_read函数向内核注册socket上的'读完成事件'，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序
		> 主线程继续处理其他逻辑
		> 当socket上的数据被读入用户缓冲区后，内核向应用程序发送一个信号，以通知应用程序数据已经可用
		> 应用程序预先定义好的信号处理函数选择一个工作线程来处理客户的请求
		> 工作线程处理完客户请求后，调用aio_write函数向内核注册socket上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操作完成
		时如何通知应用程序
		> 主线程继续处理其他逻辑
		> 当用户缓冲区的数据被写入socket之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕。
		> 应用程序预先设定好的信号处理函数选择一个工作线程来善后处理，比如决定是否关闭socket 
 
	3) 同步IO模拟Proactor
		原理：主线程执行数据读写操作，读写完成后，主线程向工作线程通知这一"完成事件"。那么从工作线程的角度来看，它们就直接获得了数据读写的结果，接下来要做的就是对读写的结果进行逻辑操作。
		> 主线程往epoll内核事件表中注册socket上的读就绪事件
		> 主线程调用epoll_wait等待socket上有数据可读
		> 当socket上有数据可读时，epoll_wait通知主线程。主线程从socket循环读取数据，直到没有更多数据可读
		> 然后将读到的数据封装成一个请求对象并插入请求队列
		> 睡眠在请求队列上的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件
		> 主线程调用epoll_wait等待socket可写
		> 当socket可写时，epoll_wait通知主线程，主线程往socket上写入服务器处理客户请求的结果

(5) 两种高效的并发模式
	
	1) 半同步/半异步
		> IO编程的"同步"和"异步"
			在IO编程中，区分的是内核向应用程序通知的是何种IO事件(是就绪事件还是完成事件)，以及谁来完成IO读写(是应用程序还是内核)
		> 并发编程的"同步"和"异步"
			在并发模式中，"同步"指的是程序完全按照代码序列的顺序执行，"异步"指的是程序的执行需要由系统事件来驱动，常见的系统事件包括中断，信号等
			同步运行的线程叫同步线程，异步方式运行的线程叫异步线程
		> 半同步/半异步模式(类似Proactor)
			同时采用同步线程和异步线程来实现
			这当中，同步用来实现客户逻辑，异步线程用来处理IO事件。异步线程监听到客户请求后，就将其封装成请求对象并插入请求队列。请求队列将通知某个工作在同步模式的工作线程来读取并处理该请求对象
			// 例如
			从fd读取数据、处理，然后写入fd，响应客户端

			工作线程 <---+
			工作线程 <---|		
			工作线程 <---|
						|	+-----------------------------------+
						+---| buf | buf | buf | buf | buf | buf |
							+-----------------------------------+
									↑   ↑   ↑    ↑    ↑   ↑
									+----------+----------+
											   |	
											异步IO
											   ↑	
											accept
											   ↑
											socket
									   ↑      ↑      ↑      ↑	
									client client client client

 		> 半同步/半反应堆模式(类似Reactor)
		 	半同步/半异步模式的变种
			异步线程只有一个，由主线程来充当。它负责监听所有socket的事件
			> 如果监听socket上有可读事件发生，即有新的连接到来，主线程就接受之以得到新的连接socket,然后往epoll内核事件表中注册该socket上的读写事件
			> 如果连接socket上有读写事件发生，即有新的客户请求到来或者有数据要发送至客户端，主线程就将该连接socket插入请求队列中。所有工作线程都睡眠在请求队列中，当有任务到来，它们通过竞争获取任务的接管权。
			> 缺点：
				> 主线程和工作线程共享请求队列
					主线程往请求队列添加任务，或者工作线程从请求队列取出任务，都需要对请求队列加锁保护，从而浪费cpu时间
				> 每个工作线程在同一时间之内处理一个客户请求
					客户数量较多，工作线程较少，则请求队列中将堆积很多任务对象
					如果通过增加工作线程来解决这一问题，则工作线程的切换也将耗费大量cpu时间。

		> 高效的半同步/半反应堆模式：
			在工作线程中也维护自己的事件循环。
 
	2) 领导者/追随者
		领导者和追随者是多个工作线程轮流获得事件源集合，轮流监听，分发并处理事件的一种模式
		> 一个领导者，多个追随者
			在任意时间点，程序仅有一个领导者，它负责监听IO事件
			其他线程都是它的追随者，它们休眠在线程池中等待成为新的领导者
			当期领导者如果检测到IO事件，首先要从线程池中推选出现的领导者线程，然后处理IO事件。此时，新的领导线程等待新的IO事件，而原来的领导者则处理IO事件，二者实现了并发。
 		> 领导者/追随者模式包括的组件(句柄集，线程集，事件处理器和具体的事件处理器)
			> 句柄集
				表示IO资源，使用wait_for_event方法监听这些句柄上的IO事件。
				将其中的就绪事件，通知给领导线程。领导者则调用绑定到Handle上的事件处理器来处理事件
				领导者将Handle和事件处理器绑定是通过调用句柄集中的register_handle 实现的。
 			> 线程集
		  		这个组件是所有工作线程(包括领导线程和追随者线程)的管理者，它负责各个线程之间的同步，以及新领导线程的推选
				线程集中的线程在任一时间必须处于如下三种状态之一：
		  		> Leader
					线程当前处于领导者身份，负责等待句柄集上的IO事件；		
		  		> Processing
					线程正在处理事件
					领导者检测到IO事件后，可以转移到 Processing 状态来处理该事件，并调用promote_new_leader方法推选新的领导者；也可以指定其他追随者来处理事件，此时领导者地位不变。当处于Processing状态的线程处理完事件之后，如果当前线程集中没有领导者，则它将成为新的领导者，否则它就直接转变为追随者。
		  		> Follower
					线程当前处于追随者身份，通过调用线程集的join方法等待成为新的领导者，也可以被当前的领导者指定来处理新任务。
			> 事件处理器和具体的事件处理器：
				事件处理器通常包含一个或多个回调函数handle_event，这些回调函数用于处理事件对应的业务逻辑
				事件处理器在使用前需要被绑定到某个句柄上，当该句柄上有事件发生时，领导者就执行与之绑定的事件处理器中的回调函数
				具体的事件处理器是事件处理器的派生类，它们必须重新实现基类的handle_event方法，以处理特定任务

(6) 有限状态机
	逻辑单元内部的一种高效编程方式
 
(7) 提高服务器性能的其他建议
	1) 池
		资源的分配很耗时，所以在服务器启动之初就完全资源的初始化，可以避免了对内核的频繁访问
		> 内存池
		> 对象池
		> 进程池
		> 线程池
		> 连接池(常用于服务器或服务器集群的内部永久连接)
 
	2) 数据复制
		高性能服务器应该避免不必要的数据复制，尤其是当数据复制发送在用户代码和内核之间的时候
		> 如果内核可以直接处理从socket或者文件读入的数据，则应用程序就没必要将这些数据从内核缓冲区复制到应用程序缓冲区(这里说的"直接处理"指的是应用程序不关心这些数据的内容，不需要对它们做任何分析)
		> 可以使用"零拷贝"sendfile函数
		> 此外，用户代码内部(不访问内核)的数据复制也应该避免。
			例如，当2个工作进程之间要传递大量的数据时，我们就应该考虑使用共享内存来在它们之间直接共享这些数据，而不是使用管道或者消息队列来传递。
 
	3) 上下文切换
		并发程序必须考虑上下文切换的问题，即进程切换或线程切换导致的系统开销
		> IO密集型服务不应该使用过多的工作线程
			线程间的切换将占用大量的cpu时间，服务器真正用于处理业务逻辑的cpu时间的比重就显得不足了，因此，每个客户连接创建一个工作线程的服务器模型是不可取的
 		> 使用Preactor模式
			这一种比较合理的方案，它允许一个线程同时处理多个客户连接
		> 避免过多的线程数量
			多线程服务器的一个优点是不同的线程可以同时运行在不同的cpu上，当线程的数量大于cpu的数目时，上下文切换就比较频繁
 
	4) 锁
		并发程序需要考虑的另外一个问题就是对共享资源的加锁保护
		锁通常被认为是导致服务器效率低下的一个因素。因为由它引入的代码，不仅不处理任何业务逻辑，而且需要访问内核资源
		半同步/半异步模式(Proactor)比半同步/半反应堆的效率高(Reactor)
		如果服务器必须使用锁，可以考虑减小锁的粒度
```

### 可重入与不可重入函数
```
https://www.jianshu.com/p/2c8de98bf0db

1、可重入概念
	可重入函数主要用于多任务环境中，一个可重入的函数简单来说就是可以被中断的函数，可以在这个函数执行的任何时刻中断它，转入OS调度下去执行另外一段代码，而返回控制时不会出现什么错误

	不可重入的函数由于使用了一些系统资源，比如全局变量区，中断向量表等，所以它如果被中断的话，可能会出现问题，这类函数是不能运行在多任务环境下的

2、可重入的条件
	(1) 不能使用静态(全局)非常量数据
	(2) 只能处理由调用者提供的数据
	(3) 函数内调用的函数也必需是可重入的

3、不可重入的函数
	> 函数体内使用了静态的数据结构
	> 函数体内调用了malloc()或者free()函数
	> 函数体内调用了标准I/O函数
```

### 线程池与工作队列
```
https://developer.ibm.com/zh/languages/java/articles/j-jtp0730/

// 使用风险
1、死锁
	普通的死锁，线程A持有对象X的独占锁，并且在等待对象Y的锁，而线程B持有对象Y的独占锁，却在等待对象X的锁。除非有某种方法来打破对锁，否则死锁的线程将永远等下去
	线程池引入了另一种死锁可能，所有池线程都在执行已阻塞的等待队列中另一任务的执行结果的任务，但这一任务却因为没有未被占用的线程而不能运行

2、资源不足
	线程池太大可能严重地影响系统性能，线程之间切换将会浪费时间
	除了线程自身所使用的资源以外，服务请求时所做的工作可能需要其它资源，例如 JDBC 连接、套接字或文件

3、并发错误
	线程池和其它排队机制依靠使用 wait() 和 notify() 方法，这两个方法都难于使用。如果编码不正确，那么可能丢失通知，导致线程保持空闲状态，尽管队列中有工作要处理。使用这些方法时，必须格外小心；即便是专家也可能在它们上面出错。而最好使用现有的、已经知道能工作的实现，例如在下面的 无须编写您自己的池 中讨论的 util.concurrent 包。

4、线程泄漏
	各种类型的线程池中一个严重的风险是线程泄漏，当从池中除去一个线程以执行一项任务，而在任务完成后该线程却没有返回池时，会发生这种情况。发生线程泄漏的一种情形出现在任务抛出一个 RuntimeException 或一个 Error 时。如果池类没有捕捉到它们，那么线程只会退出而线程池的大小将会永久减少一个。当这种情况发生的次数足够多时，线程池最终就为空，而且系统将停止，因为没有可用的线程来处理任务。

	有些任务可能会永远等待某些资源或来自用户的输入，而这些资源又不能保证变得可用，用户可能也已经回家了，诸如此类的任务会永久停止，而这些停止的任务也会引起和线程泄漏同样的问题。如果某个线程被这样一个任务永久地消耗着，那么它实际上就被从池除去了。对于这样的任务，应该要么只给予它们自己的线程，要么只让它们等待有限的时间。

5、请求过载
	仅仅是请求就压垮了服务器，这种情况是可能的。在这种情形下，我们可能不想将每个到来的请求都排队到我们的工作队列，因为排在队列中等待执行的任务可能会消耗太多的系统资源并引起资源缺乏。在这种情形下决定如何做取决于您自己；在某些情况下，您可以简单地抛弃请求，依靠更高级别的协议稍后重试请求，您也可以用一个指出服务器暂时很忙的响应来拒绝请求

// 使用准则
1、避免死锁
	避免一个任务等待另一个任务
	设定等待时间

2、熟悉业务
	CPU限制、I/O限制的不同的任务类，为不同任务类设置多个工作队列

// 线程池大小
1、处理器利用率
	等待时间 WT、服务时间 ST、N*(1+WT/ST)个线程来保持处理器得到充分利用
2、不是调整线程池大小过程中的唯一考虑事项。随着线程池的增长，您可能会碰到调度程序、可用内存方面的限制，或者其它系统资源方面的限制，例如套接字、打开的文件句柄或数据库连接等的数目

```

### go vs nodejs 并发模型
```
go并发模型：CSP

nodejs: reactor


```

### 并发模型 CSP模型和Actor模型
```
[Actor模型和CSP模型的区别] https://www.jdon.com/concurrent/actor-csp.html
```

### 并发模式
```
[go常见并发模式] https://chai2010.gitbooks.io/advanced-go-programming-book/content/ch1-basic/ch1-06-goroutine.html

(1) 生产者消费者模型

(2) 发布订阅模型
```

### linux 零拷贝
```
https://cllc.fun/2020/03/18/linux-zero-copy/

// 拷贝代价
(1) 一次拷贝的数据流向
	read: 从内核空间拷贝到用户空间
	write: 数据从用户空间拷贝到内核空间

(2) 一次拷贝的上下文切换
	调用read读取文件时，从用户态切换到内核态
	读取完成之后，切换回来
	调用write发送数据时，从用户态切换到内核态
	发送完成之后，切换回来

// 当前的零拷贝技术
(1) 直接IO
	O_DIRECT
	使用直接I/O的方式，可以将跨过内核，直接将I/O设备中的数据传递到用户空间中
	数据库用的多

(2) mmap
	通过内存映射的机制，把内核中的部分内存空间映射到用户空间的内存
	有了mmap的支持，数据从文件中读取到内核空间之后，就不会再拷贝到用户空间
	例如fd = socket，当调用socket的write时，数据会直接从内核缓存中直接拷贝到Socket的缓冲区中，避免了在用户空间中多中转一次
	虽然减少一次数据拷贝，但是还是需要4次上下文切换

(3) sendfile
	只需要2次上下文切换
	调用sendfile将文件内容通过socket发送出去时候，从用户态切换到内核态
	任务完成之后，切换回来
```

### 性能杀手
```c++
(1) 临界区
代码临界区 变量临界区
临界区的存在，导致多个线程不能并行，造成性能下降。临界区越大，多个线程出入临界区越频繁，对性能的伤害也就越大

(2) 伪共享
// 在典型的多核架构中，每个CPU都有自己的Cache。如果一个内存中的变量在多个CPU Cache中都有副本，则需要保证变量的Cache的一致性
// 现在大多数的架构实现Cache一致性都是采用MESI协议
// CPU Cache是以缓存线（Cache line）为单位进行读写的。通常来说，一条缓存线的大小为64字小为64字节。换言之，就是访问1字节的数据，系统也会将该字节所在的整条缓存线的数据都搬到缓存中
// 因为CPU Cache具有以Cache line为单位进行读写的性质，所以在多线程编程中，稍有不慎，就会掉入伪共享的陷阱，造成性能恶化
// 例如
int sum1;
int sum2;
void thread1(int v[], int v_count) {sum1 = 0; for (int i = 0; i < v_count; i++) sum1 += v[i];}
void thread2(int v[], int v_count) {sum2 = 0; for (int i = 0; i < v_count; i++) sum2 += v[i];}
sum1 + sum2;
// 代码定义了两个全局变量sum1和sum2，两个线程分别将计算结果放入各自的全局变量中，看起来并行不悖
// 由于这两个全局变量分配的内存紧挨着，cpu很可能将两个变量一起加载到同一条Cache line中
// 尽管线程1所在的CPU并不需要sum2的值，但是由于sum2和sum1在同一条Cache line中，因此sum2的值也随同sum1一并被加载到了thread1所在CPU的Cache中了
// 当thread1修改sum1的值时，尽管并未更新sum2的值，但影响的是整条Cache line，它会将thread2所在CPU对应的Cache line置为Invalidate
// 如果thread2尝试更新sum2，会触发缓存不命中反过来，thread2修改sum2时，也会影响到sum1的缓存命中
// 可以想见，就因为两个值彼此毗邻，落在同一条Cache line中，会导致大量的缓存不命中，从而影响性能

thread1 cache			thread2 cache
+-------------+			+-------------+
| sum1 | sum2 |			| sum1 | sum2 |
+-------------+			+-------------+
	   |					   |	
	   +-----------+-----------+
	   			   |		
memory 		+-------------+
       		| sum1 | sum2 |
       		+-------------+
 
// 如何避免伪共享
// 可利用填充的方式避免
struct sum_t {
	double sum;
	char padding[56];
} _sum[2];
void thread1(int v[], int v_count) {sum1 = 0; for (int i = 0; i < v_count; i++) _sum[0].sum += v[i];}
void thread2(int v[], int v_count) {sum2 = 0; for (int i = 0; i < v_count; i++) _sum[1].sum += v[i];}
_sum[0] + _sum[1];
```