### 现代处理器中的优化技术
```
https://github.com/GHScan/TechNotes/blob/master/2017/Memory_Model.md [Memory Model: 从多处理器到高级语言]

// 几个关键词
    指令周期
        每个指令的执行需要多个步骤(取指、译码、执行、访存、写回)，计算机从取指到指令执行完毕的时间
    CPU周期
        一条指令执行过程被划分为若干阶段，每一阶段(步骤)完成所需时间
        不同的步骤需要的时间不同
    时钟周期
        又称震荡周期，是处理操作的最基本单位
        一个CPU周期是若干时钟周期之和
    

(1) 流水线(Pipeline)
    现代CPU通过流水线的方式允许同时执行多个指令，从而提高功能单元的利用率和系统总吞吐

    指令1  取指  译码  执行  访存  写回
    指令2        取指  译码  执行  访存  写回
    指令3              取指  译码  执行  访存  写回
    指令4                    取指  译码  执行  访存  写回
    指令5                          取指  译码  执行  访存  写回
                               
    IPC(Instructions Per Cycle): CPU每一时钟周期内所执行的指令多少，事实上每条指令实际上需要多个时钟周期才能完成

(2) 分支预测(Dynamic Branch Prediction)
    > 流水线停顿
        带流水线的CPU需要每个时钟发射1条指令，但只有分支指令执行结束后才能确定下条指令是什么，这就导致流水线停顿
    > 分支预测惩罚
        发射分支指令之后，马上预测下条指令的地址并发射
        如果分支指令执行结束后发现预测错误，则撤销之前的操作取正确的指令重新发射，预测失败导致的撤销开销，叫分支预测惩罚

    内建函数__builtin_expect函数用来引导gcc进行条件分支预测，
    #define likely(x)  __builtin_expect(!!(x), 1)
    #define unlikely(x)    __builtin_expect(!!(x), 0)

(3) 动态多发射
    CPU希望能够提高IPC，这就要求每个时钟发射多条指令

(4) 乱序执行(Out-of-Order Excution)
    当前面的指令停顿时(可能是存储器延迟、操作数没有计算出来)，为了提高CPU利用率，CPU会发射后续无关指令，从而乱序执行

(5) 推断执行
    支持动态分支预测和乱序执行的处理器，需要保留一个重排序缓冲区(Reorder Buffer)，用来对乱序执行的指令进行顺序提交(In-Order Commit)。重排序缓冲区为推断失败时的撤销提供了解决方案，只需要清空分支指令后的所有指令即可

(6) 写缓冲区(Writer Buffer/store Buffer)
    CPU在写存储器时，不直接访问存储器或Cache，而是将要写的数据放入一个写缓冲区，然后继续执行后面的指令，这缓解了写存储器导致的停顿
    // 详见[杂项.md store Buffer]

(7) 硬件多线程
    上述的优化策略都旨在改进指令级并行
    另一种提高CPU利用率、掩盖停顿的做法是硬件多线程，又称为超线程(hyper-threading)、同时多线程(simultaneous multi-theading)
```

### 可见性、有序性和原子性
```
可见性是指某个线程修改了某一个共享变量的值，而其他线程是否可以看见该共享变量修改后的值

原子性是指一个线程的操作是不能被其他线程打断，同一时间只有一个线程对一个变量进行操作

为了优化程序执行和提高CPU的处理性能，会对指令进行重排，指令重排只会保证当前线程执行结果一致，但指令重排后势必会影响多线程的执行结果
```

### cpu cache coherence
```
http://www.wowotech.net/kernel_synchronization/memory-barrier.html
https://www.cnblogs.com/z00377750/p/9180644.html

为减少存储器访问延迟，会为每个处理器添加本地的Cache

SMP系统中引入本地Cache会导致数据多副本问题

// cpu cache protocol
                            Main Memory
                                ↑
                                ↓
                        System Bus Interface 
                                ↑               
                                ↓               
            +--------------- L2 Cache <-----------------------+    
            |                   ↑                             |  
            ↓                   ↓                             |  
    L1 Instruction Cache     L1 Data Cache                    | 
            ↑                 ↑         ↑                     |
            |          Load Buffer   Store Buffer ---> Write-Combining Buffers 
            |                 ↑         ↑
            |                 |         |
            +------------->Execution Units
                              Registers

// cache
    cpu中的cache是一行一行的，每行可存储多个变量，每行都有自己的cache状态
    每个cache line有自己的flag，当他改变时，flag会发生变化

多处理器提供硬件级别的实现来解决Cache Coherence的问题

1、MESI协议
    https://www.jianshu.com/p/94200fc2d3f1
    来确保硬件级别Cache一致性（Cache Coherence）
    > cache状态
        M（修改, Modified）: 本地处理器已经修改缓存行, 即是脏行, 它的内容与内存中的内容不一样. 并且此cache只有本地一个拷贝（专有）。
        E（专有, Exclusive）: 缓存行内容和内存中的一样, 而且其它处理器都没有这行数据。
        S（共享, Shared）: 缓存行内容和内存中的一样, 有可能其它处理器也存在此缓存行的拷贝。
        I（无效, Invalid）: 缓存行失效, 不能使用。
        modified状态和exclusive状态都是独占该cacheline, 但是modified状态下，cacheline的数据是dirty的，而exclusive状态下，cacheline中的数据和memory中的数据是一致的

    > cache操作
        local read（LR）：读本地cache中的数据；
        local write（LW）：将数据写到本地cache；
        remote read（RR）：其他核心发生read；
        remote write（RW）：其他核心发生write；

        一个Invalid的缓存行必须从主存中读取（变成S或者 E状态）来满足该CPU的读请求
        一个写请求只有在该缓存行是M或者E状态时才能被执行，如果缓存行处于S状态，必须先将其它缓存中该缓存行变成Invalid状态(该操作经常作用广播的方式来完成)

    > cache状态转换
        > 直接转换关系
            M  E  S  I
        M   ×  ×  ×  √  RW
        E   ×  ×  ×  √  RW
        S   ×  ×  √  √  LR/RR   LW/RW
        I   √  √  √  √  LW  LR  RR  RW

        > exclusive
            当前CPU中的数据状态是exclusive，表示当前CPU独占数据（其他CPU没有数据），并且和主存的数据一致

            > 从Shared状态中分离出Exclusive状态来避免独占Cache Line的处理器第一次写Cache Line时发出的Coherence Message，从而减少总线流量
            
            > 相比Shared到Modified状态的迁移，第一次写独占Cache Line时进行的是Exclusive到Modified的迁移，不必发送Invalidate Message了

        > shared
            当前CPU中的数据状态是shared，表示当前CPU和其他CPU共享数据，且数据在多个CPU之间一致、多个CPU之间的数据和主存一致

            处理器读操作引起的Read Miss会令该Cache Line以Shared状态从存储器读入本地Cache中
            
            如果之前该Cache Line以Modified状态被某处理器持有，那监听到这个Read Miss的处理器用它持有的该Cache Line最新的副本响应源处理器，并更新存储器和其状态为shared

        > modify
            当前CPU中数据的状态是modify，表示当前CPU中拥有最新数据，虽然主存中的数据和当前CPU中的数据不一致，但是以当前CPU中的数据为准

            > 处理器写操作引起的Write Miss会令Cache Line以Modified状态从存储器读入本地Cache中
            > 如果之前该Cache Line被一个或多个处理器以Shared状态持有，则写操作处理器将向他们发送Invalidate Message令它们持有的Cache Line失效
            > 如果之前该Cache Line被某处理器以Modified状态持有，则写操作处理器向它发送Read-Invalidate Message，目标处理器收到消息后将其持有的Cache Line标记为Invalid并回应以最新的数据副本同时更新存储器

        > invalid
            当前CPU中的数据状态是invalid，表示当前CPU中是脏数据，不可用，其他CPU可能有数据、也可能没有数据

            收到Invalidate或Read-Invalidate Message的处理器会将对应的Cache Line置为Invalid状态

    > 这个协议有两个行为的执行成本比较大：
        一个是将某个Cache Line标记为Invalid状态
        一个是当某Cache Line当前状态为Invalid时写入新的数据
    > 所以CPU通过Store Buffer和Invalidate Queue组件来降低这类操作的延时


2、写缓冲区(store buffer)
    处理器为确保其他处理器看见自己的写操作，需要等待其他处理器在处理完自己发出的Invalidate Message后回应以Acknowledge Message，这个时间可能是几十上百个时钟周期
    而利用Write Buffer，处理器可以在将一个写操作放入Write Buffer的同时就发出Invalidate Message，在收到Acknowledge Message后才从Write Buffer中移除并以Modified状态写入自己的本地Cache，而在收到来自其他处理器的回应前可以继续执行其他指令

3、失效队列(Invalidate Queue)
    当处理器工作负载很高时，可能来不及处理、回应来自其他处理器的Coherence Message，从而将等待回应的其他处理器阻塞
    而利用一个消息缓冲区缓存这些请求并立刻回应源处理器表示消息已收到，可以提高响应速度
    处理器在收到Invalidate Message后可以先将其放入Invalidate Queue并立刻回应以Acknowledge Message，并在之后不忙或发生Cache Miss的时候再回来处理Invalidate Queue中缓存的请求
```

### Memory Model
```
https://github.com/GHScan/TechNotes/blob/master/2017/Memory_Model.md
https://ljalphabeta.gitbooks.io/a-primer-on-memory-consistency-and-cache-coherenc/content/

1、概念
    (1) Memory Model是个规范
        Memory Model是系统和程序员之间的'规范'，它规定了在一个'共享存储器'的多线程程序中的存储器访问应该表现出怎样的行为
        不同的平台Memory Model是不同的
        > 汇编语言中的Memory Model由具体多处理器规定和实现，不可移植
        > 高级语言中的Memory Model由高级语言标准来规定，由编译器和目标多处理器共同实现，可移植

    (2) Memory Model的作用
        编译器和多处理器的优化在多线程程序中可能导致'不可预测'的结果，但是关闭这些优化会严重'损害性能'
        为最大限度保留编译器和多处理器的'优化能力'，同时使多线程程序的执行结果是'可预测的'

        它决定了多处理器编程'性能'和'正确性'(单处理器无需考虑)

        所谓的Memory Model的规范，就是使用同步设施(各种内存屏障和原子指令)来标记多线程的互作关系

2、Memory Model属性
    1) Memory order
        Load-Load Order     不同地址上的读操作会否乱序
        Load-Store Order    读操作和后面另一个地址上的写操作会否乱序
        Store-Load Order    写操作和后面的读操作会否乱序
        Store-Store Order   不同地址上的写操作会否乱序
    2) 写原子性(Store Atomicity)
        Load Other's Store Early && Non-Causality
            允许写操作被自己及个别其他处理器先看到，不支持Causality。写序列可能以不同顺序被多个处理器观察到
        Load Other's Store Early && Causality
            允许写操作被自己及个别其他处理器先看到，支持Causality
        Load Own Store Early
            只允许写操作被自己先看到。写序列以相同顺序被多个处理器观察到
        Atomic Store
            所有处理器同时看到写操作(一般不用，仅理论)

3、基于存储器分类的Memory Model
    (1) 私有数据(Private Data, p_data)
        只被固定线程访问的数据 
        没有Data-Race(数据抢占)，不需要Cache Coherence
        其上的操作可以进行任何乱序，包括跨越s_data和sync_var的读写
    (2) 公有数据(Shared Data, s_data)
        允许多个线程访问，但任意时刻只被一个Owner持有
        没有Data-Race，需要Cache Coherence
        其上的读写可以进行任何乱序，但不能跨过sync_var
    (3) 同步变量(Synchronization Variable, sync_var)
        允许多个线程同时访问
        有Data-Race，需要Cache Coherence
        sync_var的读写之间不能进行乱序

    编译器通过高级语言提供的atomic或volatile声明识别出sync_var，进而生成Barrier指令来限制sync_var之间或sync_var与s_data之间的乱序
```

### Memory Consistency和Cache Coherence的区别
```
// Cache Coherence
    是多处理器的本地Cache导致多个数据副本在'Cache和存储器间不一致'的问题
    
// Memory Model
    是多处理器和编译器优化导致存储器操作被多个处理器观察到的'顺序不一致'的问题

// 还有这些明显区别
    前者的研究对象是多个地址，后者的研究对象是单个Cache Line
    就正确性而言，前者对程序员可见，后者对程序员透明，尽管后者影响性能
    Memory Model可以实现在只有Incoherent Cache甚至没有Cache的多处理器系统上
```

### Memory Order
```
https://www.jianshu.com/p/64240319ed60
http://ifeve.com/linux-memory-barriers/
http://ifeve.com/memory-barriers-or-fences/
https://zhuanlan.zhihu.com/p/43526907

1、代码重排
    代码顺序并不是真正的执行顺序，CPU和编译器可以进行各种优化从而导致指令重排
    // cpu乱序执行
        在一个固定长度的执行队列中，寻找可以同时执行的指令
        这个过程只需考虑指令间是否有依赖关系，不需要理解程序的意图
    // 编译器重排
        比处理器的范围更大，能在很大范围内进行代码分析，从而做出更优的策略，充分利用处理器的乱序执行功能
    // 重排序场景
        1) 编译器编译时的优化
            会发生指令重排以及常数量提升至缓存中
        2) 处理器执行时的乱序优化
            特殊的指令
            解决了cpu重排
        3) 缓存同步顺序(导致可见性问题)
            MESI协议，解决CPU缓存层面的问题
            解决了内存可见性
        // 注意
            C++11中volatile语义没有任何变化，不过提供了std::atomic工具可以真正实现原子操作，而且默认加入了内存屏障

2、内存屏障(Memory Barrier)
    由上所述，在多线程环境下指令的乱序执行会造成无法预测的行为
    仅仅使用同步操作是无法达到预期的，还需要内存屏障保证程序按逻辑运行
    内存屏障并不是锁，而锁是使用了内存屏障实现的一种用户层的同步处理方式
  
    
3、什么地方需要内存屏障
    在正常操作下，一个单线程代码片段中内存操作重排序一般不会产生问题，仍然可以正常工作，即使是在一个SMP内核系统中也是如此。但是，下面四种场景下，重新排序可能会引发问题：
    > 多处理器间的交互
    > 原子操作
    > 设备访问
    > 中断

4、内存屏障
    (1) 什么是内存屏障
        一个系统中，CPU和其它硬件可以使用各种技巧来提高性能，包括内存操作的重排、延迟、合并、预取、推测执行分支以及各种类型的缓存
        内存屏障是用来禁用或抑制这些技巧的，使代码稳健地控制多个CPU和(或)设备的交互
        不同的CPU架构上内存屏障的实现非常不一样，内存屏障是cpu技术

    (2) 内存屏障功能
        1) 屏障的两边的所有指令都是正确的程序顺序，而保持程序顺序的外部可见性
        2) 实现内存数据可见性，确保内存数据会同步到CPU缓存子系统
        // 注意
            "可见性"可以认为是弱的"一致性"(弱一致)，只保证用户见到的数据是一致的，但不保证任意时刻，存储的数据都是一致的(强一致)
            下文会讨论"缓存可见性"问题，部分文章也会称为"缓存一致性"问题

    
5、屏障类型
    > LoadLoad Barriers(LL)
        指令示例: Load1;LL;Load2	
        说明: 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的的操作
    > StoreStore Barriers(SS)
        指令示例: Store1;SS;Store2
        说明: 该屏障确保Store1立刻刷新数据到内存(使其对其他处理器可见)的操作先于Store2及其后所有存储指令的操作
    > LoadStore Barriers(LS)
        指令示例: Load1;LS;Store2
        说明: 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作
    > StoreLoad Barriers(SL)
        指令示例: Store1;SL;Load2	
        说明: 该屏障确保Store1立刻刷新数据到内存的操作先于Load2及其后所有装载装载指令的操作。它会使该屏障之前的所有内存存储指令完成之后,才执行该屏障之后的内存访问指令
        // 注意
            该屏障同时具备其他三个屏障的效果，因此也称之为全能屏障(mfence)，是目前大多数处理器所支持的；但是相对其他屏障，该屏障的开销相对昂贵。然而，除了mfence，不同的CPU架构对内存屏障的实现方式与实现程度非常不一样
        
6、x86内存屏障(指令)
    (1) Store Barrier
        sfence指令，相当于StoreStore Barriers
        强制所有在sfence指令之前的store指令，都在该sfence指令执行之前被执行，发送缓存失效信号，并把store buffer中的数据刷出到CPU的L1 Cache中
        强制所有在sfence指令之后的store指令，都在该sfence指令执行之后被执行，即禁止对sfence指令前后store指令的重排序跨越sfence指令，使所有Store Barrier之前发生的内存更新都是可见的
    (2) Load Barrier
        lfence指令，相当于LoadLoad Barriers  
        强制所有在lfence指令之后的load指令，都在该lfence指令执行之后被执行，并且一直等到load buffer被该CPU读完才能执行之后的load指令(发现缓存失效后发起的刷入)，即禁止对lfence指令前后load指令的重排序跨越lfence指令，配合Store Barrier，使所有Store Barrier之前发生的内存更新，对Load Barrier之后的load操作都是可见的
    (3) Full Barrier
        mfence指令，相当于StoreLoad Barriers
        mfence指令综合了sfence指令与lfence指令的作用，强制所有在mfence指令之前的store/load指令，都在该mfence指令执行之前被执行；所有在mfence指令之后的store/load指令，都在该mfence指令执行之后被执行。即禁止对mfence指令前后store/load指令的重排序跨越mfence指令，使所有Full Barrier之前发生的操作，对所有Full Barrier之后的操作都是可见的

7、linux kernel API
    (1) 编译器Barrier
        编译器对代码的优化
        asm volatile("":::"memory")
        volatile关键字禁止编译器把asm指令与程序其他指令重新组合, memory关键字强制编译器假定RAM中所有的内存单元已经被汇编指令修改
        因此，编译器不能使用cpu寄存器中的内存单元值来优化asm指令，需要重新存取内存的数据
        注意：编译屏障并不直接影响CPU，CPU依然可以按照它所希望的顺序进行重排序

    (2) 处理器Barrier
        > rmb
            rmb()提供一个读内存的屏障。确保跨域rmb()的载入动作不会发生重排序
            rmb()之前的载入操作不会排在该调用之后，同理rmb()之后的载入操作不会排在该调用之前
        > wmb
            wmb()提供一个写内存的屏障。确保跨域wmb()的写入动作不会发生重排序
            wmb()之前的写操作不会排在该调用之后，同理wmb()之后的写操作不会排在该调用之前
        > mb
            mb方法提供了读屏障和写屏障
        > 示例
            a的初始值为1，b的初始值为2
            线程1           线程2    
            a = 3           --
            mb()            --
            b = 4           c = b
            --              rmb()
            --              d = a
            其中mb()确保了a和b按照预定的顺序写入，rmb()确保c和d按照预定的顺序读取
```

### 原子操作、内存屏障、锁之间的关系
```
多线程之间对共享内存的操作需要同步机制来协调的

这个同步机制在操作系统中称为锁或同步原语

任何一个同步原语，有锁也好无锁也罢，都需要一个或多个共享变量的标记和前后关系的判断

就是说需要指令级的原子操作和控制指令的读写顺序

所以一个锁的实现需要上面两个步骤
```

### Memory Model的强度
```
Memory Model利用不同的属性策略，来达到不同的限制强度

强度越大，粒度越大，性能越低

从强至弱
(1) 顺序一致模型(Sequential Consistency)
    LL/LS/SL/SS:        不允许
    Store Atomicity:    Load Own Store Early

(2) 强内存模型(TSO, Total Store Order)
    SL乱序:             允许
    LL/LS/SS乱序:       不允许
    Store Atomicity:    Load Own Store Early

    Load/Store分别等效于Acquire/Release操作，实现锁时无需Barrier
    因为LL/LS/SS不允许乱序，Acquire操作可以被用于Lock，Release操作可以被用于Unlock
    x86等系统中实现锁是不需要Barrier指令的！！！！！！！！
    
(3) 弱内存模型(WO, Weak Order)
    LL/LS/SL/SS乱序：允许s_data读写乱序，不允许sync_var读写乱序
    Store Atomicity：Load Own Store Early
    WO是一种在性能和可编程性上有很好折中的Memory Model

(4) RC(Release Consistency)
    在RC中，sync_var包括Acquire和Release，Ordinary操作的乱序不允许向前跨过Acquire、不允许向后跨过Release
    RC是一种提供细粒度控制的常见Memory Model
    1) RCsc
        LL/LS/SL/SS乱序：允许(Ordinary操作)
        DL乱序：不允许
        Store Atomicity：Load Own Store Early
    2) RCpc
        LL/LS/SL/SS乱序：允许(Ordinary操作)
        DL乱序：不允许
        Store Atomicity：Load Other's Store Early && Causality

```