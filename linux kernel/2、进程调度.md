### 一些网站
```
【linux进程调度】http://qiankunli.github.io/2019/05/01/linux_task_schedule.html
【linux内核调度分析】https://cloud.tencent.com/developer/article/1027448
【深入解读linux进程调度系列】https://blog.csdn.net/Vince_/article/details/89054330
【linux进程调度 非常精细解读】https://blog.csdn.net/gatieme/article/details/51456569 ！！！
【Linux进程调度】http://qiankunli.github.io/2019/05/01/linux_task_schedule.html#per-cpu%E7%9A%84struct
【Linux内核调度分析（进程调度）】https://cloud.tencent.com/developer/article/1027448

```

### 进程分类
```
(1) 交互式进程(interactive process)	
    > 此类进程经常与用户进行交互, 因此需要花费很多时间等待键盘和鼠标操作. 当接受了用户的输入后, 进程必须很快被唤醒, 否则用户会感觉系统反应迟钝	
    > shell, 文本编辑程序和图形应用程序
(2) 批处理进程(batch process)	
    > 此类进程不必与用户交互, 因此经常在后台运行. 因为这样的进程不必很快相应, 因此常受到调度程序的怠慢
    > 程序语言的编译程序, 数据库搜索引擎以及科学计算
(3) 实时进程(real-time process)	
    > 这些进程由很强的调度需要, 这样的进程绝不会被低优先级的进程阻塞. 并且他们的响应时间要尽可能的短	
    > 视频音频应用程序, 机器人控制程序以及从物理传感器上收集数据的程序
    
```

### 进程调度相关概念
```
(1) 调度策略
    不同类型的进程采用不同的调度策略
    每次调度时，会先在实时进程运行队列中查看是否有可运行的实时进程，如果没有，再去普通进程运行队列找下一个可运行的普通进程，如果也没有，则调度器会使用idle进程进行运行
    1) 普通进程
        > 基于的策略
            > io消耗性和cpu消耗性进程
                为了保证交互式应用和桌面系统的性能，一般Linux更倾向于优先调度I/O消耗型进程
            > 优先级
                nice：      -20 到 +19，越大优先级越低
                实时优先级： 0 到 99，越大优先级越高
                任何实时优先级都高于普通进程，实时优先级和nice优先级处于不相交范畴
            > 时间片    
                每次调度时，把CPU分配给队首进程，并令其执行一个时间片。时间片的大小从几ms到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾;然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。
        > SCHED_NORMAL(SCHED_OTHER)
            > 用于普通进程，通过CFS调度器实现
            > 调度器类：CFS
        > SCHED_BATCH
            > 用于非交互的处理器消耗型进程
            > 调度器类：CFS
        > SCHED_IDLE
            > 优先级最低，在系统空闲时才跑这类进程
            > 调度器类：CFS-IDLE

    2) 实时进程
        > SCHED_FIFO
            > 先入先出调度算法（实时调度策略），不采用时间片，相同优先级的任务先到先服务，高优先级的任务可以抢占低优先级的任务
            > 调度器类：RT
        > SCHED_RR
            > 轮流调度算法（实时调度策略），采用时间片，相同优先级的任务当用完时间片会被放到队列尾部，以保证公平性，同样，高优先级的任务可以抢占低优先级的任务
            > 调度器类：RT
        > SCHED_DEADLINE
            > 新支持的实时进程调度策略，针对突发型计算，且对延迟和完成时间高度敏感的任务适用
            > 调度器类：DL

(2) 调度方式
    所有的调度最终是通过正在运行的进程调用schedule函数实现
    1) 时机
        > 主动调用schedule()、cond_resched()时
        > 系统调用返回用户空间和异常中断返回用户空间时
        > 从中断上下文返回时
    2) 场景
        > 进程主动放弃cpu，比如sleep、I/O等待时，调用schedule()
        > 调用系统函数返回的时候
        > 禁止内核抢占后，再开启内核抢占的时候(开启内核抢占时，在系统调用或者异常中断上下文中调用preempt_enable()时(多次调用preempt_enable()时，系统只会在最后一次调用时会调度))
        > 时钟中断处理函数评估当前进程并标记为可抢占，然后找机会让正在运行的进程有机会调用schedule

(3) 调度入口
    主要函数是schedule()，具体见下文条目

```

### 调度器类
```
(1) 调度器类
    依据其调度策略的不同实现了5个调度器类
    1) stop_sched_class	
        > 优先级最高的线程，会中断所有其他线程，且不会被其他任务打断
        > 对应调度策略: 无, 不需要调度普通进程
    2) dl_sched_class
        > 采用EDF最早截至时间优先算法调度实时进程
        > 对应调度策略: SCHED_DEADLINE
    3) rt_sched_class
        > 采用提供 Roound-Robin算法或者FIFO算法调度实时进程
        > 对应调度策略: SCHED_FIFO, SCHED_RR
    4) fair_sched_clas
        > 采用CFS算法调度普通的非实时进程
        > SCHED_NORMAL, SCHED_BATCH
    5) idle_sched_class
        > 采用CFS算法调度idle进程
        > SCHED_IDLE
    6) 优先级
        stop_sched_class -> dl_sched_class -> rt_sched_class -> fair_sched_class -> idle_sched_class
```

### 调度相关的数据结构
```
(1) sched_class
    > sched_class结构体类似面向对象中的基类啊,通过函数指针类型的成员指向不同的函数，实现了多态（不同的调度类）
    > 就是说对于各个调度器类, 都必须提供struct sched_class的一个实例
    > 存在于进程描述符中
    > 成员函数：enqueue_task, dequeue_task, yield_task, pick_next_task, put_prev_task, set_curr_task, task_tick, ...

(2) task_struct中的调度结构
    struct task_struct
    {
        ........
        /* 表示是否在运行队列 */
        int on_rq;

        //非实时进程优先级 
        //prio: 动态优先级，范围为100~139，与静态优先级和补偿(bonus)有关
        //static_prio: 静态优先级，static_prio = 100 + nice + 20 (nice值为-20~19,所以static_prio值为100~139)
        //normal_prio: 没有受优先级继承影响的常规优先级，具体见normal_prio函数，跟属于什么类型的进程有关
        int prio, static_prio, normal_prio;

        //实时进程优先级                    
        unsigned int rt_priority;

        //调度类，调度处理函数类
        const struct sched_class *sched_class;

        //调度策略
        //#define SCHED_NORMAL            0
        //#define SCHED_FIFO              1
        //#define SCHED_RR                2
        //#define SCHED_BATCH             3
        //#define SCHED_IDLE              5
        //#define SCHED_DEADLINE          6
        unsigned int policy;

        //3个调度实体（每个实体是红黑树的一个节点,整个实体红黑树的root在就绪队列的结构体中）
        //CFS调度实体
        struct sched_entity se;
        //RT调度实体
        struct sched_rt_entity rt;
        //DEADLINE调度实体
        struct sched_dl_entity dl;

    #ifdef CONFIG_CGROUP_SCHED
        //指向其所在进程组(注意此进程组非fork出来的进程组)
        struct task_group *sched_task_group;
    #endif
        ........
    }
    //除此之外还有cpumask_t cpus_allowed，在多处理器系统上使用, 用来限制进程可以在哪些CPU上运行

(3) 调度实体
    存在于在上述的task_struct中
    调度器不直接操作进程，而是处理可调度实体, 因此需要一个通用的数据结构描述这个调度实体,即sched_entity结构, 其实际上就代表了一个调度对象，可以为一个进程，也可以为一个进程组
    1) 分类
        > sched_dl_entity(DEADLINE调度实体)
            > 采用EDF算法调度的实时调度实体
            > 对应的调度器类：dl_sched_class
        > sched_rt_entity(RT调度实体)    
            > 采用Roound-Robin或者FIFO算法调度的实时调度实体
            > 对应的调度器类：rt_sched_class
        > sched_entity(CFS调度实体)    
            > 采用CFS算法调度的普通非实时进程的调度实体
            > 对应的调度器类：fair_sched_class
    2) sched_entity
        > 结构
            struct sched_entity {
                /* 用于进行调度均衡的相关变量，主要跟红黑树有关 */
                struct load_weight		load;           // 权重，跟优先级有关
                unsigned long			runnable_weight; // 在所有可运行进程中所占的权重
                struct rb_node			run_node;       // 红黑树的节点
                struct list_head		group_node;     // 所在的进程组
                unsigned int			on_rq;          // 标记是否处于红黑树运行队列中

                u64				exec_start;             // 进程开始执行的时间
                u64				sum_exec_runtime;        // 进程总运行时间
                u64				vruntime;               // 虚拟运行时间，下面会给出详细解释
                u64				prev_sum_exec_runtime;  // 进程在切换CPU时的sum_exec_runtime，简单说就是上个调度周期中运行的总时间
                u64				nr_migrations;
                struct sched_statistics		statistics;
                
                //当前调度单元归属于某个父调度单元
                struct sched_entity    *parent;
                //当前调度单元归属的父调度单元的调度队列，即当前调度单元插入的队列
                struct cfs_rq        *cfs_rq;
                //当前调度单元的调度队列，即管理子调度单元的队列，
                //如果调度单元是task_group，my_q才会有值，如果当前调度单元是task，那么my_q自然为NULL
                struct cfs_rq        *my_q;


                // 以下省略了一些在特定宏条件下才会启用的变量
            }
        > vruntime(虚拟运行时间)
            虚拟运行时间是通过进程的实际运行时间和进程的权重(weight)计算出来的，它以ns为单位
            vruntime最小的在红黑树最左端，被最先调度
            跟踪运行时间是由update_curr不断累积完成的. 内核中许多地方都会调用该函数

(4) 就绪队列(调度队列)
    就绪队列是核心调度器用于管理活动进程的主要数据结构。
    各个CPU都有自身的就绪队列，各个活动进程只出现在一个就绪队列中, 在多个CPU上同时运行一个进程是不可能的.
    每个CPU对应包含一个运行队列结构(struct rq)，而每个运行队列又包含有其自己的实时进程运行队列(struct rt_rq)、普通进程运行队列(struct cfs_rq)、和deadline实时调度的运行队列(struct dl_rq)，也就是说每个CPU都有他们自己的实时进程运行队列及普通进程运行队列
    1) struct rq(cpu就绪队列)
        > 关键的结构
            > unsigned long nr_running    
                队列上可运行进程的数目, 不考虑优先级和调度类
            > struct load_weight load
                提供了就绪队列当前负荷的度量, 队列的符合本质上与队列上当前活动进程的数目成正比, 其中的各个进程又有优先级作为权重. 每个就绪队列的虚拟时钟的速度等于该信息
            > unsigned long cpu_load[CPU_LOAD_IDX_MAX]	
                用于跟踪此前的负荷状态
            > struct cfs_rq cfs
                cfs调度器的rq就绪队列
            > struct rt_rq rt
                实时调度器的rq就绪队列
            > struct task_struct *curr
                当前运行的进程的task_struct实例
            > struct task_struct *idle  
                指向空闲进程的task_struct实例
            > u64 clock
                就绪队列自身的时钟
        > API
            DECLARE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);
            #define cpu_rq(cpu)             (&per_cpu(runqueues, (cpu)))
            #define this_rq()               this_cpu_ptr(&runqueues)
            #define task_rq(p)              cpu_rq(task_cpu(p))
            #define cpu_curr(cpu)           (cpu_rq(cpu)->curr)
            #define raw_rq()                raw_cpu_ptr(&runqueues)

    2) cfs_rq(CFS公平调度器的就绪队列)
        其代表着一个CFS运行队列，并且包含有一个红黑树进行选择调度进程
        > 概念
            CFS包含其他进程组和进程
            不同的进程组拥有自己的CFS队列，其队列中包含其子进程和进程组
            在系统中至少有一个CFS运行队列，其就是根CFS运行队列，而其他的进程组和进程都包含在此运行队列中，不同的是进程组又有它自己的CFS运行队列，其运行队列中包含的是此进程组中的所有进程。当调度器从根CFS运行队列中选择了一个进程组进行调度时，进程组会从自己的CFS运行队列中选择一个调度实体进行调度(这个调度实体可能为进程，也可能又是一个子进程组)，就这样一直深入，直到最后选出一个进程进行运行为止
        > 关键的结构
            > struct rb_root tasks_timeline
                该红黑树的root
            > struct rb_node *rb_leftmost
                下一个调度结点(红黑树最左边结点，最左边结点就是下个调度实体)
            > struct sched_entity *curr, *next, *last, *skip
                curr: 当前正在运行的sched_entity（对于组虽然它不会在cpu上运行，但是当它的下层有一个task在cpu上运行，那么它所在的cfs_rq就把它当做是该cfs_rq上当前正在运行的sched_entity）
                next: 表示有些进程急需运行，即使不遵从CFS调度也必须运行它，调度时会检查是否next需要调度，有就调度next
                skip: 略过进程(不会选择skip指定的进程调度)
            > struct task_group *tg
                拥有该CFS运行队列的进程组    
    3) rt_rq(实时进程就绪队列)

(5) 组调度
    http://oenhan.com/task-group-sched
    https://blog.csdn.net/gatieme/article/details/51702662
    这里的进程组概念和fork调用所产生的父子进程组概念不一样。为了管理组调度，内核引进了struct task_group结构
    1) 分组
        > 按照进程的USER ID进行分组
        > cgroup
    2) 结构
        struct task_group {
            ...
            struct sched_entity **se;           //se[cpu0] 
            struct sched_rt_entity **rt_se;     //rt_se[cpu0] 
            ...
            struct cfs_rq **cfs_rq;             //cfs_rq[cpu0]
            struct rt_rq **rt_rq;               //rt_rq[cpu0]
            ...
            //parent
            //sibling
            //children
            //task_group是链表结构,有父节点,兄弟链表,孩子链表
        }

        在SMP架构下，同一进程组的进程可能运行在不同cpu上，所以每个进程组必须对每个cpu分配它的调度实体和运行队列
    3) 组调度策略


```

### 调度数据结构之间的关系
```
(1) 相关结构
    struct rq{
        struct cfs_rq cfs
        struct rt_rq rt
    }

    struct cfs_fq{
        struct rb_root tasks_timeline
        struct rb_node *rb_leftmost
        struct task_group *tg
    }

    struct task_group {
        struct sched_entity **se
        struct cfs_rq **cfs_rq

        struct sched_rt_entity **rt_se
        struct rt_rq **rt_rq
    }

    struct sched_entity {
        struct rb_node run_node
        u64 vruntime

        struct cfs_rq *cfs_rq
        struct cfs_rq *my_q
    }

    struct task_struct {
        struct sched_entity se
        struct sched_rt_entity rt
        struct sched_class *sched_class 
    }  

    调度类 {
        stop_sched_class -> dl_sched_class -> rt_sched_class -> fair_sched_class -> idle_sched_class
    }

(2) 结构关系图
                cpu 
                 |
                 ↓
             struct rq {
                 struct cfs_rq cfs --+
                 struct rt_rq rt     |
             }                       |
                      +--------------+                
                      ↓
             struct cfs_fq { <---------------------------------------------------------------------------------------+   
                 struct rb_root tasks_timeline ---+                                                                  |    
     +---------- struct rb_node *rb_leftmost      |                                                                  |                
     |           struct task_group *tg -------------------+--------> struct task_group {                             |
     |       }                                    |       |               struct sched_entity **se                   |
     |                                            |       |               struct cfs_rq **cfs_rq //选择cfs_rq[CPU0] -+
     |                     rb_node <--------------+       |               struct sched_rt_entity **rt_se
     |                        |                           |               struct rt_rq **rt_rq            
     |             +----------+---------+                 |         <---> struct task_group *slibing <--->
     |             |                    |                 |          }
     |         rb_node               rb_node              | 
     |             |                    |                 | 
     |       +-----+----+         +-----+------+          | 
     |       |          |         |            |          | 
     +---> rb_node    rb_node    rb_node     rb_node      |
                                               |          | 
                                               |          |  
     +-----> struct sched_entity {             |          | 
     |           struct rb_node run_node <-----+          |
     |           u64 vruntime                             |
     |                                                    | 
     |           struct cfs_rq *cfs_rq                    | 
     |           struct cfs_rq *my_q  //非NULL表示调度组 --+ 
     |       }
     |
     |       struct task_struct {
     +---------- struct sched_entity se
                 struct sched_rt_entity rt
  +------------- struct sched_class *sched_class 
  |                     }                                   
  |                                  
  ↓                                  
调度类 +----------------------------------------------------------------------------------------------+
      | stop_sched_class -> dl_sched_class -> rt_sched_class -> fair_sched_class -> idle_sched_class |
      +----------------------------------------------------------------------------------------------+
                                        |
                                 pick_next_task
                                        ↓    
                                      调度器
                                        ↓
                                    上下文切换
                                        ↓
                                       cpu  

(3) 结构关系描述
    1) 当前cpu的rq -> cfs_rq
    2) cfs_rq选取红黑树中最左边的sched_entity调度实体
    3) sched_entity的调度                                             
                        +------------------------------------------------------------------------------+
                        ↓    红黑树最左node                                      my_q != NULL           |
    cpu ---> rq ---> cfs_rq ----------------> task_group ---> cfs_rq ---> sched_entity -+--------------+

```

### 调度入口
```
(1) schedule主调度
    1) 工作
        > 确定当前就绪队列, 保存task_struct指针
        > 检查死锁, 关闭内核抢占后调用__schedule完成内核调度
        > 恢复内核抢占, 然后检查当前进程是否设置了重调度标志TLF_NEDD_RESCHED, 如果该进程被其他进程设置了TIF_NEED_RESCHED标志, 则函数重新执行进行调度
    2) schedule
        asmlinkage __visible void __sched schedule(void)
        {

            //获取当前的进程
            struct task_struct *tsk = current;

            // sched_submit_work用于检测当前进程是否有plugged io需要处理，由于当前进程执行schedule后，有可能会进入休眠，所以在休眠之前需要把plugged io处理掉防止死锁
            sched_submit_work(tsk);
            
            do {
                preempt_disable();                  // 关闭内核抢占
                __schedule();                       // 调度主入口
                sched_preempt_enable_no_resched();  // 开启内核抢占
            } while (need_resched());               //如果该进程被其他进程设置了TIF_NEED_RESCHED标志，则函数重新执行进行调度
        }
        EXPORT_SYMBOL(schedule);
    3) 内核抢占
        > 内核态
            用户程序的上下文属于用户态，系统调用和中断处理例程上下文属于内核态
        > 用户抢占内核抢占    
            用户态抢占：一个进程在用户态时被其他进程抢占了
            内核态抢占：进入内核态的进程, 被其他进程抢占了，则发生了内核抢占
            抢占内核的主要特点是：一个在内核态运行的进程，当且仅当在执行内核函数期间被另外一个进程取代
        > API
            #define preempt_disable() \
            do { \
                preempt_count_inc(); \
                barrier(); \
            } while (0)

            #define sched_preempt_enable_no_resched() \
            do { \
                barrier(); \
                preempt_count_dec(); \
            } while (0)

(2) __schedule
    static void __sched notrace __schedule(bool preempt)
    {
        struct task_struct *prev, *next;
        unsigned long *switch_count;
        struct rq *rq;
        int cpu;

        ...
        rq = cpu_rq(cpu);
        // 将正在运行的进程curr保存到prev中
        prev = rq->curr;

        ...
        // 关闭本地中断
        local_irq_disable();

        ...
        // 锁住该队列
        raw_spin_lock(&rq->lock);
        lockdep_pin_lock(&rq->lock);

        rq->clock_skip_update <<= 1; /* promote REQ to ACT */

        /*  切换次数记录, 默认认为非主动调度计数(抢占)  */
        switch_count = &prev->nivcsw;

        // 下面判断主动抢占schedule()还是被动抢占
        // 被动抢占有两种情况，时钟中断和其他中断
        // 时间片中断，设置当前进程need_resched，中断结束调用preempt_schedule_irq执行调度

        // 内核态没有被抢占(preempt = false，自己主动调用)，并且该进程处于停止状态(TASK_INTERRUPTIBLE)
        if (!preempt && prev->state)
        {

            // 如果当前进程有非阻塞等待信号，并且它的状态是TASK_INTERRUPTIBLE
            if (unlikely(signal_pending_state(prev->state, prev)))
            {
                // 将当前进程的状态设为：TASK_RUNNING
                prev->state = TASK_RUNNING;
            }
            else   // 否则需要将prev进程从就绪队列中删除
            {
                // 将当前进程从runqueue(运行队列)中删除
                deactivate_task(rq, prev, DEQUEUE_SLEEP);

                ...
                // 如果一个worker进入睡眠状态，通知并询问workqueue是否需要唤醒一个任务以保持并发性
                if (prev->flags & PF_WQ_WORKER) {
                    struct task_struct *to_wakeup;

                    to_wakeup = wq_worker_sleeping(prev);
                    if (to_wakeup)
                        try_to_wake_up_local(to_wakeup);
                }
            }
            ...
        }

        // 如果prev进程仍然在就绪队列上没有被删除
        if (task_on_rq_queued(prev))
            update_rq_clock(rq);  // 更新就绪队列的时钟

        // 挑选一个优先级最高的任务将其排进队列
        next = pick_next_task(rq, prev);
        // 清除pre的TIF_NEED_RESCHED标志
        clear_tsk_need_resched(prev);
        //  清楚内核抢占标识
        clear_preempt_need_resched();

        ...
        // 如果prev和next非同一个进程
        if (likely(prev != next))
        {
            ...
            // 进程之间上下文切换
            rq = context_switch(rq, prev, next);
        }
        else // 如果prev和next为同一进程，则不进行进程切换
        {
            lockdep_unpin_lock(&rq->lock);
            raw_spin_unlock_irq(&rq->lock);
        }

        balance_callback(rq);
    }
    STACK_FRAME_NON_STANDARD(__schedule);
    
(3) pick_next_task
    全局的pick_next_task函数会从按照优先级遍历所有调度器类的pick_next_task函数, 去查找最优的那个进程
    static inline struct task_struct *pick_next_task(struct rq *rq, struct task_struct *prev, struct rq_flags *rf){
        const struct sched_class *class;
        struct task_struct *p;
        ......
        for_each_class(class) {
            p = class->pick_next_task(rq, prev, rf);
            if (p) {
                if (unlikely(p == RETRY_TASK))
                    goto again;
                return p;
            }
        }
    }


// 时钟调度
    时钟中断处理函数会调用scheduler_tick函数
    scheduler_tick --> fair_sched_class.task_tick_fair --> entity_tick --> update_curr 更新当前进程的vruntime --> check_preempt_tick 检查是否是时候被抢占了
    void scheduler_tick(void){
        int cpu = smp_processor_id();
        struct rq *rq = cpu_rq(cpu);
        struct task_struct *curr = rq->curr;
        ......
        curr->sched_class->task_tick(rq, curr, 0);
        cpu_load_update_active(rq);
        calc_global_load_tick(rq);
        ......
    }


```


### 进程上下文切换
```
http://www.sizeofvoid.net/goroutine-under-the-hood/

上下文切换(有时也称做进程切换或任务切换)是指CPU从一个进程或线程切换到另一个进程或线程

(1) 基本任务
    1) 挂起一个进程，将这个进程在 CPU 中的状态（上下文）存储于内存中的某处，
    2) 在内存中检索下一个进程的上下文并将其在 CPU 的寄存器中恢复
    3) 跳转到程序计数器所指向的位置（即跳转到进程被中断时的代码行），以恢复该进程

(2) context_switch
    struct rq* context_switch(struct rq *rq, struct task_struct *prev, struct task_struct *next) 
    context_switch函数完成了进程上下文的切换
    1) 调用switch_mm() 把虚拟内存从一个进程映射切换到新进程中
    2) 调用switch_to() 从上一个进程的处理器状态切换到新进程的处理器状态。这包括保存、恢复栈信息和寄存器信息
    
(3) switch_mm
    switch_mm主要完成了进程prev到next虚拟地址空间的映射
    如果next是一个内核线程, 它使用prev所使用的地址空间(内核虚拟地址空间不用切换的)
    切换的主要是用户态的虚拟地址空间

(4) switch_to
    switch_to完成了进程的切换, 该函数切换了寄存器状态和栈, 新进程在该调用后开始执行, 而switch_to之后的代码只有在当前进程下一次被选择运行时才会执行
    > 进程切换, 即esp的切换, 由于从esp可以找到进程的描述符
    > 硬件上下文切换, 设置ip寄存器的值, 并jmp到__switch_to函数
    > 堆栈的切换, 即ebp的切换, ebp是栈底指针, 它确定了当前用户空间属于哪个进程
```

### 睡眠与唤醒
```
(1) 睡眠
    进程将自己标记成休眠状态，然后从可执行红黑树中移除，放入等待队列，然后调用选择和执行一个其他进程。
    1) 进程睡眠的过程
        //在当前进程创建一个等待队列项
        DEFINE_WAIT(wait);                                  
        
        //将等待队列项加入全局等待队列中，当然我们必须在其他地方撰写相关代码,在事件发生时,对等待队列执行wake_up()操作
        add_wait_queue(q, &wait);
        
        //循环判断条件
        while(!condition){

            //将进程状态变为TASK_INTERRUPTIBLE或TASK_UNINTERRUPTIBLE
            prepare_to_wait(&q,&wait, TASK_INTERRUPTIBLE);  

            //信号和等待事件都可以唤醒处于TASK_INTERRUPTIBLE状态的进程
            //该进程被唤醒后,如果(!condition)结果为真,则说明该进程不是由等待事件唤醒
            if (signal_pending(current)) {
                //由于信号唤醒该进程为伪唤醒，所以要判断条件是否为真
                if (condition) break;
            }                 
            
            //当前进程进入睡眠，所以当被唤醒后，也从这部开始运行
            schedule();             
        }
        finish_wait(&q, &wait);     //状态设置为TASK_RUNNING，然后移出等待队列

(2) 唤醒
    进程被设置为可执行状态，然后从等待队列移到可执行红黑树中去
    唤醒是通过wake_up()，唤醒指定等待队列的所有进程，它调用try_to_wake_up()将进程状态设置为TASK_RUNNING状态，然后调用enqueue_task()将此进程放入红黑树
    1) 唤醒过程
        等待队列
                        ↓    
                                wake_up()   要判断是否假唤醒
                        ↓            
        进程(TASK_INTERRUPTIBLE)
                        ↓
                                try_to_wake_up()                        
                        ↓        
        进程(TASK_RUNNING)
                        ↓
                                enqueue_task()
                        ↓
        红黑树
                        ↓
                当前进程是否need_resched?
                        ↓ 是
                    schedule()

```


### 抢占
```
https://cloud.tencent.com/developer/article/1432987

(1)用户抢占
    当内核即将返回用户空间时，内核会检查need_resched是否设置，如果设置，则调用schedule()，此时，发生用户抢占。一般来说，用户抢占发生几下情况
    1)从系统调用返回用户空间
    2)从中断(异常)处理程序返回用户空间

(2)内核抢占
    一个在内核态运行的进程，可能在执行内核函数期间被另一个进程取代。
    1) 内核抢占发生的时机
        > 当从中断处理程序正在执行，且返回内核空间之前。
        > 当内核代码再一次具有可抢占性的时候，如解锁（spin_unlock_bh）及软中断激活(local_bh_enable)等。
        > 如果内核中的任务显式的调用schedule()。
        > 如果内核中的任务阻塞(这同样也会导致调用schedule())。
        > preempt_count为0
    2) 内核不能被抢占的情况
        > 内核正进行中断处理
            在Linux内核中进程不能抢占中断(中断只能被其他中断中止、抢占，进程不能中止、抢占中断)，在中断例程中不允许进行进程调度。进程调度函数schedule()会对此作出判断，如果是在中断中调用，会打印出错信息。
        > 内核正在进行中断上下文的Bottom Half(中断的底半部)处理
            硬件中断返回前会执行软中断，此时仍然处于中断上下文中。
        > 内核的代码段正持有spinlock自旋锁、writelock/readlock读写锁等锁，处干这些锁的保护状态中
            内核中的这些锁是为了在SMP系统中短时间内保证不同CPU上运行的进程并发执行的正确性。当持有这些锁时，内核不应该被抢占。
        > 内核正在执行调度程序Scheduler
            抢占的原因就是为了进行新的调度，没有理由将调度程序抢占掉再运行调度程序。
        > 内核正在对每个CPU"私有"的数据结构操作(Per-CPU date structures)
            在SMP中，对于per-CPU数据结构未用spinlocks保护，因为这些数据结构隐含地被保护了(不同的CPU有不一样的per-CPU数据，其他CPU上运行的进程不会用到另一个CPU的per-CPU数据)。但是如果允许抢占，但一个进程被抢占后重新调度，有可能调度到其他的CPU上去，这时定义的Per-CPU变量就会有问题，这时应禁抢占。
    
```

### 中断与抢占
```
// 对以往的总结
> 硬中断和软中断(只要是中断上下文)执行的时候都不允许内核抢占
> 禁止中断也就禁止了内核抢占
> 硬中断可以被另一个优先级比自己高的硬中断"中断"，不能被同级(同一种硬中断)或低级的硬中断"中断"，更不能被软中断"中断"
> 软中断可以被硬中断"中断"，但是不会被另一个软中断"中断"，因为在一个CPU上，软中断总是串行执行。在单处理器计算机上，对软中断的数据结构进行访问不需要加任何同步原语
> 软中断可以被进程抢占，但是不会睡眠(不会放进睡眠队列)，所以不能在软中断中使用信号量和阻塞
```

### 禁止内核抢占和禁止中断
```
(1) 禁止中断
    禁止中断，可以确保某个中断处理程序不会抢占当前的代码
    > API
        static inline void local_irq_enable(void)
        {
            unsigned long tmpreg;
            __asm__ __volatile__(
                "mvfc	%0, psw;		\n\t"
                "or3	%0, %0, #0x0040;	\n\t"
                "mvtc	%0, psw;		\n\t"
            : "=&r" (tmpreg) : : "cbit", "memory");
        }
        
        static inline void local_irq_disable(void)
        {
            unsigned long tmpreg0, tmpreg1;
            __asm__ __volatile__(
                "ld24	%0, #0	; Use 32-bit insn. \n\t"
                "mvfc	%1, psw	; No interrupt can be accepted here. \n\t"
                "mvtc	%0, psw	\n\t"
                "and3	%0, %1, #0xffbf	\n\t"
                "mvtc	%0, psw	\n\t"
            : "=&r" (tmpreg0), "=&r" (tmpreg1) : : "cbit", "memory");
        }

(2) 禁止内核抢占
    在进程调度层面，防止当前进程不会突然被另一个进程抢占
    > API
        #define preempt_disable() \
        do { \
            //增加preempt_count
            inc_preempt_count(); \
            //保证先加了preempt_count才进行以后的操作
            barrier(); \
        } while (0)
        
        #define preempt_enable() \
        do { \
            preempt_enable_no_resched(); \
            barrier(); \
            //检查当前进程是否可抢占
            preempt_check_resched(); \
        } while (0)

(3) 禁止的目的
    不管是禁止中断还是禁止内核抢占，都是为了提供内核同步，但是他们都没有提供任何保护机制来防止其它处理器的并发访问
    Linux支持多处理器，内核代码一般都需要获取某种锁，防止来自其他处理器对共享数据的并发访问
    而禁止中断提供保护机制，这是防止来自其他中断处理程序的并发访问

(4) 对于当前cpu禁止中断就可以禁止内核抢占
    我们说禁止中断可以禁止内核抢占只是说禁止任何意外的抢占，如果进程自己要调用schedule函数，那谁也拦不住，事实上调用schedule这个函数本来就要禁止中断
    
    所以剩下的就是考虑创建或者唤醒一个更高优先级的进程，或者调用信号量、完成量，所有的这些情况都要通过try_to_wake_up函数唤醒另一个进程，但是这个函数真正干的事只是设置了一下need_resched这个函数，并没有真的调用schedule函数，调用是在系统调用返回用户空间的时候进行的，所以跟内核抢占也没啥关系

(5) 单处理器上的数据不需要自旋锁，但是仍然需要关闭内核抢占
    如果内核可以被抢占，那么一个新调度的任务就可能访问同一个变量

```