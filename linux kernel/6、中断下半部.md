### 硬中断与软中断
```
[区别](https://blog.csdn.net/xuchenhuics/article/details/79120644)

中断泛指硬中断
硬中断是外部设备对CPU的中断，软中断是中断后半部的一种处理机制

> 中断控制器
    硬中断的中断号是由中断控制器提供的
    软中断的中断号由指令直接给出，无需使用中断控制器。

> 屏蔽
    硬中断是可屏蔽的,软中断不可屏蔽

> 嵌套
    Linux下硬中断是可以嵌套的，但是没有优先级的概念，也就是说任何一个新的中断都可以打断正在执行的中断，但同种中断除外。
    软中断不能嵌套，但相同类型的软中断可以在不同CPU上并行执行

> 抢占
    > 硬中断可以被另一个优先级比自己高的硬中断'中断'，不能被同级（同一种硬中断）或低级的硬中断'中断'，更不能被软中断'中断'
    > 软中断可以被硬中断'中断'，但是不会被另一个软中断'中断'。在一个CPU上，软中断总是串行执行
    > 在单处理器上，对软中断的数据结构进行访问不需要加任何同步原语。    
    > 软中断可以被抢占，但是不会睡眠(不会放进睡眠队列)，所以不能在软中断中使用信号量和阻塞
    > 中断上下文执行的时候都不允许内核抢占

> 执行过程
    软中断一般是指由指令int引起的'伪'中断动作——给CPU制造一个中断的假象
    硬中断则是实实在在由8259的连线触发的中断
    
    int与IRQ毫无关系，但二者均与中断向量有关系

    int引起的中断，CPU是从指令中取得中断向量号
    IRQ引起的中断，CPU必须从数据线上取回中断号
    接下来CPU的工作就一样了


```

### 软中断与信号
```
https://www.cnblogs.com/charlesblc/p/6277810.html
```

### 软中断相关概念
```
(1) 哪些处理放在下半部
    如果一个任务对时间十分敏感，将其放在上半部
    如果一个任务和硬件有关，将其放在上半部
    如果一个任务要保证不被其他中断打断，将其放在上半部
    其他所有任务，考虑放在下半部

(2) 流程
                        中断退出
        +------------> irq_exit --------------+  
        ↑                                     ↓
    注册软中断         主动触发软中断       执行软中断                             否  
    open_softirq ---> raise_softirq ---> do_softirq ---> 是否有未执行的中断函数 ---> 结束本次中断
                                            ↑                          ↓ 是  
                                            +-------执行相应中断函数<---+

    软中断的触发有两种方式
    > 硬中断执行完毕退出时，调用irq_exit，会执行do_softirq
    > 主动激活内核软中断守护线程，执行do_softirq

(3) 软中断、tasklet、工作队列
    #下半部机制   上下文    复杂度                           性能   顺序执行保障                能否睡眠 工作场景
    软中断        中断     高(确保软中断的执行顺序和锁机制)    好     没有                       不能     中断上下文   
    tasklet       中断     中(提供接口使用软中断)             中     同类型不能(不会)同时执行    不能     中断上下文  
    工作队列      进程     低(在进程上下文运行，类似用户程序)  差     没有(和进程上下文一样被调度) 可以     进程上下文

    > 软中断的分配时静态的(即在编译时定义)，而tasklet的分配和初始化能够在执行时进行。
    > 软中断的并行
        > 软中断(即便是同一种类型的软中断)能够并发地运行在多个CPU上。因此，软中断是可重入函数并且必须明白地使用自旋锁保护其数据结构。
    > tasklet的并行
        > tasklet不必操心这些问题。由于内核对tasklet的运行进行了更加严格的控制。同样类型的tasklet总是被串行运行。
        > 换句话说就是：不可能存在在两个CPU上同一时候执行同样类型的tasklet。可是，类型不同的tasklet能够在几个CPU上并发执行。
        > tasklet的串行化使tasklet函数不必是可重入的

(4) 自旋锁、中断、下半部
         抢占          抢占 
    中断 ----> 软中断 -----> 进程上下文

    > 当下半部和进程上下文共享数据时，需要加锁同时禁止软中断
    > 当中断和下半部共享数据时，需要加锁同时禁止中断
    > 当下半部之间共享数据时
        > 同类tasklet
            同类的tasklet不可能同时运行，所以同类的tasklet中的共享数据不需要任何保护
        > 不同类tasklet
            同一处理器不会出现tasklet相互抢占的情况，他们在不同处理器上运行，一个自旋锁就可以


https://blog.csdn.net/vividonly/article/details/6609053
http://blog.sae.sina.com.cn/archives/4103
https://www.cnblogs.com/tolimit/p/4495128.html
https://blog.csdn.net/droidphone/article/details/7518428
http://www.wowotech.net/irq_subsystem/soft-irq.html

```



### 软中断涉及的结构与函数
```
(1) softirq_action
    //数组元素为 softirq_action,一个元素代码一个软中断。不同的软中断号对应不同的数组的下标
    static struct softirq_action softirq_vec[32]__cacheline_aligned_in_smp;
    
    struct softirq_action {
        //软中断发生时执行软中断的处理函数
        void (*action)(struct softirq_action *); 
        //软中断的处理函数的参数指针
        void *data;
    }

    //软中断类型
    enum {
        HI_SOFTIRQ=0,          //处理高优先级的tasklet
        TIMER_SOFTIRQ,         //时钟中断相关的tasklet
        NET_TX_SOFTIRQ,        //内核把数据报文传送给网卡
        NET_RX_SOFTIRQ,        //内核从网卡接收数据报文
        BLOCK_SOFTIRQ,         //块设备的软中断
        BLOCK_IOPOLL_SOFTIRQ,  //支持IO轮询的块设备软中断
        TASKLET_SOFTIRQ,       //处理常规tasklet
        SCHED_SOFTIRQ,         //调度程序软中断
        HRTIMER_SOFTIRQ,       //高精度计时器软中断
        RCU_SOFTIRQ,           //RCU锁软中断，该软中断总是最后一个软中断
        NR_SOFTIRQS            //软中断最大值，用于判断其他中断不能大于等于它 
    };

(2) irq_cpustat_t
    多个软中断可以同时在多个cpu运行，就算是同一种软中断，也有可能同时在多个cpu上运行。内核为每个cpu都管理着一个待决软中断变量（pending），它就是irq_cpustat_t
    typedef struct {
        unsigned int __softirq_pending;
    } ____cacheline_aligned irq_cpustat_t;
    > irq_cpustat_t irq_stat[NR_CPUS] ____cacheline_aligned;
        内核使用local_softirq_pending()获取此CPU的__softirq_pending的值
    > __softirq_pending用于表示该CPU的哪个软中断处于挂起状态

(3) preempt_count
    该字段放在每个进程描述符的 thread_info 字段中
    preempt_count这个成员被用来判断当前进程是否可以被抢占。如果preempt_count不等于0（可能是代码调用preempt_disable显式的禁止了抢占，也可能是处于中断上下文等），说明当前不能进行抢占，如果preempt_count等于0，说明已经具备了抢占的条件
    0~7位	抢占计数器，记录显示禁用本地cpu内核抢占的次数，值为0时代表内核允许抢占。
    8~15位	软中断计数器。记录软中断被禁用的次数，0表示软中断被激活。
    16~27位	硬中断计数器。记录硬中断嵌套的层数。irq_entry()增加它的值，irq_exit()递减它的值。
    
(4) 注册软中断
    void open_softirq(int nr, void (*action)(struct softirq_action *)) {
        // softirq_vec是个struct softirq_action类型的数组
        softirq_vec[nr].action = action;
    }
    > nr(软中断类型)
    > action(软中断处理的函数指针)

(5) 触发软中断
    void raise_softirq(unsigned int nr) { //nr 被触发的中断类型
        unsigned long flags;

        local_irq_save(flags);      // 禁止中断，并保存当前状态
        raise_softirq_irqoff(nr);
        local_irq_restore(flags);
    }

(6) ksoftirqd(内核软中断守护线程)
    in_interrupt判断现在是否在中断上下文中，或者软中断是否被禁止，如果都不成立，则唤醒软中断的守护线程，在守护进程中执行软中断的回调函数
    inline void raise_softirq_irqoff(unsigned int nr) {
        ...
        //设定本CPU上的__softirq_pending的某个(nr)bit等于1
        __raise_softirq_irqoff(nr);
        
        if (!in_interrupt())
            wakeup_softirqd();  //wakeup_softirqd函数用来唤醒本CPU上的softirqd这个内核线程
        ...    
    }

(7) 下半部的控制
    主要维护preempt_count来实现的
    1) 禁止下半部
    void local_bh_disable(void) {
        struct thread_info *t = current_thread_info();
        t->preempt_count += SOFTIQR_OFFSET;
    }
    2) 激活下半部
    激活下半部后，然后会检查执行软中断，检查执行调度
    void local_bh_enable(void) {
        struct thread_info *t = current_thread_info();
        t->preempt_count -= SOFTIQR_OFFSET;
        
        //是否中断嵌套和软中断挂起
        if (unlikely(!in_interrupt() && local_softirq_pending())) {
            do_softirq();  //执行软中断
        }

        preempt_count_dec();
        //检查执行调度
        preempt_check_resched(); 
    }

(8) 执行软中断
    asmlinkage void do_softirq(void) {
        __u32 pending;
        unsigned long flags;

        //判断是否在中断处理中，如果正在中断处理，就直接返回
        if (in_interrupt())
            return;

        //保存当前寄存器的值
        local_irq_save(flags);

        //取得当前已注册软中断的位图
        //待处理软中断的32位位图，如果第n位设置为1，那么第n位对应的软中断等待处理
        pending = local_softirq_pending();

        //循环处理所有已注册的软中断
        if (pending) {
            struct softirq_action *h;

            //重置位图
            set_softirq_pending(0);
            h = softirq_vec;

            //循环32位
            do {
                if (pending & 1) 
                    h->action(h);
                h++;
                pending >>= 1;
            }while(pending);
        }

        //恢复寄存器的值到中断处理前
        local_irq_restore(flags);
    }

```

### 软中断处理流程

1、流程步骤
```
https://www.cnblogs.com/tolimit/p/4495128.html
http://blog.sae.sina.com.cn/archives/4103
https://blog.csdn.net/droidphone/article/details/7518428

(1) 硬中断执行完毕，调用irq_exit()
(2) irq_exit()中，检查该CPU是否处于嵌套中断的情况，以及是否有软中断挂起。如果没有中断嵌套(preempt_count==0)，并且有软中断挂起，那么执行软中断_do_softirq()
(3) 禁止软中断，防止软中断守护线程竞争
(3) 执行软中断，设置一个软中断执行最多使用时间和循环次数(10次)，并且激活中断。
(4) 进入循环，获取CPU的__softirq_pending的副本。
(5) 执行此__softirq_pending副本中所有需要执行的软中断。
(6) 软中断执行完毕，并且禁止中断。
(7) 如果还有软中断需要执行并且循环次数没达到10次，那么跳到第(3)步(在软中断期间又发生了中断，产生了新的软中断，新的软中断记录在CPU的__softirq_pending上，而我们的__softirq_pending只是个副本)。
(8) 检查此次软中断总共使用的时间和循环次数，条件允许继续执行软中断，循环次数减一，并跳转到第4步。
```
2、重要函数
```
(1) irq_exit(中断退出)
    void irq_exit() {

        //禁止中断    
        local_irq_disable();

        //减少preempt_count的硬中断计数器
        preempt_count_sub(HARDIRQ_OFFSET);
        
        //in_interrupt()会检查preempt_count上的软中断计数器和硬中断计数器来判断是否处于中断嵌套中
        //local_softirq_pending()则会检查该CPU的__softirq_pending变量，是否有软中断挂起
        if (!in_interrupt() && local_softirq_pending())
            invoke_softirq();  //激活_do_softirq()

        tick_irq_exit();
        rcu_irq_exit();
        trace_hardirq_exit(); /* must be last! */
    }

(2) __do_softirq
    asmlinkage void __do_softirq(void) {
        ......
        //首先取出pending的状态
        pending = local_softirq_pending();
        //禁止软中断，主要是为了防止和软中断守护进程发生竞争
        __local_bh_disable((unsigned long)__builtin_return_address(0), SOFTIRQ_OFFSET);
    restart:
        //清除所有的软中断待决标志
        set_softirq_pending(0);
        //打开(恢复)本地cpu中断，之后是可以被硬中断抢占
        local_irq_enable();

        h = softirq_vec;
        //循环执行待决软中断的回调函数
        do {
            if (pending & 1) {
                        ......
                trace_softirq_entry(vec_nr);
                h->action(h);
                trace_softirq_exit(vec_nr);
                            ......
            }
            h++;
            pending >>= 1;
        } while (pending);
        //禁止中断
        local_irq_disable();

        pending = local_softirq_pending();
        //有新的软中断挂起，并且小于循环次数MAX_SOFTIRQ_RESTART(30)，那么继续执行循环
        if (pending && --max_restart)
            goto restart;
        //如果达到最大循环数，则激活软中断守护进程，处理剩下的软中断
        //唤醒软中断线程去执行挂起的软中断，软中断线程是ksoftirqd，这里只起到一个通知作用   
        if (pending)
            wakeup_softirqd();

        lockdep_softirq_exit();
        //恢复软中断
        __local_bh_enable(SOFTIRQ_OFFSET);
    }

(3) run_ksoftirqd
    软中断处理线程
    ksoftirqd内核线程执行函数run_ksoftirqd()中调用__do_softirq()，一般由wake_up_process()唤醒
    //在smpboot_thread_fun的一个死循环中被调用
    static void run_ksoftirqd(unsigned int cpu) {
        //禁止中断，在__do_softirq()中会开启
        local_irq_disable();
        //检查该CPU的__softirq_pending是否有软中断被挂起
        if (local_softirq_pending()) {
            /*
            * We can safely run softirq on inline stack, as we are not deep
            * in the task stack here.
            */
            //执行软中断
            __do_softirq();
            rcu_note_context_switch(cpu);
            //开中断
            local_irq_enable();
            //检查是否需要调度
            cond_resched();
            return;
        }
        //开中断
        local_irq_enable();
    }
```

### tasklet结构与特性
```
//tasklet也是利用软中断来实现的，但是它提供了比软中断更好用的接口

//两个链表
    它建立在HI_SOFTIRQ和TASKLET_SOFTIRQ这两种软中断之上，多个tasklet可以与同一个软中断相关联，系统会使用一个链表组织他们，而每个tasklet执行自己的函数处理
    系统会为每个CPU维护两个链表，用于保存HI_SOFTIRQ的tasklet和TASKLET_SOFTIRQ的tasklet，这两个链表是tasklet_vec和tasklet_hi_vec，它们都是双向链表，如下：
    struct tasklet_head {
        struct tasklet_struct *head;
        struct tasklet_struct **tail;
    };
    static DEFINE_PER_CPU(struct tasklet_head, tasklet_vec);
    static DEFINE_PER_CPU(struct tasklet_head, tasklet_hi_vec);

//同一个tasklet，同一个cpu
    同一个tasklet不能同时在几个CPU上执行，一个tasklet在一个时间上只能在一个CPU的软中断链上，不能同时在多个CPU的软中断链上，并且当这个tasklet正在执行时，其他CPU不能够执行这个tasklet。也就是说，tasklet不必要编写成可重入的函数


//softirq_init
    会将每个CPU的tasklet_vec链表和tasklet_hi_vec链表进行初始化

(1) tasklet_struct
    struct tasklet_struct {
        struct tasklet_struct *next; /* 链表中的下一个tasklet */
        unsigned long state;         /* tasklet状态 */
        atomic_t count;              /* 引用计数器 */
        void (*func)(unsigned long); /* tasklet处理函数 */
        unsigned long data;          /* tasklet处理函数的参数 */
    };
    > state
        这两个状态主要就是用于防止tasklet同时在几个CPU上运行和在同一个CPU上交错执行
        > TASKLET_STATE_SCHED: 这种状态表示此tasklet处于某个tasklet链表之上
        > TASKLET_STATE_RUN: 表示此tasklet正在运行中

(2) SMP系统的tasklet
    1) 多cpu的问题
        在SMP系统中，我们会遇到一个问题：两个CPU都需要执行同一个tasklet的情况，虽然一个tasklet只能放在一个CPU的tasklet_vec链表或者tasklet_hi_vec链表上，但是这种情况是有可能发生的，我们设想一下，中断在CPU1上得到了响应，并且它的tasklet放到了CPU1的tasklet_vec上进行执行，而当中断的tasklet上正在执行时，此中断再次发生，并在CPU2上进行了响应，此时CPU2将此中断的tasklet放到CPU2的tasklet_vec上，并执行到此中断的tasklet。
    2) 解决方案
        > 关闭本地中断的前提下，移出当前cpu的待处理tasklet链表到一个临时链表后，清除当前cpu的tasklet链表，之所以这样处理，是为了处理当前tasklet链表的时候，允许新的tasklet被调度进待处理链表中。
        > 遍历临时链表，用tasklet_trylock判断当前tasklet是否已经在其他cpu上运行，而且tasklet没有被禁止：
            > 如果没有运行，也没有禁止，则清除TASKLET_STATE_SCHED状态位，执行tasklet的回调函数。
            > 如果已经在运行，或者被禁止，则把该tasklet重新添加会当前cpu的待处理tasklet链表上，然后触发TASKLET_SOFTIRQ软中断，等待下一次软中断时再次执行。
    3) tasklet_action
        static void tasklet_action(struct softirq_action *a) {
            struct tasklet_struct *list;

            local_irq_disable();
            
            //将tasklet链表从该CPU中拿出来
            list = __this_cpu_read(tasklet_vec.head);
            
            //将该CPU的此软中断的tasklet链表清空
            __this_cpu_write(tasklet_vec.head, NULL);
            __this_cpu_write(tasklet_vec.tail, this_cpu_ptr(&tasklet_vec.head));
            local_irq_enable();

            //链表已经处于list中，并且该CPU的tasklet_vec链表为空
            while (list) {
                struct tasklet_struct *t = list;

                list = list->next;

                //检查并设置该tasklet为TASKLET_STATE_RUN状态
                if (tasklet_trylock(t)) {
                    //检查是否被禁止
                    if (!atomic_read(&t->count)) {
                    
                        //清除其TASKLET_STATE_SCHED状态
                        if (!test_and_clear_bit(TASKLET_STATE_SCHED, &t->state))
                            BUG();
                    
                        //执行该tasklet的func处理函数
                        t->func(t->data);
                    
                        //清除该tasklet的TASKLET_STATE_RUN状态
                        tasklet_unlock(t);
                        continue;
                    }
                    tasklet_unlock(t);
                }

                //以下为tasklet为TASKLET_STATE_RUN状态下的处理
                //禁止中断
                local_irq_disable();
                
                //将此tasklet添加的该CPU的tasklet_vec链表尾部
                t->next = NULL;
                *__this_cpu_read(tasklet_vec.tail) = t;
                __this_cpu_write(tasklet_vec.tail, &(t->next));
                
                //设置该CPU的此软中断处于挂起状态，设置irq_cpustat_t的__sofirq_pending变量，这样在软中断的下次执行中会再次执行此tasklet
                __raise_softirq_irqoff(TASKLET_SOFTIRQ);
                
                //开启中断
                local_irq_enable();
            }
        }

```

### tasklet API
```
(1) 注册
    1) 静态
        #define DECLARE_TASKLET(name, func, data) \
        struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(0), func, data }

        #define DECLARE_TASKLET_DISABLED(name, func, data) \
        struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(1), func, data }

    2) 动态
        extern void tasklet_init(struct tasklet_struct *t, void (*func)(unsigned long), unsigned long data);

(2) 使能和禁止tasklet
    1) tasklet_disable()
        通过给count字段加1来禁止一个tasklet，如果tasklet正在运行中，则等待运行完毕才返回（通过TASKLET_STATE_RUN标志）。
    2) tasklet_disable_nosync()  
        tasklet_disable的异步版本，它不会等待tasklet运行完毕。
    3) tasklet_enable()
        使能tasklet，只是简单地给count字段减1。

(3) 调度tasklet
    tasklet_schedule(&my_tasklet)

(4) 销毁tasklet
    tasklet_kill(struct tasklet_struct *t)
    如果tasklet处于TASKLET_STATE_SCHED状态，或者tasklet正在执行，则会等待tasklet执行完毕，然后清除TASKLET_STATE_SCHED状态。

(5) 实例
    1) test.c
        #include <linux/interrupt.h>
        #include "kn_common.h"

        MODULE_LICENSE("Dual BSD/GPL");

        static void my_tasklet_func(unsigned long);

        /* mytasklet 必须定义在testtasklet_init函数的外面，否则会出错 */
        DECLARE_TASKLET(mytasklet, my_tasklet_func, 1000);

        static int testtasklet_init(void)
        {
            printk(KERN_ALERT "interrupt's top half!\n");

            // 如果在这里定义的话，那么 mytasklet是函数的局部变量，
            // 后面调度的时候会找不到 mytasklet
            // DECLARE_TASKLET(mytasklet, my_tasklet_func, 1000);

            // 调度tasklet， 处理器会在适当时候执行这个tasklet
            tasklet_schedule(&mytasklet);
            
            return 0;
            
        }

        static void testtasklet_exit(void)
        {
            printk(KERN_ALERT "*************************\n");
            print_current_time(0);
            printk(KERN_ALERT "testtasklet is exited!\n");
            printk(KERN_ALERT "*************************\n");
                
        }

        static void my_tasklet_func(unsigned long data)
        {
            printk(KERN_ALERT "=========================\n");
            print_current_time(0);
            printk(KERN_ALERT "my tasklet function is been called!....\n");
            printk(KERN_ALERT "parameter data is %ld\n", data);
            printk(KERN_ALERT "=========================\n");
        }


        module_init(testtasklet_init);
        module_exit(testtasklet_exit);

    2) makefile
        obj-m += mytasklet.o
        mytasklet-objs := testtasklet.o kn_common.o

        #generate the path
        CURRENT_PATH:=$(shell pwd)
        #the current kernel version number
        LINUX_KERNEL:=$(shell uname -r)
        #the absolute path
        LINUX_KERNEL_PATH:=/usr/src/kernels/$(LINUX_KERNEL)
        #complie object
        all:
            make -C $(LINUX_KERNEL_PATH) M=$(CURRENT_PATH) modules
            rm -rf modules.order Module.symvers .*.cmd *.o *.mod.c .tmp_versions *.unsigned
        #clean
        clean:
            rm -rf modules.order Module.symvers .*.cmd *.o *.mod.c *.ko .tmp_versions *.unsigned   

    3) 加载运行
        make
        insmod mytasklet.ko
        rmmod mytasklet
        dmesg | tail -10

        # 运行结果
        interrupt's top half!
        =========================
        2013-4-22 14:53:14
        my tasklet function is been called!....
        parameter data is 1000
        =========================
        *************************
        2013-4-22 14:53:20
        testtasklet is exited!
        *************************
```

### 工作队列
```
1、工作队列的特点
    > 工作队列和tasklet不一样，不是基于软中断来实现的
    > 在进程上下文中运行，工作函数可以休眠任意时间
    > 每创建一个工作队列，内核都会为其创建一个新的内核守护线程（软中断和tasklet只有一个）

2、工作队列的结构
    (1) workqueue_struct
        创建一个工作队列，就会创建一个内核工作线程
        struct workqueue_struct {
            struct cpu_workqueue_struct *cpu_wq; //工作者线程
            struct list_head list;
            const char *name;
            int singlethread;
            int freezeable;                      //Freeze threads during suspend
            int rt;
        #ifdef CONFIG_LOCKDEP
            struct lockdep_map lockdep_map;
        #endif
        };

    (2) cpu_workqueue_struct
        一个工作队列也是只能工作在一个CPU上面的，即每一个CPU都有一个工作队列。而cpu_workqueue_sruct就是描述该CPU的工作队列的结构体
        struct cpu_workqueue_struct {

            spinlock_t lock;                   //锁保护这种结构

            struct list_head worklist;         //工作队列头节点
            wait_queue_head_t more_work;
            struct work_struct *current_work;

            struct workqueue_struct *wq;       //关联工作队列结构
            struct task_struct *thread;        //关联线程
        } ____cacheline_aligned;

    (3) work_struct
        struct work_struct {
            atomic_long_t data;             //这个并不是处理函数的参数，而是表示此work是否pending等状态的flag
        #define WORK_STRUCT_PENDING 0       //T if work item pending execution
        #define WORK_STRUCT_FLAG_MASK (3UL)
        #define WORK_STRUCT_WQ_DATA_MASK (~WORK_STRUCT_FLAG_MASK)
            struct list_head entry;         //中断下半部处理函数的链表
            work_func_t func;               //处理中断下半部工作的函数
        #ifdef CONFIG_LOCKDEP
            struct lockdep_map lockdep_map;
        #endif
        };

        //工作队列处理函数的原型
        typedef void (*work_func_t)(struct work_struct *work);

    (4) schedule_work
        将一个新的work_struct加入我们的工作队列（这里的工作队列是已经被创建的系统工作队列）上    
        int schedule_work(struct work_struct *work) {
            return queue_work(system_wq, work); //将一个新的work_struct添加进workqueue队列
        }

3、工作队列的流程
    (1) 架构
                
        工作线程  
        +------------------------------------------------------------------------+
        |                  调用                                                  |      
        | worker_thread --------> run_workqueue                                  |      
        |                               ↓                                        |
        |        work_struct -> work_struct -> work_struct -> work_struct -> ... |
        +------------------------------------------------------------------------+
                                                                            ↑    加入新的work_struct      
                                                                        queue_work()

    (2) 创建工作队列(工作线程)
        1) 默认的工作线程(kevent)
            在Linux启动时创建，该线程被创建之后就处于sleep状态，当我们使用schedule_work函数时，才会唤醒该线程，当工作队列上的所有节点被执行完毕，该线程又会处于休眠状态
        2) 自定义工作队列(自己创建工作线程)
            指定的CPU上创建一个工作队列，例如采用create_singlethread_workqueue函数，就会在编号为第一个的CPU上创建内核线程和工作队列

    (3) 使用工作队列
        1) 创建
            > 静态创建一个work_struct 
                #define DECLARE_WORK(n, f)                    \
                    struct work_struct n = __WORK_INITIALIZER(n, f)
                > n
                    work_struct结构体，不用事先定义
                > f
                    下半部处理函数
            > 动态创建一个work_struct
                INIT_WORK(work, f);
                > work
                    work_struct指针
                > f
                    处理函数    

        2) 刷新现有的工作(这个步骤不是必须的)
            刷新现有工作的意思就是在追加新的工作之前，保证队列中的已有工作已经执行完了
            //刷新系统默认的队列，即 events 队列
            void flush_scheduled_work(void);

            //刷新用户自定义的队列, wq 用户自定义的队列
            void flush_workqueue(struct workqueue_struct *wq);

        3) 调度工作(调度新定义的工作，使之处于等待处理器执行的状态)
            //调度新定义的工作，在系统默认的工作者线程中执行此工作
            schedule_work(struct work_struct *work);
            > work
                第一步中定义的工作

            //调度新定义的工作，在用户自定义的工作者线程中执行此工作
            int queue_work(struct workqueue_struct *wq, struct work_struct *work);
            > wq
                用户自定义的工作队列类型
            > work
                第一步中定义的工作

    (4) 实例
        1) test.c
            #include <linux/workqueue.h>
            #include "kn_common.h"

            MODULE_LICENSE("Dual BSD/GPL");

            static void my_work_func(struct work_struct *);
            static void my_custom_workqueue_func(struct work_struct *);

            /* 静态创建一个工作，使用系统默认的工作者线程，即 events/n */
            DECLARE_WORK(mywork, my_work_func);

            static int testworkqueue_init(void)
            {
                /*自定义的workqueue */
                struct workqueue_struct *myworkqueue = create_workqueue("myworkqueue");

                /* 动态创建一个工作 */
                struct work_struct *mywork2;
                mywork2 = kmalloc(sizeof(struct work_struct), GFP_KERNEL);
                INIT_WORK(mywork2, my_custom_workqueue_func);
                            
                printk(KERN_ALERT "interrupt's top half!\n");

                /* 刷新系统默认的队列 */
                flush_scheduled_work();
                /* 调度工作 */
                schedule_work(&mywork);

                /* 刷新自定义的工作队列 */
                flush_workqueue(myworkqueue);
                /* 调度自定义工作队列上的工作 */
                queue_work(myworkqueue, mywork2);

                return 0;
            }

            static void testworkqueue_exit(void)
            {
                printk(KERN_ALERT "*************************\n");
                print_current_time(0);
                printk(KERN_ALERT "my workqueue test is exited!\n");
                printk(KERN_ALERT "*************************\n");
                    
            }

            static void my_work_func(struct work_struct *work)
            {
                printk(KERN_ALERT "=========================\n");
                print_current_time(0);
                printk(KERN_ALERT "my workqueue function is been called!....\n");
                printk(KERN_ALERT "=========================\n");
            }

            static void my_custom_workqueue_func(struct work_struct *work)
            {
                printk(KERN_ALERT "=========================\n");
                print_current_time(0);
                printk(KERN_ALERT "my cutomize workqueue function is been called!....\n");
                printk(KERN_ALERT "=========================\n");
                kfree(work);
            }

            module_init(testworkqueue_init);
            module_exit(testworkqueue_exit);

        2) makefile
            obj-m += myworkqueue.o
            myworkqueue-objs := testworkqueue.o kn_common.o

            #generate the path
            CURRENT_PATH:=$(shell pwd)
            #the current kernel version number
            LINUX_KERNEL:=$(shell uname -r)
            #the absolute path
            LINUX_KERNEL_PATH:=/usr/src/kernels/$(LINUX_KERNEL)
            #complie object
            all:
                make -C $(LINUX_KERNEL_PATH) M=$(CURRENT_PATH) modules
                rm -rf modules.order Module.symvers .*.cmd *.o *.mod.c .tmp_versions *.unsigned
            #clean
            clean:
                rm -rf modules.order Module.symvers .*.cmd *.o *.mod.c *.ko .tmp_versions *.unsigned

        3) 运行
            make
            insmod myworkqueue.ko
            rmmod myworkqueue
            dmesg | tail -13

            # 运行结果
            interrupt's top half!
            =========================
            2013-4-23 9:55:29
            my workqueue function is been called!....
            =========================
            =========================
            2013-4-23 9:55:29
            my cutomize workqueue function is been called!....
            =========================
            *************************
            2013-4-23 9:55:29
            my workqueue is exited!
            *************************        
```
