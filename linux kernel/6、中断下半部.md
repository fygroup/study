### 硬中断与软中断
```
[区别](https://blog.csdn.net/xuchenhuics/article/details/79120644)

硬中断是外部设备对CPU的中断，软中断是中断底半部的一种处理机制

> 中断控制器
    硬中断的中断号是由中断控制器提供的
    软中断的中断号由指令直接给出，无需使用中断控制器。

> 屏蔽
    硬中断是可屏蔽的,软中断不可屏蔽

> 嵌套
    Linux下硬中断是可以嵌套的，但是没有优先级的概念，也就是说任何一个新的中断都可以打断正在执行的中断，但同种中断除外。
    软中断不能嵌套，但相同类型的软中断可以在不同CPU上并行执行

> 抢占
    硬中断可以被另一个优先级比自己高的硬中断“中断”，不能被同级（同一种硬中断）或低级的硬中断“中断”，更不能被软中断“中断”。
    软中断可以被硬中断“中断”，但是不会被另一个软中断“中断”。在一个CPU上，软中断总是串行执行。所以在单处理器上，对软中断的数据结构进行访问不需要加任何同步原语。    
    软中断可以被抢占，但是不会睡眠(不会放进睡眠队列)，所以不能在软中断中使用信号量和阻塞
```

### 软中断与信号
```
https://www.cnblogs.com/charlesblc/p/6277810.html
```

### 软中断相关概念
```
(1) 哪些处理放在下半部
    如果一个任务对时间十分敏感，将其放在上半部
    如果一个任务和硬件有关，将其放在上半部
    如果一个任务要保证不被其他中断打断，将其放在上半部
    其他所有任务，考虑放在下半部

(2) 流程
                        中断退出
        +------------> irq_exit --------------+  
        ↑                                     ↓
    注册软中断         触发软中断          执行软中断                             否  
    open_softirq ---> raise_softirq ---> do_softirq ---> 是否有未执行的中断函数 ---> 结束本次中断
                                            ↑                          ↓ 是  
                                            +-------执行相应中断函数<---+

(3) 软中断、tasklet、工作队列
    #下半部机制   上下文    复杂度                           性能   顺序执行保障                能否睡眠 工作场景
    软中断        中断     高(确保软中断的执行顺序和锁机制)    好     没有                       不能     中断上下文   
    tasklet       中断     中(提供接口使用软中断)             中     同类型不能(不会)同时执行    不能     中断上下文  
    工作队列      进程     低(在进程上下文运行，类似用户程序)  差     没有(和进程上下文一样被调度) 可以     进程上下文

    > 软中断的分配时静态的(即在编译时定义)，而tasklet的分配和初始化能够在执行时进行。
    > 软中断的并行
        > 软中断(即便是同一种类型的软中断)能够并发地运行在多个CPU上。因此，软中断是可重入函数并且必须明白地使用自旋锁保护其数据结构。
    > tasklet的并行
        > tasklet不必操心这些问题。由于内核对tasklet的运行进行了更加严格的控制。同样类型的tasklet总是被串行运行。
        > 换句话说就是：不可能存在在两个CPU上同一时候执行同样类型的tasklet。可是，类型不同的tasklet能够在几个CPU上并发执行。
        > tasklet的串行化使tasklet函数不必是可重入的

https://blog.csdn.net/vividonly/article/details/6609053
http://blog.sae.sina.com.cn/archives/4103
https://www.cnblogs.com/tolimit/p/4495128.html
https://blog.csdn.net/droidphone/article/details/7518428
http://www.wowotech.net/irq_subsystem/soft-irq.html

```

### 软中断涉及的结构与函数
```
(1) softirq_action
    //数组元素为 softirq_action,一个元素代码一个软中断。不同的软中断号对应不同的数组的下标
    static struct softirq_action softirq_vec[32]__cacheline_aligned_in_smp;
    
    struct softirq_action {
        //软中断发生时执行软中断的处理函数
        void (*action)(struct softirq_action *); 
        //软中断的处理函数的参数指针
        void *data;
    }

    //软中断类型
    enum {
        HI_SOFTIRQ=0,          //处理高优先级的tasklet
        TIMER_SOFTIRQ,         //时钟中断相关的tasklet
        NET_TX_SOFTIRQ,        //内核把数据报文传送给网卡
        NET_RX_SOFTIRQ,        //内核从网卡接收数据报文
        BLOCK_SOFTIRQ,         //块设备的软中断
        BLOCK_IOPOLL_SOFTIRQ,  //支持IO轮询的块设备软中断
        TASKLET_SOFTIRQ,       //处理常规tasklet
        SCHED_SOFTIRQ,         //调度程序软中断
        HRTIMER_SOFTIRQ,       //高精度计时器软中断
        RCU_SOFTIRQ,           //RCU锁软中断，该软中断总是最后一个软中断
        NR_SOFTIRQS
    };

(2) irq_cpustat_t
    多个软中断可以同时在多个cpu运行，就算是同一种软中断，也有可能同时在多个cpu上运行。内核为每个cpu都管理着一个待决软中断变量（pending），它就是irq_cpustat_t
    typedef struct {
        unsigned int __softirq_pending;
    } ____cacheline_aligned irq_cpustat_t;
    > irq_cpustat_t irq_stat[NR_CPUS] ____cacheline_aligned;
        内核使用local_softirq_pending()获取此CPU的__softirq_pending的值
    > __softirq_pending用于表示该CPU的哪个软中断处于挂起状态

(3) preempt_count
    该字段放在每个进程描述符的 thread_info 字段中
    preempt_count这个成员被用来判断当前进程是否可以被抢占。如果preempt_count不等于0（可能是代码调用preempt_disable显式的禁止了抢占，也可能是处于中断上下文等），说明当前不能进行抢占，如果preempt_count等于0，说明已经具备了抢占的条件
    0~7位	抢占计数器，记录显示禁用本地cpu内核抢占的次数，值为0时代表内核允许抢占。
    8~15位	软中断计数器。记录软中断被禁用的次数，0表示软中断被激活。
    16~27位	硬中断计数器。记录硬中断嵌套的层数。irq_entry()增加它的值，irq_exit()递减它的值。
    
(4) 注册软中断
    void open_softirq(int nr, void (*action)(struct softirq_action *)) {
        // softirq_vec是个struct softirq_action类型的数组
        softirq_vec[nr].action = action;
    }
    > nr(软中断类型)
    > action(软中断处理的函数指针)

(5) 触发软中断
    void raise_softirq(unsigned int nr) { //nr 被触发的中断类型
        unsigned long flags;

        local_irq_save(flags);
        raise_softirq_irqoff(nr);
        local_irq_restore(flags);
    }

(6) ksoftirqd(内核软中断守护线程)
    in_interrupt判断现在是否在中断上下文中，或者软中断是否被禁止，如果都不成立，则唤醒软中断的守护进程，在守护进程中执行软中断的回调函数
    inline void raise_softirq_irqoff(unsigned int nr) {
        ...
        if (!in_interrupt())
            wakeup_softirqd();
        ...    
    }

(7) 下半部的控制
    主要维护preempt_count来实现的
    1) 禁止下半部
    void local_bh_disable(void) {
        struct thread_info *t = current_thread_info();
        t->preempt_count += SOFTIQR_OFFSET;
    }
    2) 激活下半部
    激活下半部后，然后会检查执行软中断，检查执行调度
    void local_bh_enable(void) {
        struct thread_info *t = current_thread_info();
        t->preempt_count -= SOFTIQR_OFFSET;
        
        //是否中断嵌套和软中断挂起
        if (unlikely(!in_interrupt() && local_softirq_pending())) {
            do_softirq();  //执行软中断
        }

        preempt_count_dec();
        //检查执行调度
        preempt_check_resched(); 
    }

(8) 执行软中断
    asmlinkage void do_softirq(void) {
        __u32 pending;
        unsigned long flags;

        //判断是否在中断处理中，如果正在中断处理，就直接返回
        if (in_interrupt())
            return;

        //保存当前寄存器的值
        local_irq_save(flags);

        //取得当前已注册软中断的位图
        //待处理软中断的32位位图，如果第n位设置为1，那么第n位对应的软中断等待处理
        pending = local_softirq_pending();

        //循环处理所有已注册的软中断
        if (pending) {
            struct softirq_action *h;

            //重置位图
            set_softirq_pending(0);
            h = softirq_vec;

            //循环32位
            do {
                if (pending & 1) 
                    h->action(h);
                h++;
                pending >>= 1;
            }while(pending);
        }

        //恢复寄存器的值到中断处理前
        local_irq_restore(flags);
    }

```

### 软中断处理流程
https://www.cnblogs.com/tolimit/p/4495128.html
http://blog.sae.sina.com.cn/archives/4103
https://blog.csdn.net/droidphone/article/details/7518428

1、流程步骤
```
(1) 硬中断执行完毕，调用irq_exit()
(2) irq_exit()中，检查该CPU是否处于嵌套中断的情况，以及是否有软中断挂起。如果没有中断嵌套(preempt_count==0)，并且有软中断挂起，那么执行软中断_do_softirq()
(3) 禁止软中断，防止软中断线程
(3) 执行软中断，设置一个软中断执行最多使用时间和循环次数(10次)，并且激活中断。
(4) 进入循环，获取CPU的__softirq_pending的副本。
(5) 执行此__softirq_pending副本中所有需要执行的软中断。
(6) 软中断执行完毕，并且禁止中断。
(7) 如果还有软中断需要执行并且循环次数没达到10次，那么跳到第(3)步(在软中断期间又发生了中断，产生了新的软中断，新的软中断记录在CPU的__softirq_pending上，而我们的__softirq_pending只是个副本)。
(8) 检查此次软中断总共使用的时间和循环次数，条件允许继续执行软中断，循环次数减一，并跳转到第4步。
```
2、重要函数
```
(1) irq_exit(中断退出)
    void irq_exit() {

        //禁止中断    
        local_irq_disable();

        //减少preempt_count的硬中断计数器
        preempt_count_sub(HARDIRQ_OFFSET);
        
        //in_interrupt()会检查preempt_count上的软中断计数器和硬中断计数器来判断是否处于中断嵌套中
        //local_softirq_pending()则会检查该CPU的__softirq_pending变量，是否有软中断挂起
        if (!in_interrupt() && local_softirq_pending())
            invoke_softirq();  //激活_do_softirq()

        tick_irq_exit();
        rcu_irq_exit();
        trace_hardirq_exit(); /* must be last! */
    }

(2) __do_softirq
    asmlinkage void __do_softirq(void) {
        ......
        //首先取出pending的状态
        pending = local_softirq_pending();
        //禁止软中断，主要是为了防止和软中断守护进程发生竞争
        __local_bh_disable((unsigned long)__builtin_return_address(0), SOFTIRQ_OFFSET);
    restart:
        //清除所有的软中断待决标志
        set_softirq_pending(0);
        //打开(恢复)本地cpu中断，之后是可以被硬中断抢占
        local_irq_enable();

        h = softirq_vec;
        //循环执行待决软中断的回调函数
        do {
            if (pending & 1) {
                        ......
                trace_softirq_entry(vec_nr);
                h->action(h);
                trace_softirq_exit(vec_nr);
                            ......
            }
            h++;
            pending >>= 1;
        } while (pending);
        //禁止中断
        local_irq_disable();

        pending = local_softirq_pending();
        //有新的软中断挂起，并且小于循环次数MAX_SOFTIRQ_RESTART(30)，那么继续执行循环
        if (pending && --max_restart)
            goto restart;
        //如果达到最大循环数，则激活软中断守护进程，处理剩下的软中断
        //唤醒软中断线程去执行挂起的软中断，软中断线程是ksoftirqd，这里只起到一个通知作用   
        if (pending)
            wakeup_softirqd();

        lockdep_softirq_exit();
        //恢复软中断
        __local_bh_enable(SOFTIRQ_OFFSET);
    }

(3) run_ksoftirqd
    软中断处理线程
    //在smpboot_thread_fun的一个死循环中被调用
    static void run_ksoftirqd(unsigned int cpu) {
        //禁止中断，在__do_softirq()中会开启
        local_irq_disable();
        //检查该CPU的__softirq_pending是否有软中断被挂起
        if (local_softirq_pending()) {
            /*
            * We can safely run softirq on inline stack, as we are not deep
            * in the task stack here.
            */
            //执行软中断
            __do_softirq();
            rcu_note_context_switch(cpu);
            //开中断
            local_irq_enable();
            //检查是否需要调度
            cond_resched();
            return;
        }
        //开中断
        local_irq_enable();
    }
```

### tasklet结构与特性
```
//tasklet也是利用软中断来实现的，但是它提供了比软中断更好用的接口

//两个链表
    它建立在HI_SOFTIRQ和TASKLET_SOFTIRQ这两种软中断之上，多个tasklet可以与同一个软中断相关联，系统会使用一个链表组织他们，而每个tasklet执行自己的函数处理
    系统会为每个CPU维护两个链表，用于保存HI_SOFTIRQ的tasklet和TASKLET_SOFTIRQ的tasklet，这两个链表是tasklet_vec和tasklet_hi_vec，它们都是双向链表，如下：
    struct tasklet_head {
        struct tasklet_struct *head;
        struct tasklet_struct **tail;
    };
    static DEFINE_PER_CPU(struct tasklet_head, tasklet_vec);
    static DEFINE_PER_CPU(struct tasklet_head, tasklet_hi_vec);

//同一个tasklet，同一个cpu
    同一个tasklet不能同时在几个CPU上执行，一个tasklet在一个时间上只能在一个CPU的软中断链上，不能同时在多个CPU的软中断链上，并且当这个tasklet正在执行时，其他CPU不能够执行这个tasklet。也就是说，tasklet不必要编写成可重入的函数

//softirq_init
    会将每个CPU的tasklet_vec链表和tasklet_hi_vec链表进行初始化

(1) tasklet_struct
    struct tasklet_struct {
        struct tasklet_struct *next; /* 链表中的下一个tasklet */
        unsigned long state;         /* tasklet状态 */
        atomic_t count;              /* 引用计数器 */
        void (*func)(unsigned long); /* tasklet处理函数 */
        unsigned long data;          /* tasklet处理函数的参数 */
    };
    > state
        这两个状态主要就是用于防止tasklet同时在几个CPU上运行和在同一个CPU上交错执行
        > TASKLET_STATE_SCHED: 这种状态表示此tasklet处于某个tasklet链表之上
        > TASKLET_STATE_RUN: 表示此tasklet正在运行中

(2) SMP系统的tasklet
    1) 多cpu的问题
        在SMP系统中，我们会遇到一个问题：两个CPU都需要执行同一个tasklet的情况，虽然一个tasklet只能放在一个CPU的tasklet_vec链表或者tasklet_hi_vec链表上，但是这种情况是有可能发生的，我们设想一下，中断在CPU1上得到了响应，并且它的tasklet放到了CPU1的tasklet_vec上进行执行，而当中断的tasklet上正在执行时，此中断再次发生，并在CPU2上进行了响应，此时CPU2将此中断的tasklet放到CPU2的tasklet_vec上，并执行到此中断的tasklet。
    2) 解决方案
        > 关闭本地中断的前提下，移出当前cpu的待处理tasklet链表到一个临时链表后，清除当前cpu的tasklet链表，之所以这样处理，是为了处理当前tasklet链表的时候，允许新的tasklet被调度进待处理链表中。
        > 遍历临时链表，用tasklet_trylock判断当前tasklet是否已经在其他cpu上运行，而且tasklet没有被禁止：
            > 如果没有运行，也没有禁止，则清除TASKLET_STATE_SCHED状态位，执行tasklet的回调函数。
            > 如果已经在运行，或者被禁止，则把该tasklet重新添加会当前cpu的待处理tasklet链表上，然后触发TASKLET_SOFTIRQ软中断，等待下一次软中断时再次执行。
    3) tasklet_action
        static void tasklet_action(struct softirq_action *a) {
            struct tasklet_struct *list;

            local_irq_disable();
            
            //将tasklet链表从该CPU中拿出来
            list = __this_cpu_read(tasklet_vec.head);
            
            //将该CPU的此软中断的tasklet链表清空
            __this_cpu_write(tasklet_vec.head, NULL);
            __this_cpu_write(tasklet_vec.tail, this_cpu_ptr(&tasklet_vec.head));
            local_irq_enable();

            //链表已经处于list中，并且该CPU的tasklet_vec链表为空
            while (list) {
                struct tasklet_struct *t = list;

                list = list->next;

                //检查并设置该tasklet为TASKLET_STATE_RUN状态
                if (tasklet_trylock(t)) {
                    //检查是否被禁止
                    if (!atomic_read(&t->count)) {
                    
                        //清除其TASKLET_STATE_SCHED状态
                        if (!test_and_clear_bit(TASKLET_STATE_SCHED, &t->state))
                            BUG();
                    
                        //执行该tasklet的func处理函数
                        t->func(t->data);
                    
                        //清除该tasklet的TASKLET_STATE_RUN状态
                        tasklet_unlock(t);
                        continue;
                    }
                    tasklet_unlock(t);
                }

                //以下为tasklet为TASKLET_STATE_RUN状态下的处理
                //禁止中断
                local_irq_disable();
                
                //将此tasklet添加的该CPU的tasklet_vec链表尾部
                t->next = NULL;
                *__this_cpu_read(tasklet_vec.tail) = t;
                __this_cpu_write(tasklet_vec.tail, &(t->next));
                
                //设置该CPU的此软中断处于挂起状态，设置irq_cpustat_t的__sofirq_pending变量，这样在软中断的下次执行中会再次执行此tasklet
                __raise_softirq_irqoff(TASKLET_SOFTIRQ);
                
                //开启中断
                local_irq_enable();
            }
        }

```

### tasklet API
```
(1) 注册
    1) 静态
        #define DECLARE_TASKLET(name, func, data) \
        struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(0), func, data }

        #define DECLARE_TASKLET_DISABLED(name, func, data) \
        struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(1), func, data }

    2) 动态
        extern void tasklet_init(struct tasklet_struct *t, void (*func)(unsigned long), unsigned long data);

(2) 使能和禁止tasklet
    1) tasklet_disable()
        通过给count字段加1来禁止一个tasklet，如果tasklet正在运行中，则等待运行完毕才返回（通过TASKLET_STATE_RUN标志）。
    2) tasklet_disable_nosync()  
        tasklet_disable的异步版本，它不会等待tasklet运行完毕。
    3) tasklet_enable()
        使能tasklet，只是简单地给count字段减1。

(3) 调度tasklet
    tasklet_schedule(&my_tasklet)

(4) 销毁tasklet
    tasklet_kill(struct tasklet_struct *t)
    如果tasklet处于TASKLET_STATE_SCHED状态，或者tasklet正在执行，则会等待tasklet执行完毕，然后清除TASKLET_STATE_SCHED状态。

(5) 实例
    1) test.c
        #include <linux/interrupt.h>
        #include "kn_common.h"

        MODULE_LICENSE("Dual BSD/GPL");

        static void my_tasklet_func(unsigned long);

        /* mytasklet 必须定义在testtasklet_init函数的外面，否则会出错 */
        DECLARE_TASKLET(mytasklet, my_tasklet_func, 1000);

        static int testtasklet_init(void)
        {
            printk(KERN_ALERT "interrupt's top half!\n");

            // 如果在这里定义的话，那么 mytasklet是函数的局部变量，
            // 后面调度的时候会找不到 mytasklet
            // DECLARE_TASKLET(mytasklet, my_tasklet_func, 1000);

            // 调度tasklet， 处理器会在适当时候执行这个tasklet
            tasklet_schedule(&mytasklet);
            
            return 0;
            
        }

        static void testtasklet_exit(void)
        {
            printk(KERN_ALERT "*************************\n");
            print_current_time(0);
            printk(KERN_ALERT "testtasklet is exited!\n");
            printk(KERN_ALERT "*************************\n");
                
        }

        static void my_tasklet_func(unsigned long data)
        {
            printk(KERN_ALERT "=========================\n");
            print_current_time(0);
            printk(KERN_ALERT "my tasklet function is been called!....\n");
            printk(KERN_ALERT "parameter data is %ld\n", data);
            printk(KERN_ALERT "=========================\n");
        }


        module_init(testtasklet_init);
        module_exit(testtasklet_exit);

    2) makefile
        obj-m += mytasklet.o
        mytasklet-objs := testtasklet.o kn_common.o

        #generate the path
        CURRENT_PATH:=$(shell pwd)
        #the current kernel version number
        LINUX_KERNEL:=$(shell uname -r)
        #the absolute path
        LINUX_KERNEL_PATH:=/usr/src/kernels/$(LINUX_KERNEL)
        #complie object
        all:
            make -C $(LINUX_KERNEL_PATH) M=$(CURRENT_PATH) modules
            rm -rf modules.order Module.symvers .*.cmd *.o *.mod.c .tmp_versions *.unsigned
        #clean
        clean:
            rm -rf modules.order Module.symvers .*.cmd *.o *.mod.c *.ko .tmp_versions *.unsigned   

    3) 加载运行
        make
        insmod mytasklet.ko
        rmmod mytasklet
        dmesg | tail -10

        # 运行结果
        interrupt's top half!
        =========================
        2013-4-22 14:53:14
        my tasklet function is been called!....
        parameter data is 1000
        =========================
        *************************
        2013-4-22 14:53:20
        testtasklet is exited!
        *************************
```

### 工作队列的特点
```
工作队列和tasklet不一样，不是基于软中断来实现的

在进程上下文中运行，工作函数可以休眠任意时间

每创建一个工作队列，内核都会为其创建一个新的内核守护线程（软中断和tasklet只有一个）

```

### 工作队列的结构
```
(1) workqueue_struct
    创建一个工作队列，就会创建一个内核工作线程
    struct workqueue_struct {
        struct cpu_workqueue_struct *cpu_wq; //工作者线程
        struct list_head list;
        const char *name;
        int singlethread;
        int freezeable;                      //Freeze threads during suspend
        int rt;
    #ifdef CONFIG_LOCKDEP
        struct lockdep_map lockdep_map;
    #endif
    };

(2) cpu_workqueue_struct
    一个工作队列也是只能工作在一个CPU上面的，即每一个CPU都有一个工作队列。而cpu_workqueue_sruct就是描述该CPU的工作队列的结构体
    struct cpu_workqueue_struct {

        spinlock_t lock;                   //锁保护这种结构

        struct list_head worklist;         //工作队列头节点
        wait_queue_head_t more_work;
        struct work_struct *current_work;

        struct workqueue_struct *wq;       //关联工作队列结构
        struct task_struct *thread;        //关联线程
    } ____cacheline_aligned;

(3) work_struct
    struct work_struct {
        atomic_long_t data;             //这个并不是处理函数的参数，而是表示此work是否pending等状态的flag
    #define WORK_STRUCT_PENDING 0       //T if work item pending execution
    #define WORK_STRUCT_FLAG_MASK (3UL)
    #define WORK_STRUCT_WQ_DATA_MASK (~WORK_STRUCT_FLAG_MASK)
        struct list_head entry;         //中断下半部处理函数的链表
        work_func_t func;               //处理中断下半部工作的函数
    #ifdef CONFIG_LOCKDEP
        struct lockdep_map lockdep_map;
    #endif
    };

    //工作队列处理函数的原型
    typedef void (*work_func_t)(struct work_struct *work);

(4) schedule_work
    将一个新的work_struct加入我们的工作队列（这里的工作队列是已经被创建的系统工作队列）上    
    int schedule_work(struct work_struct *work) {
        return queue_work(system_wq, work); //将一个新的work_struct添加进workqueue队列
    }

```

### 工作队列的流程
```
(1) 架构
            
    工作线程  
    +------------------------------------------------------------------------+
    |                  调用                                                  |      
    | worker_thread --------> run_workqueue                                  |      
    |                               ↓                                        |
    |        work_struct -> work_struct -> work_struct -> work_struct -> ... |
    +------------------------------------------------------------------------+
                                                                        ↑    加入新的work_struct      
                                                                     queue_work()

(1) 创建工作队列(工作线程)
    1) 默认的工作线程(kevent)
        在Linux启动时创建，该线程被创建之后就处于sleep状态，当我们使用schedule_work函数时，才会唤醒该线程，当工作队列上的所有节点被执行完毕，该线程又会处于休眠状态
    2) 自定义工作队列(自己创建工作线程)
        指定的CPU上创建一个工作队列，例如采用create_singlethread_workqueue函数，就会在编号为第一个的CPU上创建内核线程和工作队列

(2) 使用工作队列
    1) 创建
        > 静态创建一个work_struct 
            #define DECLARE_WORK(n, f)                    \
                struct work_struct n = __WORK_INITIALIZER(n, f)
            > n
                work_struct结构体，不用事先定义
            > f
                下半部处理函数
        > 动态创建一个work_struct
            INIT_WORK(work, f);
            > work
                work_struct指针
            > f
                处理函数    

    2) 刷新现有的工作(这个步骤不是必须的)
        刷新现有工作的意思就是在追加新的工作之前，保证队列中的已有工作已经执行完了
        //刷新系统默认的队列，即 events 队列
        void flush_scheduled_work(void);

        //刷新用户自定义的队列, wq 用户自定义的队列
        void flush_workqueue(struct workqueue_struct *wq);

    3) 调度工作(调度新定义的工作，使之处于等待处理器执行的状态)
        //调度新定义的工作，在系统默认的工作者线程中执行此工作
        schedule_work(struct work_struct *work);
        > work
            第一步中定义的工作

        //调度新定义的工作，在用户自定义的工作者线程中执行此工作
        int queue_work(struct workqueue_struct *wq, struct work_struct *work);
        > wq
            用户自定义的工作队列类型
        > work
            第一步中定义的工作

(3) 实例
    1) test.c
        #include <linux/workqueue.h>
        #include "kn_common.h"

        MODULE_LICENSE("Dual BSD/GPL");

        static void my_work_func(struct work_struct *);
        static void my_custom_workqueue_func(struct work_struct *);

        /* 静态创建一个工作，使用系统默认的工作者线程，即 events/n */
        DECLARE_WORK(mywork, my_work_func);

        static int testworkqueue_init(void)
        {
            /*自定义的workqueue */
            struct workqueue_struct *myworkqueue = create_workqueue("myworkqueue");

            /* 动态创建一个工作 */
            struct work_struct *mywork2;
            mywork2 = kmalloc(sizeof(struct work_struct), GFP_KERNEL);
            INIT_WORK(mywork2, my_custom_workqueue_func);
                        
            printk(KERN_ALERT "interrupt's top half!\n");

            /* 刷新系统默认的队列 */
            flush_scheduled_work();
            /* 调度工作 */
            schedule_work(&mywork);

            /* 刷新自定义的工作队列 */
            flush_workqueue(myworkqueue);
            /* 调度自定义工作队列上的工作 */
            queue_work(myworkqueue, mywork2);

            return 0;
        }

        static void testworkqueue_exit(void)
        {
            printk(KERN_ALERT "*************************\n");
            print_current_time(0);
            printk(KERN_ALERT "my workqueue test is exited!\n");
            printk(KERN_ALERT "*************************\n");
                
        }

        static void my_work_func(struct work_struct *work)
        {
            printk(KERN_ALERT "=========================\n");
            print_current_time(0);
            printk(KERN_ALERT "my workqueue function is been called!....\n");
            printk(KERN_ALERT "=========================\n");
        }

        static void my_custom_workqueue_func(struct work_struct *work)
        {
            printk(KERN_ALERT "=========================\n");
            print_current_time(0);
            printk(KERN_ALERT "my cutomize workqueue function is been called!....\n");
            printk(KERN_ALERT "=========================\n");
            kfree(work);
        }

        module_init(testworkqueue_init);
        module_exit(testworkqueue_exit);

    2) makefile
        obj-m += myworkqueue.o
        myworkqueue-objs := testworkqueue.o kn_common.o

        #generate the path
        CURRENT_PATH:=$(shell pwd)
        #the current kernel version number
        LINUX_KERNEL:=$(shell uname -r)
        #the absolute path
        LINUX_KERNEL_PATH:=/usr/src/kernels/$(LINUX_KERNEL)
        #complie object
        all:
            make -C $(LINUX_KERNEL_PATH) M=$(CURRENT_PATH) modules
            rm -rf modules.order Module.symvers .*.cmd *.o *.mod.c .tmp_versions *.unsigned
        #clean
        clean:
            rm -rf modules.order Module.symvers .*.cmd *.o *.mod.c *.ko .tmp_versions *.unsigned

    3) 运行
        make
        insmod myworkqueue.ko
        rmmod myworkqueue
        dmesg | tail -13

        # 运行结果
        interrupt's top half!
        =========================
        2013-4-23 9:55:29
        my workqueue function is been called!....
        =========================
        =========================
        2013-4-23 9:55:29
        my cutomize workqueue function is been called!....
        =========================
        *************************
        2013-4-23 9:55:29
        my workqueue is exited!
        *************************        
```
