### 造成并发的原因
```
(1) 中断
(2) 软中断和tasklet
(3) 内核抢占
(4) 睡眠与用户空间同步
(5) 对称多处理
```

### 编写内核并发需要注意的问题
```
(1) 这个数据是不是全局的？除了当前线程外，其他线程能不能访问它？
(2) 这个数据会不会在进程上下文和中断上下文中共享？他是不是要在两个不同的中断处理程序中共享？
(3) 进程访问数据时可不可以被抢占？被调度的新程序会不会访问同一数据？
(4) 当前进程会不会阻塞或睡眠在某些资源上？如果是，它会让共享资源出于何种状态？
(5) 如果这个函数在另一个处理器上被调度会发生什么？
```

### LOCK指令
```
软件级别的原子操作是依赖于硬件支持的

现代CPU无法保证一条指令是原子的

在x86体系中, CPU提供了HLOCK pin引线, 允许CPU在执行某一个指令(仅仅是一个指令)时拉低HLOCK pin引线的电位, 直到这个指令执行完毕才放开, 从而锁住了总线, 如此在同一总线的CPU就暂时无法通过总线访问内存了, 这样就保证了多核处理器的原子性
```

### 原子操作
```
X86原子性操作可以简单划分为
(1) 读写操作
    原子load(读)、原子store(写)
    UP(单核系统)和SMP(多核系统)的原子读、写都是原子性的
(2) 读改写操作
    Read-Modify-Write RMW
    SMP系统中需要LOCK指令锁总线的帮助才能实现RMW的原子性
    static __always_inline void arch_atomic_add(int i, atomic_t *v)
    {
        asm volatile(LOCK_PREFIX "addl %1,%0"
                : "+m" (v->counter)  // input+output
                : "ir" (i));  // input
    }

(3) 比较交换操作
    Compare-And-Swap CAS
    现代cpu提供了cmpxchg指令
    asm volatile(LOCK_PREFIX "cmpxchgb %b1,%2"
                     : "=a"(prev)
                     : "q"(new), "m"(*__xg(ptr)), "0"(old)
                     : "memory");
```

### linux同步原语
```
https://www.zhihu.com/question/66733477/answer/246635823
https://www.zhihu.com/question/58047327/answer/155607124
https://www.cnblogs.com/wang_yb/archive/2013/05/01/3052865.html

(1) 原子操作(atomic)
    linux系统最基础的原子操作
    提供了2类接口
        原子整数操作，有32位和64位，头文件分别为<asm/atomic.h>和<asm/atomic64.h>
        原子位操作，头文件 <asm/bitops.h>

(2) 自旋锁(spinlock)
    原子操作只能用于临界区只有一个变量的情况，实际应用中，临界区的情况要复杂的多
    自旋锁由linux内核提供
    1) 特点
        > 当一个线程获取了锁之后，其他试图获取这个锁的线程一直在循环等待获取这个锁，直至锁重新可用。
        > 由于线程处于一直循环的获取这个锁的状态中，所以会造成CPU处理时间的浪费，因此最好将自旋锁用于能很快处理完的临界区。
        > 自旋锁与中断
            > 禁止中断
                线程获取自旋锁之前，要禁止当前处理器上的中断（防止获取锁的线程和中断形成竞争条件）❗
                比如：当前线程获取自旋锁后，在临界区中被中断处理程序打断，中断处理程序正好也要获取这个锁，于是中断处理程序会等待当前线程释放锁，而当前线程也在等待中断执行完后再执行临界区和释放锁的代码。
            > 禁止中断下半部
                下半部处理和进程上下文共享数据时，由于下半部的处理可以抢占进程上下文的代码，所以进程上下文在对共享数据加锁前要禁止下半部的执行，解锁时再允许下半部的执行。
            > 禁止中断上半部
                中断处理程序（上半部）和下半部处理共享数据时，由于中断处理（上半部）可以抢占下半部的执行，所以下半部在对共享数据加锁前要禁止中断处理（上半部），解锁时再允许中断的执行。
            > tasklet
                同一种tasklet不可能同时运行，所以同类tasklet中的共享数据不需要保护。
                不同类tasklet中共享数据时，需要自旋锁。其中一个tasklet获得锁后，不用禁止其他tasklet的执行，因为同一个处理器上不会有tasklet相互抢占的情况
                同类型或者非同类型的软中断在共享数据时，也不用禁止下半部，因为同一个处理器上不会有软中断互相抢占的情况
        > 自旋锁与抢占
            自旋锁自带禁止内核抢占
        > 死锁
            > 不能递归
                递归的请求同一个自旋锁会自己锁死自己
            > 不能阻塞(内部不能进行上下文切换)
                如果进程获得自旋锁之后再阻塞，那么你的CPU已经拥有了该锁，那么用于释放锁的代码将得不到运行，可能导致死锁的发生
            > 只能由系统内核调用
                自旋锁一定是由系统内核调用的。不可能在用户程序中由用户请求自旋锁。当一个用户进程拥有自旋锁期间，内核是把代码提升到管态的级别上运行。在内部，内核能获取自旋锁，但任何用户都做不到这一点（用户进程可以随时发生上下文切换，或被阻塞）

    2) API
        #include <asm/spinlock.h> 
        spin_lock()	            //获取指定的自旋锁
        spin_lock_irq()	        //禁止本地中断并获取指定的锁
        spin_lock_irqsave()	    //保存本地中断的当前状态，禁止本地中断，并获取指定的锁
        spin_unlock()	        //释放指定的锁
        spin_unlock_irq()	    //释放指定的锁，并激活本地中断
        spin_unlock_irqstore()	//释放指定的锁，并让本地中断恢复到以前状态
        spin_lock_init()	    //动态初始化指定的spinlock_t
        spin_trylock()	        //试图获取指定的锁，如果未获取，则返回0
        spin_is_locked()	    //如果指定的锁当前正在被获取，则返回非0，否则返回0
        spin_lock_bh()          //获取指定锁，并禁止中断下半部
        spin_unlock_bh()        //释放指定锁，并恢复中断下半部
    3) 模型
        while (抢锁(lock) == 没抢到) {
        }
        
(3) 读写自旋锁(rwlock)
    1) 特点
        读写自旋锁除了和普通自旋锁一样有自旋特性以外，还有以下特点： 
        > 读锁之间是共享的, 即一个线程持有了读锁之后，其他线程也可以以读的方式持有这个锁
        > 写锁之间是互斥的, 即一个线程持有了写锁之后，其他线程不能以读或者写的方式持有这个锁
        > 读写锁之间是互斥的, 即一个线程持有了读锁之后，其他线程不能以写的方式持有这个锁
        注：读写锁要分别使用，不能混合使用，否则会造成死锁。
    2) API
        #include <asm/rwlock.h>
        read_lock()                 //获取指定的读锁
        read_lock_irq()	            //禁止本地中断并获得指定读锁
        read_lock_irqsave()	        //存储本地中断的当前状态，禁止本地中断并获得指定读锁
        read_unlock()	            //释放指定的读锁
        read_unlock_irq()	        //释放指定的读锁并激活本地中断
        read_unlock_irqrestore()	//释放指定的读锁并将本地中断恢复到指定前的状态
        write_lock()	            //获得指定的写锁
        write_lock_irq()	        //禁止本地中断并获得指定写锁
        write_lock_irqsave()	    //存储本地中断的当前状态，禁止本地中断并获得指定写锁
        write_unlock()	            //释放指定的写锁
        write_unlock_irq()	        //释放指定的写锁并激活本地中断
        write_unlock_irqrestore()	//释放指定的写锁并将本地中断恢复到指定前的状态
        write_trylock()	            //试图获得指定的写锁；如果写锁不可用，返回非0值
        rwlock_init()	            //初始化指定的rwlock_t
    3) 使用方法
        //定义读写自旋锁
        DEFINE_RWLOCK(mr_rwlock);

        read_lock(&mr_rwlock);
        /* 临界区(只读).... */
        read_unlock(&mr_rwlock);
        
        write_lock(&mr_lock);
        /* 临界区(读写)... */
        write_unlock(&mr_lock);

        //错误用法，混合使用
        /* 获取一个读锁 */
        read_lock(&mr_lock);
        /* 在获取写锁的时候，由于读写锁之间是互斥的，
        * 所以写锁会一直自旋等待读锁的释放，
        * 而此时读锁也在等待写锁获取完成后继续下面的代码。
        * 因此造成了读写锁的互相等待，形成了死锁。
        */
        write_lock(&mr_lock);
        
(4) 信号量
    1) 特点
        > 与自旋锁的区别
            信号量也是一种锁，和自旋锁不同的是，线程获取不到信号量的时候，不会像自旋锁一样循环的去试图获取锁，而是进入睡眠，直至有信号量释放出来时，才会唤醒睡眠的线程，进入临界区执行。
        > 适用于时间长的临界区
            由于使用信号量时，线程会睡眠，所以等待的过程不会占用CPU时间。所以信号量适用于等待时间较长的临界区。
            信号量消耗的CPU时间的地方在于使线程睡眠和唤醒线程，
            如果 （使线程睡眠 + 唤醒线程）的CPU时间 > 线程自旋等待的CPU时间，那么可以考虑使用自旋锁。
        > 二值信号量和计数信号量 
            > 信号量有二值信号量和计数信号量2种，其中二值信号量比较常用。
            > 二值信号量表示信号量只有2个值，即0和1。信号量为1时，表示临界区可用，信号量为0时，表示临界区不可访问。
            > 二值信号量表面看和自旋锁很相似，区别在于争用自旋锁的线程会一直循环尝试获取自旋锁，
            > 而争用信号量的线程在信号量为0时，会进入睡眠，信号量可用时再被唤醒。
            > 计数信号量有个计数值，比如计数值为5，表示同时可以有5个线程访问临界区。
    2) API
        sema_init(struct semaphore *, int)	以指定的计数值初始化动态创建的信号量
        init_MUTEX(struct semaphore *)	以计数值1初始化动态创建的信号量
        init_MUTEX_LOCKED(struct semaphore *)	以计数值0初始化动态创建的信号量（初始为加锁状态）
        down_interruptible(struct semaphore *)	以试图获得指定的信号量，如果信号量已被争用，则进入可中断睡眠状态
        down(struct semaphore *)	以试图获得指定的信号量，如果信号量已被争用，则进入不可中断睡眠状态
        down_trylock(struct semaphore *)	以试图获得指定的信号量，如果信号量已被争用，则立即返回非0值
        up(struct semaphore *)	以释放指定的信号量，如果睡眠队列不空，则唤醒其中一个任务

        //信号量结构体具体如下：
        /* Please don't access any members of this structure directly */
        struct semaphore {
            spinlock_t        lock;
            unsigned int        count;
            struct list_head    wait_list;
        };
        //可以发现信号量结构体中有个自旋锁，这个自旋锁的作用是保证信号量的down和up等操作不会被中断处理程序打断。

    3) 用法
        #include <linux/semaphore.h>

        //定义并声明一个信号量，名字为mr_sem，用于信号量计数
        static DECLARE_MUTEX(mr_sem);

        //试图获取信号量，信号未获取成功时，进入睡眠，此时线程状态为 TASK_INTERRUPTIBLE
        //也可以用down(&mr_sem), 这个方法把线程状态置为 TASK_UNINTERRUPTIBLE 后睡眠
        down_interruptible(&mr_sem);
       
        /* 临界区 ... */
       
        //释放给定的信号量
        up(&mr_sem);

        //一般用的比较多的是down_interruptible()方法，因为以 TASK_UNINTERRUPTIBLE 方式睡眠无法被信号唤醒。


(5) 读写信号量
    读写信号量和信号量之间的关系与读写自旋锁和普通自旋锁之间的关系差不多。
    读写信号量都是二值信号量，即计数值最大为1，增加读者时，计数器不变，增加写者，计数器才减一。也就是说读写信号量保护的临界区，最多只有一个写者，但可以有多个读者。
    读写信号量的相关内容参见：<asm/rwsem.h> 具体实现与硬件体系结构有关。

(6) 互斥体(mutex)
    1) 特点
        > 互斥体
            一种可以睡眠的锁，相当于二值信号量，只是提供的API更加简单，使用的场景也更严格一些。mutex的计数值只能为1，也就是最多只允许一个线程访问临界区
        > 进程上下文
            mutex不能在中断或者下半部中使用，也就是mutex只能在进程上下文中使用
            在同一个上下文中上锁和解锁，不能递归的上锁和解锁
            持有个mutex时，进程不能退出，mutex只能通过官方API来管理，不能自己写代码操作它
        > 互斥体与信号量
            只要满足互斥体的使用场景就尽量优先使用互斥体
        > 互斥体与自旋锁
            低开销加锁          优先使用自旋锁
            短期锁定	        优先使用自旋锁
            长期加锁	        优先使用互斥体
            中断上下文中加锁     使用自旋锁
            持有锁需要睡眠	    使用互斥体
    2) API
        #include <linux/mutex.h>

        mutex_lock(struct mutex *)	    //为指定的mutex上锁，如果锁不可用则睡眠
        mutex_unlock(struct mutex *)	//为指定的mutex解锁
        mutex_trylock(struct mutex *)	//试图获取指定的mutex，如果成功则返回1；否则锁被获取，返回0
        mutex_is_locked(struct mutex *)	//如果锁已被争用，则返回1；否则返回0

(7) 完成变量
    完成变量的机制类似于信号量
    比如一个线程A进入临界区之后，另一个线程B会在完成变量上等待，线程A完成了任务出了临界区之后，使用完成变量来唤醒线程B

(8) 大内核锁
    大内核锁已经不再使用，只存在与一些遗留的代码中

(9) 顺序锁(seqlock, 读写锁的一种优化)
    1) 特点
        > 读锁、写锁
            读锁被获取的情况下，写锁仍然可以被获取(与rwlock主要区别)
            写者与写者之间仍然是互斥的，即如果有写者在进行写操作，其他写者必须自旋在那里，直到写者释放了顺序锁
        > 限制与使用场景
            必须要求被保护的共享资源不含有指针，因为写者可能使得指针失效，但读者如果正要访问该指针，将导致OOPs
            顺序锁优先保证写锁的可用，所以适用于那些读者很多，写者很少，且写优于读的场景。
        > 原理
            读之前和读之后都会检查顺序锁的序列值，如果前后值不符，则说明在读的过程中有写的操作发生，那么读操作会重新执行一次，直至读前后的序列值是一样的。
            do
            {
                /* 读之前获取 顺序锁foo 的序列值 */
                seq = read_seqbegin(&foo);
            ...
            } while(read_seqretry(&foo, seq)); /* 顺序锁foo此时的序列值!=seq 时返回true，反之返回false */
    2) API
        #include <linux/seqlock.h>

        //定义一个顺序锁有两种方式
        seqlock_t seqlock
        seqlock_init(&seqlock)      //方法一
        DEFINE_SEQLOCK(seqlock)     //方法二

        //写
        write_seqlock(&seqlock);
        /* -------- 写临界区 ---------*/
        write_sequnlock(&seqlock);

        //读
        unsigned long seq;
        do { 
            seq = read_seqbegin(&seqlock); 
        /* ---------- 这里读临界区数据 ----------*/
        } while (read_seqretry(&seqlock, seq)); 

(10) RCU
    https://www.ibm.com/developerworks/cn/linux/l-rcu/index.html
    https://zhuanlan.zhihu.com/p/56404913
    https://www.cnblogs.com/qcloud1001/p/7755331.html
    https://cloud.tencent.com/developer/article/1054094
    https://zhuanlan.zhihu.com/p/67520807

    1) 特点
        > 原理
            对于被RCU保护的共享数据结构，读者不需要获得任何锁就可以访问它
            写者在访问它时首先拷贝一个副本，然后对副本进行修改，最后使用一个回调(callback)机制在'适当的时机'把指向原来数据的指针重新指向新的被修改的数据
            这个时机就是所有引用该数据的CPU都退出对共享数据的操作

        > 与rwlock的区别
            适合多读少些但写开销较大的业务
            它既允许多个读者同时访问被保护的数据，又允许多个读者和多个写者同时访问被保护的数据(注意：是否可以有多个写者并行访问取决于写者之间使用的同步机制)
            读者没有任何同步开销，而写者的同步开销则取决于使用的写者间同步机制
            RCU不能替代rwlock，因为如果写比较多时，对读者的性能提高不能弥补写者导致的损失

        > 不能阻塞
            读者在访问被RCU保护的共享数据期间不能被阻塞，这是RCU机制得以实现的一个基本前提，也就说当读者在引用被RCU保护的共享数据期间，读者所在的CPU不能发生上下文切换，当然spinlock和rwlock都需要这样的前提
            写者在访问被RCU保护的共享数据时不需要和读者竞争任何锁，只有在有多于一个写者的情况下需要获得某种锁以与其他写者同步。写者修改数据前首先拷贝一个被修改元素的副本，然后在副本上进行修改，修改完毕后它向垃圾回收器注册一个回调函数以便在适当的时机执行真正的修改操作。

        > 宽限期(grace period)
            在一个删除(指的是old version的销毁)动作发生后，它必须等待read_lock临界区结束(读线程结束)，才可以进行销毁操作
            删除 ---> 宽限期 ---> 销毁
            内核把从写操作开始到等待所有读操作结束的这段时间叫做宽限期（Grace Period）。synchronize_rcu函数就是等待宽限期结束的函数    

        > quiescent state
            CPU发生了上下文切换称为经历一个quiescent state
            call_rcu_bh将把 softirq 的执行完毕也认为是一个 quiescent state

        > 怎么识别宽限期
            判断当前没有在临界区也不是针对某一个资源的，而是直接针对整个内核中的所有资源的，当写操作发生的时候，synchronize_rcu开始计算，当所有的CPU都发生过抢占的时候，就可以说明是当前没有在进行的读操作了，写操作就可以顺利的继续执行。
            即只要当前cpu发生上下文切换

        > 开销很大
            1> 读锁关闭当前cpu抢占
            2> 内核中有一个rcu_gp_kthread线程，专门用来发起宽限期和收集各个CPU的抢占信息，在满足条件后通知写操作继续。由于RCU是全局的，对不同资源的写操作有可能同时在产生，这个时候在一个宽限期结束的时候，会同时唤醒所有在等待的写操作
            3> 也正是因为RCU可以算是一个超大力度的内核锁，任何的写请求都要等待整个系统的读请求完成，所以RCU锁对写操作时非常不友好，这也是RCU锁用在多读少写的原因

        > RCU是一种设计模式
            删除链表元素为例
            1> 遍历该链表得到指向元素 B 的指针
            2> 修改元素 B 的前后指向，A->next->C, A<-prep<-C        
            3> 修改指针指向是原子性的，而且元素B并没有更改。期间读者访问不需要同步
            4> 写者完成这些操作后注册一个回调函数(grace period 之后删除元素 B)
            5> 垃圾收集器在检测到所有的CPU不在引用该链表后，即所有的 CPU 已经经历了 quiescent state,grace period 已经过去后，就调用刚才写者注册的回调函数删除了元素 B。

    2) 实现机制
                                            reader0, reader1, reader2
                                               ↓        ↓        ↓
                        +------------->RCU projected data(old version) <------reclamation
                        ↑         | 
        RCU projected pointer     | removal 
                        ↓         ↓      
                        +------------->RCU projected data(new version)
                                             ↑              ↑
                                          reader3         reader4                        
        1> removal
            write分配一个new version的共享数据进行数据更新，更新完毕后将RCU protected pointer指向新版本的数据。一旦把RCU protected pointer指向的新的数据，也就意味着将其推向前台，公布与众（reader都是通过pointer访问数据的）。通过这样的操作，原来read 0、1、2对共享数据的reference被移除了（对于新版本的受RCU保护的数据而言），它们都是在旧版本的RCU protected data上进行数据访问。
        2> reclamation
            共享数据不能有两个版本，因此一定要在适当的时机去回收旧版本的数据。当然，不能太着急，不能reader线程还访问着old version的数据的时候就强行回收，这样会让reader crash的。reclamation必须发生在所有的访问旧版本数据的那些reader离开临界区之后再回收，而这段等待的时间被称为grace period。
        顺便说明一下，reclamation并不需要等待read3和4，因为write端的为RCU protected pointer赋值的语句是原子的，乱入的reader线程要么看到的是旧的数据，要么是新的数据。对于read3和4，它们访问的是新的共享数据，因此不会reference旧的数据，因此reclamation不需要等待read3和4离开临界区。

    3) API
        > reader
            > rcu_read_lock
                用来标识RCU read side临界区的开始
                //对于读者，RCU 仅需要抢占失效，因此获得读锁和释放读锁分别定义为
                #define rcu_read_lock()         preempt_disable()
                #define rcu_read_unlock()       preempt_enable()
            
            > rcu_dereference
                该接口用来获取RCU protected pointer, reader要访问RCU保护的共享数据，当然要获取RCU protected pointer，然后通过该指针进行dereference的操作
                也是读内存屏障

            > rcu_read_unlock
                用来标识reader离开RCU read side临界区

        > writer
            > rcu_assign_pointer
                该接口被writer用来进行removal的操作。在writer完成新版本数据分配和更新之后，调用这个接口可以让RCU protected pointer指向RCU protected data(new version)。
                写内存屏障
            
            > synchronize_rcu
                writer端的操作可以是同步的，也就是说，完成更新操作之后，可以调用该接口函数等待所有在旧版本数据上的reader线程离开临界区，一旦从该函数返回，说明旧的共享数据没有任何引用了，可以直接进行reclaimation的操作。

            > call_rcu
                某些情况下（例如在softirq context中），writer无法阻塞，这时候可以调用call_rcu接口函数，该函数仅仅是注册了callback就直接返回了，在适当的时机会调用callback函数，完成reclaimation的操作。这样的场景其实是分开removal和reclaimation的操作在两个不同的线程中：updater和reclaimer。

    4) 实例
        > 普通应用
            struct foo{
                int a;
                char b;
                long c;
            };
            DEFINE_SPINLOCK(foo_mutex);
            struct foo *glob_foo;    

            void foo_read(void){
                rcu_read_lock()

                //读屏障
                //foo *fp = glob_foo;
                foo *fp = rcu_dereference(glob_foo);    //确保fp = glob_foo
                
                if (fp != NULL) {
                    do_somthing(fp->a, fp->b, fp->c);
                }
                rcu_read_lock()
            }

            void foo_write(struct foo *new_foo) {
                spin_lock(&foo_mutex);
                foo *old_foo = glob_foo;
                new_foo->a = 1;
                new_foo->b = 'b';
                new_foo->c = 100;

                //由于存在编译器优化或cpu优化导致的乱序，要用写内存屏障
                //glob_foo = new_foo; 
                rcu_assign_pointer(glob_foo, new_foo);      //确保

                spin_unlock(&foo_mutex);
                synchronize_rcu();
                kfree(old_foo);
            }

        > 链表操作的RCU版本


(11) cpu变量
    最简单的同步技术，每个CPU构造一个变量的副本，这样多个CPU相互操作各自的副本，互不干涉
    注意禁止内核抢占，因为会导致cpu变量引用错误
    //根据当前的cpu编号，索引cpu变量
    int cpu
    cpu = get_cpu()     //禁止内核抢占，并获得当前cpu号
    //对数据进行操作
    put_cpu()           //激活内核抢占

```

### 抢占与同步
```
1、为什么需要加锁
    内核是抢占性的（无论是多处理器还是单处理器），一个与运行在临界区中的内核进程可以停下来以便让优先级更高的进程执行。所以内核抢占代码使用自旋锁作为非抢占区域标记
    自旋锁禁止内核和中断抢占

2、不需要加锁
    如果数据对处理器是唯一的，仅仅禁止中断就可以了，不需要加锁(类似伪并发访问)


3、抢占相关API
    //增加抢占计数器，从而禁止内核抢占
    preempt_disable()   
    //激活内核抢占，检查和执行被挂起的需调度的任务
    preempt_enable()   
    //激活内核抢占，但是不会检查和执行被挂起的需调度的任务
    preempt_enable_no_resched()   
    //返回抢占计数
    preempt_count()
    


```

### spin lock的优化
```
https://zhuanlan.zhihu.com/p/84617791?utm_source=qq&utm_medium=social&utm_oi=555400798499188736
```


### 无锁编程(lock-free)
```
https://zhuanlan.zhihu.com/p/55178835 [说说无锁(Lock-Free)编程那些事]
https://www.xiaobotalk.com/2020/06/atomic-multithreading/ [原子操作-无锁多线程编程]
http://ifeve.com/lock-based-vs-lock-free-concurren/ [基于锁的并发算法 vs 无锁的并发算法]
http://ifeve.com/lock-free-vs-wait-free-concurrency/ [无锁并发和无等待并发的对比分析]
https://www.cnblogs.com/mylinuxer/articles/5159467.html [无锁编程本质论]
http://ifeve.com/lock-free-and-wait-free/ [无锁和无等待的定义和例子]
https://www.ibm.com/developerworks/cn/linux/l-cn-lockfree/ [透过 Linux 内核看无锁编程]
https://zhuanlan.zhihu.com/p/53012280 [简化概念下的 lock-free 编程]
https://www.zhihu.com/question/295904223 [wait-free是指什么]
https://www.cnblogs.com/gaochundong/p/lock_free_programming.html [Lock-Free 编程]
http://novoland.github.io/%E5%B9%B6%E5%8F%91/2014/07/26/Lock-Free%20%E7%AE%97%E6%B3%95.html [Lock-Free 算法]

1、使用系统锁、同步原语的问题
    (1) 一些同步原语操作内核对象，会带来上下文切换影响效率
    (2) 锁的粒度比较大，加锁释放锁的消耗较大
    (3) 持有锁的优先级低线程可能被系统中断进入睡眠，这样其他等待锁的线程就会一直等下去
    (4) 持有锁的线程挂掉后得不到释放，导致死锁
    
2、非阻塞同步(Non-blocking Synchronization)
    在并行程序中保护共享数据用到'同步'，同步分为'阻塞同步'和'非阻塞同步'
    阻塞同步会造成死锁、活锁、性能低下等问题，为了降低风险和提高效率，现在大多使用'非阻塞同步'
    非阻塞同步的方案 无干扰(obstruction-free)、无锁(lock-free)、无等待(wait-free)
    (1) obstruction-free
    (2) lock-free
        能够确保执行它的所有线程中'至少有'在有限步内完成了任务
        当很多线程运行的时候，尽管有一些的线程竞争原语失败处于'饥饿'状态。虽然这些'倒霉蛋'线程可能一时还轮不到它运行，但它也不会阻碍别的线程，但是这些'饿'的线程最终都会运行下去的，最终在有限步内完成了任务

    (3) wait-free
        任意线程的任何操作'都可以'在有限步之内结束，而不用关心其它线程的执行速度
        承接lock-free，每个线程都不会出现'饥饿'状态，都会有条不紊的在有限步之内结束

    性能：wait > lock > obstruction
    实现难度：wait > lock


3、lock-free
    (1) 细粒度锁？
        细粒度锁是利用原子指令和内存屏障来实现多线程对共享内存的读写，其粒度之细可以与无锁媲美
        但是lock-free并不是细粒度锁，它更多的是无锁数据结构，将共享数据放入无锁的数据结构中，采用原子修改的方式来访问共享数据
        注意：对共享资源的安全访问，在不使用锁、同步原语的情况下，只能'依赖'于硬件支持的'原子操作'
        常见的数据结构有 无锁stack、无锁queue、无锁hashmap等

    (1) 优点
        > 从其定义来看，它们是 wait-free 的，可以确保线程永远不会阻塞
        > 状态转变是原子性的，以至于在任何点失败都不会恶化数据结构
        > 因为线程永远不会阻塞，所以当同步的细粒度是单一原子写或比较交换时，它们通常可以带来更高的吞吐量
        > lock-free 算法会有更少的同步写操作，因此纯粹从性能来看，它可能更便宜。
    (2) 缺点
        > 乐观的并发使用会对 hot data structures 导致 livelock
        > 代码需要大量困难的测试。通常其正确性取决于对目标机器内存模型的正确解释
        > lock-free 代码很难编写和维护
    (3) 
```

### lockfree vs spinlock
```
https://lumian2015.github.io/lockFreeProgramming/lock-free-vs-spin-lock.html

lockfree和spinlock都是依赖于原子操作，乍一看它们相似度很高，让我们看看它们的区别

// lockfree
int count;
void threadFunc(void) {
    int val;
    for (int i = 0; i < 1000000; i++) {
        do {
            val = count;
        } while (!atmoic_compare_exchange_weak(&count, &val, val + 1))
    }
    return;
}

// spinlock
int count;
int lock = 0;
void threadFunc(void) {
    int expected = 0;
    for (int i = 0; i < 1000000; i++) {
        while (!atomic_compare_exchange_weak(&lock, &expected, 1))  // spin_lock
            expected = 0;
        count++;
        lock = 0;   // spin_unlock
    }
}

// 区别
lockfree性能比spinlock要高一点

// 为什么
4个线程运行上述函数，观察竞争情况
lockfree版本
    thread1 val = count                 // count initial 0
    thread2 val = count                 // count = 0
            CAS(&count, &val, val + 1)  // success! count = 1
    thread3 val = count                 // count = 1
            CAS(&count, &val, val + 1)  // success! count = 2
    thread4 val = count                 // count = 1
            CAS(&count, &val, val + 1)  // error! now count is 2, and do while again
spinlock版本
    thread1 CAS(&lock, &expected, 1)    // get lock and set 1
            count++
    thread2 CAS(&lock, &expected, 1)    // error! thread1 hold the lock, please busy-waiting
    thread3 CAS(&lock, &expected, 1)    // error! thread1 hold the lock, please busy-waiting
    thread4 CAS(&lock, &expected, 1)    // error! thread1 hold the lock, please busy-waiting

// 总结
lockfree
    无论其他线程是否访问共享对象，每个线程都可以访问共享对象并对程序进行处理(尽管有时可能会有一些冲突)
spinlock
    如果一个线程正在访问共享对象，其他线程将被阻塞，无法访问共享对象
```

