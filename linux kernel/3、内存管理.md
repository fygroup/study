### 虚拟内存
```
https://www.cnblogs.com/panchanggui/p/9288389.html

虚拟内存被组织为一个由存放在磁盘上的N个连续的字节大小的单元组成的数组
虚拟内存被分割为虚拟页（VP，页），物理内存也被分割为物理页（PP,页帧）

虚拟内存的结构存储在磁盘上，因为程序可以申请很多的虚拟内存

//包含三个不相交的子集
未分配的：未分配和创建的页，不占任何磁盘空间
缓存的：已缓存的在物理内存中已分配的页
未缓存的：未缓存的在物理内存中已分配的页

未分配表示：表示没有任何数据和他们相关联，不占任何磁盘空间
缓存表示：映射到物理内存的虚拟内存

//已分配还没有缓存
```

### 内存地址
```
// 在X86体系中有三种不同的地址
(1) 逻辑地址
    段 + 偏移量，指由程序产生的段内偏移。有时候直接把逻辑地址当做虚拟地址

(2) 线性地址(虚拟地址)
    16进制表示，32位范围0x00000000到0xffffffff

(3) 物理地址
    芯片级内存单元寻址，他们与从微处理器的地址引脚发送到内存总线上的电信号相对应。由32或36无符号整数表示

// MMU
    MMU内存控制单MMU元，管理内存并把虚拟地址转换成物理地址的硬件

    逻辑地址 ----------------> 虚拟地址 --------------> 物理地址
               MMU的分段单元             MMU的分页单元    
    
    程序代码会产生逻辑地址，通过逻辑地址变换就可以生成一个线性地址
```

### 硬件分段
```
MMU分段(硬件)

https://www.cnblogs.com/tolimit/p/4775945.html
https://zhuanlan.zhihu.com/p/25867829

MMU分段单元把逻辑地址转换成线性地址

逻辑地址 = 段标识符(16位，也叫段选择符) + 相对地址的偏移量(32位)

1、段选择符和段寄存器
    (1) 段选择符
        段选择符主要用途就是根据段索引号和TI标志，去到GDT或者LDT中找到这个选择符对应的段描述符

        > 段选择符是一个16位长的字段，段选择符并不直接指向段，而是指向段描述符表中定义段的段描述符
        > 段寄存器存放的是段选择符
        > 结构
            索引号(Index)                               15 ~ 3 (13位), 描述符表中的索引项号
            表指示标志(Table Index)                      3 ~ 2 (1位), 段描述表的索引，TI=0 GDT, TI=1 LDT
            请求特权级别(RPL Requested Privilege Level)  2 ~ 0 (2位), 提供了段保护信息
            
            只有请求者特权级RPL高于(数字低于)或等于相应的描述符特权级DPL，描述符才能被存取

    (2) 段寄存器
        为了方便快速找到段选择符，处理器提供段寄存器，段寄存器唯一目的是存放段选择符
        > 6个段寄存器
            cs、ss、ds、es、fs 和gs
            每个都有一个对应的非编程寄存器，它们对应的非编程寄存器中保存的是段描述符

        > 3个专门段寄存器
            cs代码段寄存器，指向包含程序指令的段
            ss栈段寄存器，指向包含当前程序栈的段
            ds数据段寄存器，指向包含静态数据或者全局数据段
            其他3个段寄存器作一般用途，可以指向任意的数据段

        > cs 寄存器还有一个很重要的功能
            它含有一个两位的字段，用以指明CPU的当前特权级（Current Privilege Level，CPL）
            值为 0 代表最高优先级，而值为 3 代表最低优先级，Linux 只用 0 级和 3 级，分别称之为内核态和用户态

        > 每个段寄存器都有一个"可见"部分和一个"隐藏"部分
            当一个段选择符被加载到一个段寄存器可见部分中时，处理器也同时把段选择符指向的段描述符中的段地址、段限长以及访问控制信息加载到段寄存器的隐藏部分中。缓冲在段寄存器（可见和隐藏部分）中的信息使得处理器可以在进行地址转换时不再需要花费时间从段描述符中读取基地址和限长值

2、段描述符
    由8个字节组成，描述段的内容和特征，放在全局描述表(GDT)或局部描述表(LDT)中

    (1) 非编程寄存器
        寄存器保存的是段选择符，段选择符会到描述符表中获取对应的段描述符，然后将段描述符保存到对应寄存器的'非编程寄存器'中
        这样就不用每次访问段都要跑到内存中的段描述符表中获取

    (2) 段描述符的结构
        包含段属性(12位)、段基址(32位)、段界限(20位)

        // 段描述符的代码表示
        // 段描述符的base和limit是分散的，目的是为了内存对齐节省内存
        struct gdt_entry {
            uint16_t limit_low;
            uint16_t base_low;
            uint8_t base_middle;
            uint8_t access;
            unsigned limit_high: 4;
            unsigned flags: 4;
            uint8_t base_high;
        } __attribute__((packed));
        
    (3) 段描述符的内容
        > BASE(32位)
            段首地址的线性地址(注意，base的byte是分散开的)
        > LIMIT(20位)
            此最后一个地址的偏移量，也相当于长度，G=0，段大小在1~1MB，G=1，段大小为4KB~4GB
        > G
            为0代表此段长度以字节为单位，为1代表此段长度以4K为单位
        > S
            为0表示是系统段，否则为代码段或数据段。
        > Type
            描述段的类型和存取权限
        > DPL
            描述符特权级，表示访问这个段CPU要求的最小优先级(保存在cs寄存器的CPL特权级)
            当DPL为0时，只有CPL为0才能访问，DPL为3时，CPL为0为3都可以访问这个段
        > P
            表示此段是否被交换到磁盘，总是置为1，因为linux不会把一个段都交换到磁盘中
        > D或B
            如果段的LIMIT是32位长，则置1，如果是16位长，置0
        > AVL 忽略
 
    (4) 段描述符的分类
        > 储存段描述符 
            > 数据段描述符
            > 代码段描述符
        > 系统描述符
            > 系统段描述符
                > 局部描述符表(LDT)的段描述符
                > 任务状态段(TSS)的描述符
            > 门描述符
                中断、调用、陷阱、任务
   
3、段描述符表
    段描述符保存在全局描述符表(GDT)和局部描述符表(LDT)中
    > 全局描述符表(GDT)
        系统中'每个CPU'有属于自己的一个全局描述符表(GDT)，其所在内存的基地址和其大小一起保存在CPU的gdtr寄存器中
        其大小为64K，一共可保存8192个段描述符，不过'第一个一般都会置空'，也就是能保存8191个段描述符
        全局描述符表GDT，除了任务门，中断门和陷阱门描述符外，包含着系统中所有任务都共用的段的描述符
    > 中断描述符表(IDT)
        中断描述符表IDT，包含256个门描述符
        IDT中只能包含任务门、中断门和陷阱门描述符，虽然IDT表最长也可以为64K字节，但只能存取2K字节以内的描述符，即256个描述符，这个数字是为了和8086保持兼容
    > 局部描述符表(LDT)
        每个进程可以创建属于自己的局部描述符表(LDT)
        LDT的基地址和大小一起保存在ldtr寄存器中
        每一个任务的局部描述符表LDT本身也用一个描述符来表示，称为LDT描述符，它包含了有关局部描述符表的信息，被放在全局描述符表GDT中
        linux一般不使用LDT

4、地址转换(逻辑地址->线性地址)
    先检查段选择符中的TI字段，确定GDT还是LDT(gdtr/ldtr)
    通过段选择符Index字段计算段描述符地址: index * 8 + gdtr/ldtr
    获得线性地址: 段描述符Base字段值 + 逻辑地址偏移量

```

### RPL DPL CPL 权限检查
```
CPL
    存放在代码段寄存器中(cs)，代表当前执行程序的特权级
    当程序转移到不同特权级的代码段时，处理器将改变CPL，只有0和3两个值，分别表示内核态和用户态

DPL
    存放在段描述符或者门描述符中，用于表示段的特权级，每个段的DPL固定

RPL
    存放在段选择子中，每个段选择子有自己的RPL，它说明的是进程对段访问的请求权限

规则
    当进程访问一个段时，需要进程特权级检查，一般要求DPL >= max {CPL, RPL}
    所以用户随意设置RPL并不会发生权限越级
```

### linux分段
```
分段和分页在某种程度上有些多余，linux倾向于分页的形式

// linux四个主要的段描述符
    运行在用户态的所有进程都使用一对相同的段来对指令和数据寻址，内核态的所有进程都使用一对相同的段来对指令和数据寻址
    段         Base        G   Limit     S   Type   DPL D/B P
    用户代码段  0x00000000  1   0xfffff   1   10     3   1   1
    用户数据段  0x00000000  1   0xfffff   1   2      3   1   1
    内核代码段  0x00000000  1   0xfffff   1   10     0   1   1
    内核数据段  0x00000000  1   0xfffff   1   2      0   1   1

    上述相应的段选择符由宏 __USER_CS, __USER_DS, __KERNEL_CS, __KERNEL_DS来定义

// linux下逻辑地址与线性地址一致
    所有的段都是从0x00000000开始，那就是linux下逻辑地址与线性地址一致，即逻辑地址的偏移量字段的值与线性地址的值一样

// 内核态和用户态
    当前cpu的cs寄存器CPL反映了用户态和内核态，CPL是由段选择符的RPL制定的
    CPL只有小于等于段描述符的DPL才能访问

    当内核调用系统函数时，执行call汇编指令该指令仅指定其逻辑地址的偏移量部分，而段选择符不用设置
    当切入内核态时，只需将__KERNEL_CS加载进cs寄存器即可    

// linux中的GDT 
    每个cpu对应一个GDT，每个GDT包含18个段描述符和14个空的保留项
    18个段描述符包含了用户态和内核态的代码数据段4个
    
// linux中的LDT 
    大多数用户态下不适用LDT

// linux更喜欢分页的方式
```

### 硬件中的分页
```
MMU分页(硬件)

分页单元把线性地址转换成物理地址，但为了效率使用页
(1) 页
    > 线性地址被分成固定的长度为单位的组，称为页
    > 页内部连续的线性地址被映射到连续物理地址中
    > 内核可以指定一个页的物理地址和其存取权限，而不用指定页所包含的全部线性地址的存取权限

(2) 页框(物理页)
    > 分页单元把RAM分成固定长度的页框
    > 一个页的长度等于页框

(3) 页表
    把线性地址映射到物理地址的数据结构称为页表，页表存放在主存中，并在启动分页单元之前必须由内核对页表进行适当的初始化


// 内存管理的基本思路是通过页目录和页表两极映射实现从线性地址到物理地址的转换

// 常规分页
    > 32位线性地址分成3个域
        Directory(目录):  最高10位
        Table(页表): 中间10位
        offset(偏移量): 最低12位
    
    > 目录项和页表项有同样的结构

// 扩展分页
    允许页框从4k扩展到4M，用于把大段连续的线性地址转换成相应的物理地址，可以不用中间页表进行转换
    > 32位线性地址分成2个域
        Directory(目录):  最高10位
        offset(偏移量): 其余22位
    

// 权限控制
    分页单元和分段单元的保护方案不同
    > 分段单元一般有4个权限(用户态或内核态的代码段或数据段)
    > 页和页表一般有2个权限，由目录项或页表项标志User/Supervisor控制的
        若此标志为0，只有内核态(CPL=0)才能对页寻址。若为1，都能寻址

    段有可读、可写、可执行的权限，页只有读写权限，由目录项或页表项标志Read/Write控制的。若为0，标识相应的页或页表是只读的，否则为可读写
```

### linux分页
```
// 采用4级分页模型
页全局目录
页上级目录
页中间目录
页表


    
```


### 区
```
内核将内存按地址的顺序分成了不同的区，有的硬件只能访问有专门的区

头文件 <linux/mmzone.h> 

(1) 为什么要划分区
    由于硬件的限制，内核不能将所有页一直同仁
    > 一些硬件只能用某些特定的内存地址执行DMA(直接内存访问)
    > 一些体系的内存物理寻址范围比虚拟寻址范围大得多。这样物理地址不能全部映射到虚拟地址上

(2) 3个区
    以x86-32为例
    > ZONE_DMA	    DMA使用的页	    0-16MB
        某些硬件只能直接访问内存地址，不支持内存映射，对于这些硬件内核会分配 ZONE_DMA 区的内存
    > ZONE_NORMAL	正常可寻址的页  16-896M
        此区包含能正常映射的页
    > ZONE_HIGHMEM	动态映射的页	>896MB
        '高端内存'，动态映射。其中的页并不能永久地映射到内核地址空间

(3) x86-64的分区
    x86_64体系结构可以映射和处理64位的内存空间，所以没有ZONE_HIGHMEM区，所有物理内存都处于ZONE_DMA和ZONE_NORMAL区

(4) 只有48位
    理论上x86-64系统CPU的寻址空间是16EB，但是实际上只有虚拟地址的最低48位才会在地址转换时被使用，因为
    > 现在还用不到完整的64位寻址空间，所以硬件也没必要支持那么多位的地址
    > 地址宽度越大，操作系统做虚拟地址转换时越累
```

### 页
```
https://zhuanlan.zhihu.com/p/68465952

1、内存管理的基本单位
    > 内核把页(物理页)作为内存管理的基本单位
    > 系统中每个物理页都会分配一个struct page的结构体
    > 通过struct page结构体可以知道一个页是否空闲、如果已分配谁拥有该页。拥有者可以是用户进程空间、动态分配的内核数据、静态内核代码或页高速缓存等
    > 页的大小与体系结构有关，在 x86 结构中一般是 4KB或者8KB
    > 整个系统页耗费的内存不多，对于一个页大小 4KB 的 4G内存来说，一个有 4*1024*1024 / 4 = 1048576 个page，一个page 算40个字节，在管理内存上共消耗内存 40MB左右

    getconf -a | grep -i 'page' 查看当前系统的页。PAGESIZE 就是当前机器页大小，即 4KB

2、struct page
    #include <linux/mm_types.h>
    struct page {
        // 存放页的状态，是不是脏的，是不是锁定等。每一位表示一个状态，共32个状态
        unsigned long flags;
        
        atomic_t _count;                    // 页的引用计数   
        union {
            atomic_t _mapcount;             // 已经映射的页表项计数
            struct {                        // 用于slab分配器，对象的数目
                u16 inuse;
                u16 objects;
            };
        };
        union {
            struct {
            unsigned long private;          // 此page作为私有数据时，指向私有数据
            struct address_space *mapping;  // 此page作为页缓存时，指向关联的address_space
            };
    #if USE_SPLIT_PTLOCKS
            spinlock_t ptl;
    #endif
            struct kmem_cache *slab;        // 用于slab分配器，指向slab指针
            struct page *first_page;        // 尾部复合页中的第一个页
        };
        union {
            pgoff_t index;                  // 映射内的偏移
            void *freelist;                 // SLUB: freelist req. slab lock */
        };
        struct list_head lru;               // 将页关联起来的链表项
    #if defined(WANT_PAGE_VIRTUAL)
        void *virtual;                      // 页的虚拟地址
    #endif
    ...
    };

3、page结构的说明
    flags       描述页的属性
    _count      表示内核中引用该页的次数
    _mapcount   表示页表中有多少项指向该页
    lru         是一个表头，用于在各种链表上维护该页，以便将页按不同类别分组
    first_page  内核将多个毗连的页合并为较大的复合页，first_page指向首页
    mapping     指定了页帧所在的地址空间

    index       页帧在映射内部的偏移量
```

### 页的内核API
```
1、页的获得与释放
    (1) 页的获取
        #include <linux/gfp.h>
        1) alloc_page
            //分配2^order(1<<order) '连续'的物理页，返回的指针指向第一个页的结构体，出错返回NULL
            struct page* alloc_pages(gfp_t gfp_mask, unsigned int order)
            //分配一页
            struct page* alloc_page(gfp_t gfp_mask)

        2) page_address
            //页转换成逻辑地址。返回指针只向物理页当前所在的逻辑地址
            void* page_address(struct page* page)
            //注意区分页结构体指针和页所在的逻辑地址。如果不涉物理页的操作，一般只用逻辑地址unsigned long

        3) __get_free_pages
            //与alloc_page相同，返回第一个页的逻辑地址
            unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order)
            //分配一页
            unsigned long __get_free_page(gfp_t gfp_mask)
            > 注意
                __get_free_pages可能会分配失败，要进行检查
        4) get_zeroed_page
            //获得填充一页并填充为0。此函数与__get_free_pages相同，只不过把分配好的页填充0
            unsigned long get_zeroed_page(gfp_t gfp_mask)
            > 注意
                分配好的页包含"随机"的垃圾信息信息，不安全。给用户空间分配也非常有用

    (2) 页的释放
        // 通过page地址来释放物理页
        void __free_pages(struct page* page, unsigned int order)
        // 通过逻辑地址来释放物理页
        void free_pages(unsigned long addr, unsigned int order)
        void free_page(unsigned long addr)
        > 注意
            传递错误的struct page或地址，用了错误的order会导致系统崩溃

2、通过字节来进行页的获取与释放(用得最多)
    (1) kmalloc
        #include <linux/slab.h> 
        void* kmalloc(size_t size, gfp_t gfp_mask)
        void kfree(const void *)
        > 分配的内存物理地址是连续的，虚拟地址也是连续的
        > 使用中用的较多的是kmalloc，kmalloc的性能较好(内存命中)。因为kmalloc的物理地址和虚拟地址之间的映射比较简单，只需要将物理地址的第一页和虚拟地址的第一页关联起来即可

    (2) vmalloc
        #include <mm/vmalloc.h>
        void* vmalloc(size_t size)
        void vfree(const void *)
        > 分配的内存物理地址是不连续的，虚拟地址是连续的
        > vmalloc由于物理地址是不连续的，所以要将物理地址的每一页都和虚拟地址关联起来才行(vmalloc获得的页必须一个一个的进行映射)
        > 优先使用高端物理内存，先分配高端内存，然后kmap进行一一映射

3、上述分配页的关键标志gfp_mask
    (1) gfp_mask
        #include <linux/gfp.h>
        1) 行为标志(控制分配内存时，分配器的一些行为)
            __GFP_WAIT	    分配器可以睡眠
            __GFP_HIGH	    分配器可以访问紧急事件缓冲池
            __GFP_IO	    分配器可以启动磁盘I/O
            __GFP_FS	    分配器可以启动文件系统I/O
            __GFP_COLD	    分配器应该使用高速缓存中快要淘汰出去的页
            __GFP_NOWARN	分配器将不打印失败警告
            __GFP_REPEAT	分配器在分配失败时重复进行分配，但是这次分配还存在失败的可能
            __GFP_NOFALL	分配器将无限的重复进行分配。分配不能失败
            __GFP_NORETRY	分配器在分配失败时不会重新分配
            __GFP_NO_GROW	由slab层内部使用
            __GFP_COMP	    添加混合页元数据，在 hugetlb 的代码内部使用

        2) 区标志(ZONE_DMA, ZONE_NORMAL, ZONE_HIGHMEM)
            __GFP_DMA	    从ZONE_DMA分配
            __GFP_DMA32	    只在ZONE_DMA32分配
            __GFP_HIGHMEM	从ZONE_HIGHMEM或者ZONE_NORMAL分配(如果ZONE_HIGHMEM没有多余的页则从ZONE_NORMAL分配)

        3) 类型标志(由上面2种标志组合而成的一些常用的场景)
            > GFP_ATOMIC    __GFP_HIGH  
                这个标志用在中断处理程序，下半部，持有自旋锁以及其他不能睡眠的地方
            > GFP_KERNEL    (__GFP_WAIT | __GFP_IO | __GFP_FS )	
                这是常规的分配方式，可能会阻塞。这个标志在睡眠安全时用在进程上下文代码中。为了获得调用者所需的内存，内核会尽力而为。这个标志应当为首选标志
            > GFP_USER      (__GFP_WAIT | __GFP_IO | __GFP_FS )	
                这是常规的分配方式，可能会阻塞。用于为用户空间进程分配内存时
            > GFP_HIGHUSER	(__GFP_WAIT | __GFP_IO | __GFP_FS ) | __GFP_HIGHMEM)	
                从ZONE_HIGHMEM进行分配，可能会阻塞。用于为用户空间进程分配内存
            > GFP_DMA       __GFP_DMA	
                从ZONE_DMA进行分配。需要获取能供DMA使用的内存的设备驱动程序使用这个标志，通常与以上的某个标志组合在一起使用。

    (2) 使用场景
        进程上下文，可以睡眠            使用 GFP_KERNEL
        进程上下文，不可以睡眠	        使用 GFP_ATOMIC，在睡眠之前或之后以 GFP_KERNEL 执行内存分配
        中断处理程序	               使用 GFP_ATOMIC
        软中断	                      使用 GFP_ATOMIC
        tasklet	                      使用 GFP_ATOMIC
        需要用于DMA的内存，可以睡眠	    使用 (GFP_DMA｜GFP_KERNEL)
        需要用于DMA的内存，不可以睡眠	使用 (GFP_DMA｜GFP_ATOMIC)，或者在睡眠之前执行内存分配
```

### slab层
```
https://www.ibm.com/developerworks/cn/linux/l-linux-slab-allocator/index.html

频繁的分配/释放内存必然导致系统性能的下降，所以有必要为频繁分配/释放的对象内心建立缓存。而且，如果能为每个处理器建立专用的高速缓存，还可以避免SMP(多对成处理器结构)锁带来的性能损耗

(1) 特性
    1) 高速缓存
        > 在内存中建立各种对象的高速缓存(struct kmem_cache)
        > 每个高速缓存包含3个链表slabs_full、slabs_partial、slabs_empty，这些链表包含高速缓存中所有的slab
    2) slab
        > slab是一个连续的内存块(一个或多个连续页), 里面包含多个对象
        > slab的三种状态: slabs_full(满)，slabs_partial(部分满)，slabs_empty(空)  
        > slab用于管理缓存的对象，slab是slab分配器进行操作的最小分配单位，因此如果需要对slab进行扩展，这也就是所扩展的最小值
        > 由于对象是从slab中进行分配和释放的，因此单个slab可以在slab列表之间进行移动。例如，当一个slab中的所有对象都被使用完时，就从 slabs_partial 列表中移动到 slabs_full 列表中。当一个 slab 完全被分配并且有对象被释放后，就从 slabs_full 列表中移动到 slabs_partial 列表中。当所有对象都被释放之后，就从 slabs_partial 列表移动到 slabs_empty 列表中。
        > 关系
            物理内存
                kmem_cache
                kmem_cache -+-> slab_full列表
                            |
                            +-> slab_partial列表 ---> slab(slab链表) 
                            |                           ↓
                            |                         slab
                            |                           ↓
                            |                         slab ---> page(多个页) ---> 多个object
                            |
                            |
                            +-> slab_empty列表
        > 例子
            > inode频繁的创建和释放，利用高速缓存进行分配
            > 高速缓存inode_cachep，它包含多个slab，每个slab包含多个struct inode对象
            > 内核请求分配一个新的inode，就会从部分满或空的slab中返回一个已分配但未使用的inode指针
            > 内核用完inode对象后，slab分配器就把该对象标为空闲

(2) slab分配器
    1) 结构
        #include <mm/slab.h>
        struct slab {
            struct list_head list;   //存放缓存对象，这个链表有3种状态(满，部分满，空)
            unsigned long colouroff; //slab 着色的偏移量
            void *s_mem;             //在 slab 中的第一个对象
            unsigned int inuse;      //slab 中已分配的对象数
            kmem_bufctl_t free;      //第一个空闲对象(如果有的话)
            unsigned short nodeid;   //应该是在 NUMA 环境下使用
        };

    2) cache_grow(创建新的slab)
        当高速缓存内，没有空闲的对象、或没有slab、或者slab都处于slab_full链表中，那么高速缓存则创建新的slab添加到空闲链表中
        static int cache_grow(struct kmem_cache *cachep, gfp_t flags, int nodeid, void *objp)
        函数里面包含了kmem_getpages(为slab分配页)，alloc_slabmgmt(为slab管理区分配空间)

    3) cache_init_objs(初始化slab对象)
        static void cache_init_objs(struct kmem_cache *cachep, struct slab *slabp)

    4) slab_destroy(销毁slab就是释放slab管理区和对象占用的空间)
        static void slab_destroy(struct kmem_cache *cachep, struct slab *slabp)

(3) API
    高速缓存的应用，不用考虑slab层，仅限于高速缓存的创建、高速缓存中分配对象、向高速缓存释放对象、高速缓存的销毁
    1) kmem_cache_create(创建一个新缓存)
        struct kmem_cache* kmem_cache_create (const char *name, size_t size, size_t align,unsigned long flags, void (*ctor)(void *))
        name: 高速缓存的名字
        size: 每个元素(对象)的大小
        align: 页内第一个对象的偏移，确保页内的对齐
        flags: 控制高速缓存的行为，默认0
        ctor： 已废弃，NULL

    2) kmem_cache_alloc(分配一个指针对象)    
        void *kmem_cache_alloc(struct kmem_cache *cachep, gfp_t flags)

    3) kmem_cache_free(释放对象)
        void kmem_cache_free(struct kmem_cache *cachep, void *objp)
        
    4) kmem_cache_destroy(销毁高速缓存)
        void kmem_cache_destroy(struct kmem_cache *cachep) 

```

### 内核内存的分配方式
```
内核的内存分配和用户空间的内存分配相比有着更多的限制条件，同时也有着更高的性能要求。

(1) 内核栈上的静态分配
    1) 内核栈
        在x86体系结构中，内核栈的大小一般就是32位1页或64位2页，即 4KB ~ 8KB
        内核栈空间有限，需要更高的效率和更少的问题发生。内核栈一般都是小而且固定的

    2) 中断栈
        每个进程除了有个内核栈之外，还有一个中断栈，中断栈一般也就1页大小
        中断栈不与被中断的进程共享一个内核栈，有单独的栈

    3) 为什么这么少
        > 减少进程内存消耗
        > 随着系统的运行时间增加，寻找连续页会越来越困难，

    4) 当前系统内核栈大小
        ulimit -a | grep 'stack'

(2) 高端内存的映射
    根据定义高端内存(ZONE_HIGHMEM区)的页不能永久的映射到内核地址空间
    所以alloc_pages()以__GFP_HIGHMEM标记获得页不会有逻辑地址

    1) 永久映射
        此函数在高端和低端内存上都能用
        当时低端内存时，进返回该页的虚拟地址；
        当高端内存时，会建立永久映射，然后返回该地址
        此函数可以睡眠，所以只能用在进程上下文中
        // 将ZONE_HIGHMEM区的一个page永久的映射到内核地址空间，返回值即为这个page对应的逻辑地址
        static inline void* kmap(struct page *page)

        // 允许永久映射的数量是有限的，所以不需要高端内存时，应该及时的解除映射
        static inline void kunmap(struct page *page)

    2) 临时映射
        临时映射不会阻塞，也禁止了内核抢占，所以可以用在中断上下文和其他不能重新调度的地方

        //将ZONE_HIGHMEM区的一个page临时映射到内核地址空间，其中的km_type表示映射的目的，enum kn_type的定义参见：<asm/kmap_types.h>
        static inline void *kmap_atomic(struct page *page, enum km_type idx)

        //相应的解除映射是个宏
        #define kunmap_atomic(addr, idx)  do { pagefault_enable(); } while (0)

(3) 按cpu分配
    1) 处理共享数据的问题
        > 单cpu和多cpu的加锁
            处理共享数据时，单cpu无需加锁，但是SMP环境多cpu比需要枷锁，因为当前cpu处理的数据，其他cpu也会处理，导致混乱
        > 禁止内核抢占
            单CPU环境下，上述情况无需加锁，只需在 if处理之前禁止内核抢占，在 else 处理之后恢复内核抢占即可。
            而在SMP环境下，上述情况必须加锁，因为禁止内核抢占只能禁止当前CPU的抢占，其他的CPU仍然调度线程B来抢占线程A的执行

    2) 为什么需要为cpu单独份配？
        SMP环境下加锁过多的话，会严重影响并行的效率，如果是自旋锁的话，还会浪费其他CPU的执行时间。所以内核中才有了按CPU分配数据的接口。
        减少了对数据的锁，提高了系统的性能。
        每个CPU有自己的数据，所以处理器切换时可以大大减少缓存失效的几率
        
    3) get_cpu(获得当前cpu号)
        int count[NR_CPUS];     //NR_CPUS表示当前系统cpu数
        int cpu = get_cpu();    //获得当前处理器，并禁止内核抢占
        //为什么要禁止内核抢占
        //1) 如果被强占并重新调度，那么此时cpu变量就无效(通常获得cpu后不能休眠)
        //2) 如果另一个抢占代码的任务也操作共享数据，就混乱了
        ...
        count[cpu]++;           //不同的cpu做不同的事
        ...
        put_cpu()               //激活内核抢占

    4) 编译时分配
        #include <linux/percpu.h>

        //给每个CPU定义一个类型为 type，名称为 name 的变量
        DEFINE_PER_CPU(type, name)

        //操作当前处理器上的var变量, 禁止内核抢占
        #define get_cpu_var(var) (*({                \
            extern int simple_identifier_##var(void);    \
            preempt_disable();/* 这句就是禁止当前处理器上的内核抢占 */    \
            &__get_cpu_var(var); }))

        //激活当前处理器的内核抢占
        #define put_cpu_var(var) preempt_enable()  /* 这句就是激活当前处理器上的内核抢占 */

        //使用
        DEFINE_PER_CPU(int, name);      //为每个CPU定义一个 int 类型的name变量
        get_cpu_var(name)++;            //当前处理器上的name变量 +1
        put_cpu_var(name);              //完成对name的操作后，激活当前处理器的内核抢占

    5) 运行时分配
        // 给每个处理器分配一个 size 字节大小的对象，对象的偏移量是 align
        extern void *__alloc_percpu(size_t size, size_t align);
        // 释放所有处理器上已分配的变量 __pdata
        extern void free_percpu(void *__pdata);
        // 还有一个宏，是按对象类型 type 来给每个CPU分配数据的，
        // 其实本质上还是调用了 __alloc_percpu 函数
        #define alloc_percpu(type)    (type *)__alloc_percpu(sizeof(type), \
                                    __alignof__(type))

        //例子
        void *percpu_ptr;
        unsigned long *foo;

        percpu_ptr = alloc_percpu(unsigned long);
        if (!percpu_ptr)
            /* 内存分配错误 */

        foo = get_cpu_var(percpu_ptr);
        /* 操作foo ... */
        put_cpu_var(percpu_ptr);
```

### 内存分配使用场景(总结)
```
如果需要物理上连续的页	        选择低级页分配器或者 kmalloc 函数
如果kmalloc分配是可以睡眠	    指定 GFP_KERNEL 标志
如果kmalloc分配是不能睡眠	    指定 GFP_ATOMIC 标志
如果不需要物理上连续的页	     vmalloc 函数 (vmalloc 的性能不如 kmalloc)
如果需要高端内存	            alloc_pages 函数获取 page 的地址，再用 kmap 之类的函数进行映射
如果频繁撤销/创建教导的数据结构	 建立slab高速缓存
```

### 缺页异常
```
缺页异常的原因有以下几种

> 导致缺页异常的线性地址根本不在进程的"虚存区间"中，段错误(栈扩展是一种例外情况)
> 地址在"虚存区间"中，但"虚存区间"的访问权限不够；例如"区间"是只读的，而你想写，段错误
> 权限也够了，但是映射关系没建立；先建立映射关系再说
> 映射关系也建立了，但是页面不在内存中。肯定是换出到交换分区中了，换进来再说
> 页面也在内存中。但页面的访问权限不够。例如页面是只读的，而你想写。这通常就是"写时拷贝COW"的情况。
> 缺页异常发生在"内核动态映射空间"。这是由于进程进入内核后，访问一个通过 vmalloc() 获得线性地址而引起的异常。对这种情况，需要将内核页目录表、页表中对应的映射关系拷贝到进程的页目录表和页表中。
```

### 伙伴系统
```
每一页对应一个struct page，每个内存域都关联一个struct zone

struct zone {
    ...
    // 不同长度的空闲区域
    struct free_area free_area[MAX_ORDER];
    ...
}

struct free_area {
    // 用于连接连接空闲页的链表
    struct list_head free_list[MIGRATE_TYPES];
    // nr指定当前内存区空闲的页块个数
    unsigned long nr_free;
}

// 阶
阶描述了内存分配的数量单位，内存块长度为2^order，order范围0~MAX_ORDER


```

### malloc原理
```
1、虚拟内存申请
    进程虚拟内存的分配有两种方式，分别由两个系统调用完成：brk 和 mmap (不考虑共享内存)
    (1) brk
        将数据段(.data)的最高地址指针_edata 往高地址推
        malloc小于128K的内存，使用brk分配
    (2) mmap
        在进程的虚拟地址空间中(堆和栈中间，称为'文件映射区域'的地方)找一块空闲的虚拟内存
    注意: 上述两种方式分配的都是虚拟内存，没有分配物理内存，当发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系

2、malloc实现原理
    brk和mmap属于系统调用，每次申请影响性能
    其次内存容易产生碎片，因为堆从低地址到高地址，如果低地址的内存没有被释放，高地址的内存就不能被回收
    
    malloc采用的是内存池的实现方式，先申请一大块内存(用brk或mmap申请)，然后将内存分成不同大小的内存块，然后用户申请内存时，直接从内存池中选择一块相近的内存块即可

    当进行内存分配时，Malloc会通过隐式链表遍历所有的空闲块，选择满足要求的块进行分配
    如果该块恰好与请求的大小相符，则将其从链表中移走并返回给用户
    如果该块太大，则将其分为两部分，尾部的部分分给用户，剩下的部分留在空闲链表中
    因此malloc分配的是一块连续的内存

    当内存释放时，首先搜索空闲链表，找到可以插入被释放块的合适位置
    如果与被释放块相邻的任一边是一个空闲块，则将这两个块合为一个更大的块，以减少内存碎片


```

### MMZ
```
所有DDR内存中，一部分由操作系统管理，称为OS内存，另一部分由MMZ模块管理，供媒体业务单独使用，称为MMZ内存

mmz大部分为媒体业务独立使用，内存在媒体硬件模块流转，应用无需访问，这时不用映射，只有当应用需要访问时才需要进行映射

OS内存分配记录 /proc/meminfo

// MMZ内存
(1) 概述
    /proc/media-mem
        查看分配记录，这里记录了当前MMZ内存被分配至哪些模块，被谁使用了
        
    /dev/mmz_userdev
        mmz内存由mmz驱动模块进行管理供媒体业务单独使用的内存，在驱动加载时可以指定该模块管理内存的大小
        该驱动由media-mem.c和mmz-userdev.c组成
        加载驱动后相应的设备文件/dev/mmz_userdev，应用层通过打开该设备文件进行ioctl（申请mmz内存、释放mmz内存、重映射mmz内存到内核等）和直接mmap操作，而媒体底层驱动模块则直接调用mmz驱动的导出接口进行相应操作

(2) 数据结构
    1) mmz区域描述符
        hil_media_memory_zone描述了一个mmz区域的所有信息，可以有多个mmz区域，通过链表连接在一起
    2) mmb内存描述符
        hil_media_memory_block描述了从mmz区域申请一块内存，同一个mmz区域内的所有mmb通过链表连接
        mmz_userdev_info该结构体保存打开该设备文件的进程信息，存放在file结构体的private_data成员里
        mmb_info该结构体描述应用申请到mmb后的相关信息，同进程的mmb_info通过链表形式管理

// 内存配置
(1) OS内存配置
(2) mmz内存配置


```
