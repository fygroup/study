### ORM
```
对象关系映射（Object Relational Mapping，简称ORM）模式是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。简单的说，ORM是通过使用描述对象和数据库之间映射的元数据，将程序中的对象自动持久化到关系数据库中。

ORM 就是通过实例对象的语法，完成关系型数据库的操作的技术，是"对象-关系映射"（Object/Relational Mapping）

ORM 把数据库映射成对象。
数据库的表（table） --> 类（class）
记录（record，行数据）--> 对象（object）
字段（field）--> 对象的属性（attribute）

//Hibernate(java的ORM)
Hibernate 将 Java 类映射到数据库表中，从 Java 数据类型中映射到 SQL 数据类型中，并把开发人员从 95% 的公共数据持续性编程工作中解放出来。
```

### 关系型和非关系型
```
关系型数据库和非关系型数据库在使用场景上差别比较大
一般非关系型数据库是基于CAP模型，而传统的关系型数据库是基于ACID模型
非关系型数据库可能更多的偏向于OLAP场景，而关系型数据库更多偏向于OLTP场景
非关系型中没有事务这个概念，每一个数据集都是原子级别的

https://zhuanlan.zhihu.com/p/78619241

// sql还是nosql
https://www.jianshu.com/p/296bacba3510

```

### 行存储和列存储
```
// 数据写入
    行存储的写入是一次完成
    列存储由于需要把一行记录拆分成单列保存，写入次数明显比行存储多
    效率：行存储 > 列存储

// 数据读取
    行存储通常将一行数据完全读出，就会存在冗余列
    列存储每次读取的数据是集合的一段或者全部，不存在冗余性问题
    效率：行存储 < 列存储

// 数据压缩
    由于同一个数据列的数据重复度很高，因此，列式数据库压缩时有很大的优势

行存储：mysql、Oracle
列存储：一些分布式数据库，Hive
```

### OLTP与OLAP
```
数据处理大致可分为两大类

OLTP
    做事务处理，主要对数据的增删改
    要求实时性高、稳定性强、确保数据及时更新成功
    行存储的数据库更适合OLTP

OLAP
    做分析处理，主要对数据的查询
    强调数据分析，强调SQL执行市场，强调磁盘I/O，强调分区等
    列存储的数据库更适合OLAP

```

### SQL四种语言
```
数据查询语言DQL，数据操纵语言DML，数据定义语言DDL，数据控制语言DCL

1、DQL
    基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块

2、DML
    主要有三种形式：
    1) 插入：INSERT
    2) 更新：UPDATE
    3) 删除：DELETE
    
3、DDL
    数据库中的某些对象(例如，database,table)进行管理
    CREATE TABLE/VIEW/INDEX/SYN/CLUSTER
    不能rollback

4、DCL
    用来授予或回收访问数据库的某种特权，并控制数据库操纵事务发生的时间及效果，对数据库实行监视等
    1) GRANT(授权)
    2) ROLLBACK(回滚)
    3) COMMIT(提交)
        显式提交、隐式提交、自动提交


```

### 数据库的事务(session)
```
1、事务四大特征(ACID)
    Atomicity(原子性)
	    一个事务中的所有操作，要么全部完成，要么全部不完成，不会在中间某个环节结束。
        事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。
    Consistency(一致性)
	    在事务开始之前和事务结束以后，数据库数据的一致性约束没有被破坏。
    Isolation(隔离性)
	    数据库允许多个并发事务同时对数据进行读写和修改的能力。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。
    Durability(持久性)
	    事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

2、事务问题
    1) 并发导致的问题
        > 更新丢失(Lost Update)
            当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题(最后的更新覆盖了由其他事务所做的更新)
            
            例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。最后保存其更改副本的编辑人员覆盖另一个编辑人员所做的更改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题。
        > 脏读(Dirty Reads)
            一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些"脏"数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做"脏读"
        > 不可重复读(Non-Repeatable Reads)
            一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了。这种现象就叫做"不可重复读"
        > 幻读(Phantom Reads)
            一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。
        
        不可重复读是读取到了另一事务的更新，而幻读是读取到了另一事务的插入(MySQL中无法测试到幻读)
        
    2) 级别
        数据库实现事务隔离的方式，基本上可分为以下两种。
        一种是在读取数据前，对其加锁，阻止其他事务对数据进行修改。另一种用多版本数据库，生成一个数据请求时间点的一致性数据快照（Snapshot)，并用这个快照来提供一定级别（语句级或事务级）的一致性读取。
        > 未提交读(Read Uncommitted)
            允许脏读，也就是可能读取到其他会话中未提交事务修改的数据
        > 提交读(Read Committed)
            只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)
        > 可重复读(Repeated Read)
            可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读
        > 串行读(Serializable)
            完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞
        事务隔离级别	             脏读	不可重复读	幻读
        读未提交（read-uncommitted） 是	    是	       是
        不可重复读（read-committed） 否	    是	       是
        可重复读（repeatable-read）	 否	    否	       是
        串行化（serializable）	     否	    否	       否

        读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力
```


### 数据库的并发控制
```
https://blog.csdn.net/xifeijian/article/details/20313977
https://www.cnblogs.com/paul8339/p/6877729.html
https://tech.meituan.com/2014/08/20/innodb-lock.html
https://zhuanlan.zhihu.com/p/133823461
https://zhuanlan.zhihu.com/p/45339550
https://draveness.me/database-concurrency-control/
https://www.zhihu.com/question/60278698

1、事务的特性
    原子性
    持久性
    隔离性
    一致性

2、冲突
    1) 读写冲突
        事务先A读取某行数据、事务B后修改该行数据，和事务B先修改某行事务、事务A后读该行记录两种schedule。事务A读到的结果不同。这种冲突可能会导致不可重复读异象和脏读异象。
    2) 写读冲突
        与读写冲突产生的原因相同。这种冲突可能会导致脏读异象。
    3) 写写冲突
        两个操作先后写一个对象，后一个操作的结果决定了写入的最终结果。这种冲突可能会导致更新丢失异象。

3、并发控制
    (1) 悲观并发控制
        总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）
        传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁，释放锁之前任何人都不能对其数据进行操作,性能不高
        1) 共享锁和排他锁（按级别划分）
            共享锁（读锁）：其他事务可以读，但不能写（提高读读并发）
            排他锁（写锁） ：其他事务不能读取，也不能写（保证数据的一致性）
        2) 表级锁、行级锁、页级锁（按粒度划分）
            1> 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。
            2> 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。使用行级锁定的主要是InnoDB存储引擎。
            3> 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。
        3) 自动锁、显示锁（加锁方式）
            INSERT、UPDATE、DELETE InnoDB会自动加排他锁，对于普通SELECT语句，InnoDB不会加任何锁，当然也可以显示加锁。
        数据库中常用的加锁方式称为两阶段锁（2PL）
        阶段一：Growing，事务向锁管理器请求它需要的所有锁（存在加锁失败的可能）
        阶段二：Shrinking，事务释放Growing阶段获取的锁，不允许再请求新锁
        存在死锁的可能，事务1持有A锁等B锁，事务2持有B锁等A锁

    (2) 乐观并发控制
        它并不是真正的锁，很多人都会误以为乐观锁是一种真正的锁，然而它只是一种并发控制的思想
        每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据
        1) 相关协议
            1) 基于时间戳的协议(Timestamp)
                1> 时间戳
                    TS：一个事务开始的时间戳，事务开始时候分配一个全局自增的Timestamp
                    RT(x)：x最近被写入的时间戳
                    WT(x)：x最近被读取的时间戳
                    c(x)：表示最近一次x的修改是否已提交
                2> 判断条件
                    > 事务发起读请求:
                        > TS >= WT(X)， 此读是可实现的：  
                            > C(X)为true，同意请求，且 RT(X) = max (TS, RT(X));   
                            > C(X)为false，推迟事务T，到C(X)为true或写X的事务中止；   
                        > TS <= WT(X)， 此读时不合法的，回滚事务T，并以新时间戳重启；   
                    > 事务发起写请求
                        > TS >= RT(X)，并且TS >= WT(X)，此写是合法的
                            > 写入X；
                            > WT(X) = TS(T);
                            > C(X) = false;
                        > TS >= RT(X) 且 TS < WT(X)，即此写是合法的，但是X已经由一个更晚的事务写入：
                            > C(X)为true，那么将忽略T的写
                            > C(X)为false，那么将推迟事务T
                        > TS < RT(X)，表明已经有一个更晚的事务读取过X，那么事务T是不可实现的，那么需要回滚事务T
                    > commit事务
                        C(x) = true，然后促发依赖元素X的其他所有事务
        
            2) 基于验证的协议(OCC)
                比基于Timestamp的方式要更加的乐观，将冲突检测推迟到Commit前才进行!!!
                OCC假设事务会成功，开始事务时该读读，该写写，不加锁。只有到提交时做一下验证，验证这个事务是不是能够成功提交
                OCC分为三阶段：
                1> Read Phase, 对于读，放到Read Set，对于写，把写记到临时副本，放到Write Set。因为写是写到临时区的，属于未提交结果，其它事务读不到（这点是和MVCC的重要区别）
                2> Validation Phase，重扫Read Set，Write Set，检验数据是否满足Isolation Level，如果满足则Commit，否则Abort
                3> WritePhase，或者叫做Commit Phase，把临时副本区的数据更新到数据库中，完成事务提交

        2) 相关实现方式
            > 版本号机制
                一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。
            > CAS算法
                compare and swap（比较与交换），是一种有名的无锁算法。
                无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。
                CAS算法涉及到三个操作数:
                    需要读写的内存值 V
                    进行比较的值 A
                    拟写入的新值 B
                当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。       
        3) 乐观锁的缺点
            > ABA问题
                如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 "ABA"问题。
            > 循环时间长开销大
                自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。
            > 只能保证一个共享变量的原子操作

    (3) 多版本并发控制(MVCC)
        在InnoDB中，会在每行数据后添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。 在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。 在可重读Repeatable reads事务隔离级别下：

        SELECT时，读取创建版本号<=当前事务版本号，删除版本号为空或>当前事务版本号。
        INSERT时，保存当前事务版本号为行的创建版本号
        DELETE时，保存当前事务版本号为行的删除版本号
        UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行
        通过MVCC，虽然每行记录都需要额外的存储空间，更多的行检查工作以及一些额外的维护工作，但可以减少锁的使用，大多数读操作都不用加锁，读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行，也只锁住必要行

4、乐观锁与MVCC
    https://www.zhihu.com/question/27876575
    https://www.zhihu.com/question/60278698
    
    多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制
    乐观并发控制（OCC）是一种用来解决写-写冲突的无锁并发控制
    多版本并发控制可以结合基于锁的并发控制来解决写-写冲突，即MVCC+2PL，也可以结合乐观并发控制来解决写-写冲突
```

### 数据库缓存
```
//一级缓存
SqlSession级别的缓存。在操作数据库时需要构造sqlSession对象，在对象中有一个数据结构（HashMap）用于存储缓存数据。不同的sqlSession之间的缓存数据区域（HashMap）是互相不影响的。
session级别的，默认开启，不可卸除，一般都会用到 

//二级缓存
全局缓存,mapper级别的缓存，多个SqlSession去操作同一个Mapper的sql语句，多个SqlSession可以共用二级缓存，二级缓存是跨SqlSession的。
sessionfactory（创建session，hibernate的初始化）级别的，适合1、很少别修改的数据， 

缓存首先一进来去查二级缓存，二级缓存没有去找一级缓存，一级缓存没有去找数据库。二级缓存----->一级缓存-------->数据库。
```

### 视图
```
一个比较复杂的查询不想每次都写很多语句，就可以写个视图。
或者给特定用户开放某些表的读取权限，但要加一些行和列的限制，也可以写个视图。
使用视图，可以定制用户数据，聚焦特定的数据。

安全，快速
```


### 底层引擎数据结构
```
(1) HASH索引
    Bitcask

(2) LSM
    https://www.cnblogs.com/eaglegeek/p/4557803.html
    https://www.zhihu.com/question/19887265
    https://zhuanlan.zhihu.com/p/65483906
    https://www.cnblogs.com/gaoguangjun/p/8513054.html
    https://cloud.tencent.com/developer/news/340271

    LevelDB、Hbase、MongoDB
    TSM
    influxdb

(3) B-tree
    Mysql Innodb、

// LSM用于顺序写，提供更快的写入性能，Btree由于更加平衡，读取性能会更强。

// hash索引更适合简单的kv存储，适合做缓存。LSM适合高并发的数据写入，B-tree更适合大量查询的应用场景，
```

### nosql存储方式
```
// 面向列族或键值存储需要定义数据结构(半结构化)，面向文档无需结构(非结构化)

1、kv存储
    Memcached，Redis
    适用于高频率读写，可以横向扩展
    不支持事务，条件查询效率低下

2、列存储
    HBase
    大数据的实时读写操作，高吞吐量写，随机访问大数据集，主要适合于批量数据处理等

3、文档存储
    mongodb

4、图存储
    Neo4J
    图数据库，适合社会网络应用 LinkedIn Facebook 文件系统 角色关系
```

### 数据库范式
```
https://www.cnblogs.com/CareySon/archive/2010/02/16/1668803.html

// 目的
    减少数据冗余（这是最主要的好处，其他好处都是由此而附带的）
    消除异常（插入异常，更新异常，删除异常）
    让数据组织的更加和谐

1、第一范式
    第一范式就是属性(列)不可分割
    第一范式是关系数据库的基础

2、第二范式
    要符合第一范式
    表中的属性必须完全依赖于全部主键，而不是部分主键

3、第三范式(3NF)
    要符合第二范式
    第三范式是为了消除数据库中关键字之间的依赖关系
    非主键的信息只在一个地方存储，不出现在多张表
    减少数据冗余

4、实例
    (1) 未经范式化的表
        EmployeeId
        departmentName
        Name
        Address
        job
        jobDescript
        skill
        departmentDescript
        email
    (2) 第一范式化
        Address列记录了"北京市XX路XX小区XX号"，显然不符合第一范式，第一范式则需要将此属性分解到另一个表(addressId,city,country,street)

        EmployeeId        +----> addressID
        departmentName    |      city
        Name              |      country
        AddressID <-------+      street        
        job
        jobDescript
        skill
        departmentDescript
        email

    (3) 第二范式化
        departmentDescription是由主键DepartmentName所决定，但却不是由主键EmployeeID决定，所以departmentDescription只依赖于两个主键中的一个

        EmployeeId               
        Name                     
        addressID                
        job         
        jobDescript             
        departmentID 
        skill                         
        email                     
        
        addressID
        city
        country
        street

        departmentID
        departmentName
        departmentDescript
        

    (4) 第三范式化
        jobDescription(岗位职责)是由job(岗位)所决定，则jobDescription依赖于job,可以看出这不符合第三范式

        EmployeeId               
        Name                     
        addressID                
        job                      
        departmentID 
        skill                         
        email                     
        
        addressID
        city
        country
        street

        departmentID
        departmentName
        departmentDescript

        job
        jobDescript
                               
```