### 数据库基础知识
```
1、有关权限的表
    user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的
    db权限表：记录各个帐号在各个数据库上的操作权限
    table_priv权限表：记录数据表级的操作权限
    columns_priv权限表：记录数据列级的操作权限
    host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT(授予)和REVOKE(删除)语句的影响

2、数据类型
    (1) 整数类型
        包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT
        分别表示1字节、2字节、3字节、4字节、8字节整数
        任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数
    (2) 实数类型
        包括FLOAT、DOUBLE、DECIMAL
        DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数
        而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算
        计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理
    (3) 字符串类型
        包括VARCHAR、CHAR、TEXT、BLOB
        VARCHAR用于存储可变长字符串，CHAR是定长的
        对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片
        对于非常短的列，CHAR比VARCHAR在存储空间上更有效率
        使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存
        尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销
    (4) 枚举类型
        有时可以使用ENUM代替常用的字符串类型
        尽量避免使用数字作为ENUM枚举的常量，因为容易混乱
    (5) 日期和时间类型
        尽量使用timestamp，空间效率高于datetime
        用整数保存时间戳通常不方便处理
        如果需要存储微妙，可以使用bigint存储
```

### 引擎
```
1、MyISAM与InnoDB区别
    Innodb引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束
    MyIASM引擎不提供事务的支持，也不支持行级锁和外键

2、Innodb的特点
    (1) 插入缓冲(insert buffer)
        1) 不同索引的数据插入方式
            > 主键索引
                属于聚簇索引，在进行插入操作的时候，数据页的存放是按主键顺序存放的，此时磁盘顺序访问，速度会很快
                对于主索引的插入，是顺序插入，性能高
            > 非主键索引
                属于非聚簇索引，插入则不再是顺序的了，这时需要离散地访问非聚集索引页，磁盘的随机读取效率很低，导致了插入操作的性能下降
        2) insert buffer
            InnoDB 存储引擎创造性地设计了 Insert Buffer
            对于非聚簇索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚簇索引页是否在缓冲池中
            若在，则直接插入；若不在，则先放入到一个 Insert Buffer 对象中
            然后再以一定的频率和情况进行 Insert Buffer 和辅助索引叶子节点的 merge 操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中），这就大大提高了对于非聚簇索引插入的性能
        3) insert buffer使用条件
            自己确保插入数据索引的正确性
            因为数据库不会查找索引页来判断插入记录的唯一性。如果去查找就会发生离散读取，就违背了insert buffer的初衷

    (2) 二次写(double write)
    (3) 自适应哈希索引(ahi)
    (4) 预读(read ahead)
```

### 索引的概念
```
1、索引的创建与删除
    (1) 创建
        1) 在执行CREATE TABLE时创建索引
            CREATE TABLE user_index (
                id INT auto_increment PRIMARY KEY,  // 自增长
                first_name VARCHAR (16),
                last_name VARCHAR (16),
                id_card VARCHAR (18),
                information text,
                KEY name (first_name, last_name),
                FULLTEXT KEY (information),
                UNIQUE KEY (id_card)
            )

        2) 使用ALTER TABLE命令去增加索引
            ALTER TABLE table_name ADD INDEX index_name (column_list)
            ALTER TABLE用来创建普通索引、UNIQUE索引

        3) 使用CREATE INDEX命令创建索引
            CREATE INDEX index_name ON table_name (column_list)
            CREATE INDEX可对表增加普通索引或UNIQUE索引，但是不能创建PRIMARY KEY索引

    (2) 删除索引
        alter table user_index drop KEY name;
        alter table user_index drop KEY id_card;
        alter table user_index drop KEY information;

2、索引的类型
    > 查看索引详情
        SHOW INDEX FROM table_name
    
    > 主键索引 PRIMARY KEY
        唯一索引；不允许有空值；建表时同时创建；一个表只能有一个主键

    > 唯一索引 UNIQUE
        唯一索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一
        // 创建唯一索引
        ALTER TABLE table_name ADD UNIQUE (column)
        // 创建唯一组合索引
        ALTER TABLE table_name ADD UNIQUE (column1,column2)

    > 普通索引 INDEX
        最基本的索引，它没有任何限制
        // 创建普通索引
        ALTER TABLE table_name ADD INDEX index_name (column)
    
    > 组合索引 INDEX
        组合索引，即一个索引包含多个列。多用于避免回表查询
        // 创建组合索引
        ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3)

    > 全文索引 FULLTEXT
        全文索引是目前搜索引擎使用的一种关键技术
        // 创建全文索引
        ALTER TABLE table_name ADD FULLTEXT (column)

    索引一经创建不能修改，如果要修改索引，只能删除重建
    // 删除索引
    DROP INDEX index_name ON table_name

3、不同区别
    (1) MyISAM索引与InnoDB索引的区别
        InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引
        InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效
        MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据
        InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效

    (2) 聚簇索引和非聚簇索引
        聚簇索引：索引和数据存储在一块(都存储在同一个B*tree 中)。一般主键索引都是聚餐索引
        非聚簇索引：索引数据和存储数据是分离的。一般非主键索引都是非聚簇索引

    (3) 主键索引和非主键索引
        主键索引 -> 读取3个数据块 -> 获得数据
        非主键索引 -> 获得主键索引 -> 再查询其他数据

4、索引设计的原则
    > 适合索引的列是出现在where子句中的列，或者连接子句中指定的列
    > 基数较小的类，索引效果较差，没有必要在此列建立索引
    > 使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间
    > 不要过度索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，索引列越多，这个时间就会越长。所以只保持需要的索引有利于查询即可
    > 最左前缀原则，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边

5、常见问题
    (1) 百万级别或以上的数据如何删除
        由于索引需要额外的维护成本，对数据的增加,修改,删除,都会产生额外的对索引文件的操作
        这些操作需要消耗额外的IO，会降低增/改/删的执行效率
        // 方法
        先删除索引；然后删除其中无用数据；删除完成后重新创建索引(此时数据较少了)创建索引也非常快
        与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了
    
```

### 索引的结构
```
索引底层结构涉及 B树、B+树、hash索引

1、B树和B+树的区别和优缺点
    (1) 区别
        B树，可以将键和值存放在内部节点和叶子节点
        B+树，内部节点都是键，没有值，叶子节点同时存放键和值
        B+树的叶子节点有一条链相连，而B树的叶子节点各自独立

    (2)优缺点
        使用B树的好处
            内部节点同时存储键和值，这种特性使得B树在特定数据重复多次查询的场景中更加高效
        使用B+树的好处
            内部节点只存放键，不存放值，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围
            叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间

2、Hash索引和B+树的区别
    hash索引进行等值查询更快(一般情况下)，但是却无法进行范围查询
    hash索引不支持使用索引进行排序
    hash索引不支持模糊查询以及多列索引的最左前缀匹配
    hash索引任何时候都避免不了回表查询数据，而B+树在符合某些条件(聚簇索引，覆盖索引等)的时候可以只通过索引完成查询
    hash索引虽然在等值查询上较快，但是不稳定。可能发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低

3、数据库为什么使用B+树而不是B树
    B树只适合随机检索，而B+树同时支持随机检索和顺序检索
    B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低
    B+树的查询效率更加稳定
    增删文件(节点)时，效率更高。因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率
```


### 锁
```
1、锁的粒度
    MyISAM采用表级锁
    InnoDB支持行级锁和表级锁，默认为行级锁
    允许行锁和表锁共存，实现多粒度锁机制
    (1) 行级锁
        行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁
        开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高；行级锁分为共享锁和排他锁
    (2) 表级锁
        表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少
        开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低；也分为共享锁和排他锁
    (3) 页级锁
        页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录
        开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

        页级锁分为gap lock(间隙锁)与next-key lock
        间隙锁: 锁定一个范围，不包括记录本身
        next-key lock: 锁定一个范围，包含记录本身
        > innodb对于行的查询使用next-key lock
        > next-key lock为了解决Phantom Problem幻读问题
        > 当查询的索引含有唯一属性时，将next-key lock降级为行锁
        > Gap lock设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
        > 有两种方式显式关闭gap锁: 将事务隔离级别设置为RC; 将参数innodb_locks_unsafe_for_binlog设置为1

2、共享锁和排他锁
    共享锁(S): 读锁，允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁
    排他锁(X): 写锁，允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁
    意向共享锁(IS): 自动加的共享锁，不需要用户干预
    意向排他锁(IX): 自动加的排他锁，不需要用户干预
    排他锁的申请前提：没有线程对该结果集中的任何行数据使用排他锁或共享锁，否则申请会阻塞
    // 兼容性
    如果一个事务请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放
    兼容性  IS	IX	 S	  X
    IS	   兼容	兼容 兼容 互斥
    IX	   兼容	兼容 互斥 互斥
    S      兼容	互斥 兼容 互斥
    X	   互斥	互斥 互斥 互斥

3、加锁方式
    (1) 表级锁
        > MyISAM在执行SELECT前，会自动给涉及的所有表加读锁
        > 在执行UPDATE、DELETE、INSERT等前，会自动给涉及的表加写锁
        > 手动加表锁 lock table film_text write
        > 手动释放表锁 unlock tables
    (2) 行级锁
        > InnoDB行锁是通过给索引加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的
        > 只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁
        > 有时即便使用了索引字段，如果MySQL认为全表扫描效率更高，比如对一些很小的表，会使用开销小的表级锁
        > 索引字段类型(varchar)，如果where条件中不是和varchar类型进行比较(比如int)，则会对name进行类型转换，而执行的全表扫描
        > 对于 UPDATE、DELETE 和 INSERT 语句，InnoDB会自动给涉及数据集加排他锁X
        > 对于普通 SELECT 语句，InnoDB不会加任何锁
        > 手动加共享锁 SELECT ... FROM table_name WHERE ... LOCK IN SHARE MODE
        > 手动加排它锁 select ... for update
        > for update仅适用于InnoDB，且必须在事务(BEGIN/COMMIT)中才能生效
        > 在进行事务操作时，通过for update语句，MySQL会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞
    (3) 页级锁
        > 进行范围条件而不是相等条件检索数据，并请求共享或排他锁时，会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录（这样做可以防止幻读）
        > 这种加锁机制会阻塞符合条件范围内键值的并发插入，影响性能
        > 如果使用相等条件请求给一个不存在的记录加锁，InnoDB也会使用间隙锁

4、死锁
    死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象
    解决死锁的方法
    > 使用事务，不使用 lock tables
    > 避免长事务，降低一个事务的复杂度
    > 在事务中避免使用SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE
    如果业务处理不好可以用分布式事务锁或者使用乐观锁

5、一些操作
    (1) 查询表级锁争用情况
        show status like 'table%';
            +----------------------------+---------+
            | Variable_name              | Value   |
            +----------------------------+---------+
            | Table_locks_immediate      | 100     |    //产生表级锁定的次数
            | Table_locks_waited         | 11      |    //出现表级锁定争用而发生等待的次数
            +----------------------------+---------+

    (2) 查询InnoDB行锁争用情况
        show status like 'innodb_row_lock%';
            +-------------------------------+-------+
            | Variable_name                 | Value |
            +-------------------------------+-------+
            | InnoDB_row_lock_current_waits | 0     |
            | InnoDB_row_lock_time          | 0     |
            | InnoDB_row_lock_time_avg      | 0     |
            | InnoDB_row_lock_time_max      | 0     |
            | InnoDB_row_lock_waits         | 0     |
            +-------------------------------+-------+
        
    (3) 获得发生锁冲突的表、数据行
        Show innodb status         //会不断显示数据表的连接 状态
            *************************** 1. row ***************************
            ....
            ------------
            TRANSACTIONS
            ------------
            ...
        暂停查看
        DROP TABLE innodb_monitor

```


### 事务
```
1、事务四大特征(ACID)
    Atomicity(原子性)
	    一个事务中的所有操作，要么全部完成，要么全部不完成，不会在中间某个环节结束。
        事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。
    Consistency(一致性)
	    在事务开始之前和事务结束以后，数据库数据的一致性约束没有被破坏。
    Isolation(隔离性)
	    数据库允许多个并发事务同时对数据进行读写和修改的能力。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。
    Durability(持久性)
	    事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

2、并发导致的问题
    (1) 更新丢失(Lost Update)
        当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题(最后的更新覆盖了由其他事务所做的更新)
        例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。最后保存其更改副本的编辑人员覆盖另一个编辑人员所做的更改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题

    (2) 脏读(Dirty Reads)
        一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些"脏"数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做"脏读"
        
    (3) 不可重复读(Non-Repeatable Reads)
        一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了。这种现象就叫做"不可重复读"
        
    (4) 幻读(Phantom Reads)
        一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为幻读
        
        不可重复读是读取到了另一事务的更新，而幻读是读取到了另一事务的插入(MySQL中无法测试到幻读)
        
3、隔离级别
    事务隔离机制的实现基于"锁机制"和"并发调度"
    在读取数据前，对其加锁，阻止其他事务对数据进行修改
    并发调度使用的是MVVC(多版本并发控制)，通过保存修改的旧版本信息来支持并发一致性读和回滚等特性
    (1) 未提交读(Read Uncommitted)
        最低的隔离级别，可能读取到其他会话中未提交事务修改的数据。会导致脏读、幻读或不可重复读

    (2) 提交读(Read Committed)
        允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生
        Oracle等多数数据库默认都是该级别

    (3) 可重复读(Repeated Read)
        对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生
        InnoDB默认级别。但是还存在幻象读
    
    (4) 串行读(Serializable)
        最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读
        完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞
    
    事务隔离级别	             脏读	不可重复读	幻读
    读未提交（read-uncommitted） 是	    是	       是
    不可重复读（read-committed） 否	    是	       是
    可重复读（repeatable-read）	 否	    否	       是
    串行化（serializable）	     否	    否	       否

    读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力


4、事务回滚的实现
    (1) MySQL
        是SQL语句级的，在执行事务中的SQL语句前，需要先在日志缓冲写日志，记录该事务的日志序列号和执行的SQL语句。当事务提交时，必须将存储引擎的日志缓冲写入磁盘（通过innodb_flush_log_at_trx_commit来控制）。如果回滚，不是物理恢复，是逻辑恢复，因为它是通过执行相反的dml语句来实现的。而且不会回收因为insert和upate而新增加的page页的。即insert变成delete，update变成相反的update
    (2) Oracle
        是基于数据库文件块的

5、并发控制
    数据库管理系统(DBMS)中的并发控制确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性
    乐观并发控制(乐观锁)和悲观并发控制(悲观锁)是并发控制主要采用的技术手段
    (1) 悲观锁
        假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务
        传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁，释放锁之前任何人都不能对其数据进行操作，性能不高

        // 2PL(两阶段锁)
        数据库事务的加锁方式
        阶段一：Growing，事务向锁管理器请求它需要的所有锁(存在加锁失败的可能)
        阶段二：Shrinking，事务释放Growing阶段获取的锁，不允许再请求新锁
        存在死锁的可能，事务1持有A锁等B锁，事务2持有B锁等A锁
        // 注意
        在事务执行过程中，随时都可以执行锁定，锁只有在执行COMMIT或者ROLLBACK时才会释放，并且所有的锁是在同一时刻被释放。所以在一个事务中，推荐最后执行需要独占(获得读锁)的行，尽量减少行锁持有的时间

        注意区分 2PL 和 2PC

    (2) 乐观锁
        假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定
        乐观锁一般会使用版本号机制(mvcc多版本并发控制)或CAS算法实现(无锁编程)
        // 缺点(这里说的是CAS)
        > ABA问题
        > 循环时间长开销大，会给CPU带来非常大的执行开销
        > 只能保证一个共享变量的原子操作

6、MVCC
    多版本并发控制技术使得大部分支持行锁的事务引擎，不再单纯的使用行锁来进行数据库的并发控制,取而代之的是，把数据库的行锁与行的多个版本结合起来，只需要很小的开销，就可以实现一致性非锁定读，从而大大提高数据库系统的并发性能
    只有read-committed和repeatable-read两种事务隔离级别才能使用MVCC
    read-uncommited由于是读到未提交的，所以不存在版本的问题
    serializable则会对所有读取的行加锁

7、操作
    开启事务：Start Transaction
    事务结束：End Transaction
    提交事务：Commit Transaction
    回滚事务：Rollback Transaction

    // 示例
    BEGIN;      //开始一个事务
    xxxx
    如果出错：
        ROLLBACK    //事务回滚
    xxxx
    COMMIT      //事务确认

    // MYSQL的事务处理主要有两种方法
    (1) 用begin,rollback,commit来实现
        begin 开始一个事务
        rollback 事务回滚
        commit  事务确认
    (2) 直接用set来改变mysql的自动提交模式
        MYSQL默认是自动提交的，也就是你提交一个QUERY，它就直接执行！我们可以通过
        set autocommit=0   禁止自动提交
        set autocommit=1   开启自动提交
        来实现事务的处理

    // 但注意当你用 set autocommit=0 的时候，你以后所有的SQL都将做为事务处理，直到你用commit确认或rollback结束，注意当你结束这个事务的同时也开启了个新的事务！按第一种方法只将当前的作为一个事务！推荐使用第一种方法！

    // MYSQL中只有INNODB和BDB类型的数据表才能支持事务处理！其他的类型是不支持的！

    // 开启事务：start transaction；结束事务：commit或rollback。

    // 默认隔离级别为Repeatable read，可以通过 select @@tx_isolation 查看
    
    // 隔离级别操作
    查看当前会话隔离级别 select @@tx_isolation
    查看系统当前隔离级别 select @@global.tx_isolation
    设置当前会话隔离级别 set session transaction isolatin level repeatable read
    设置系统当前隔离级别 set global transaction isolation level repeatable read
```

### 视图
```
// 特点
    视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系
    视图的建立和删除不影响基本表
    对视图内容的更新(添加，删除和修改)直接影响基本表

// 优点
    查询简单化。视图能简化用户的操作
    数据安全性。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护
    逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性

// 缺点
    性能
        数据库必须把视图的查询转化成对基本表的查询
    修改限制
        当用户试图修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改
        事实上，当从视图中插入或者删除时，情况也是这样。对于简单视图来说，这是很方便的，但是，对于比较复杂的视图，可能是不可修改的

// 类别
    有UNIQUE等集合操作符的视图
    有GROUP BY子句的视图
    有诸如AVG\SUM\MAX等聚合函数的视图
    使用DISTINCT关键字的视图
    连接表的视图

```

### 存储过程与函数
```
存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需要创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快

// 优点
存储过程是预编译过的，执行效率高
存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯
安全性高，执行存储过程需要有一定权限的用户
存储过程可以重复使用，减少数据库开发人员的工作量

// 缺点
调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点
移植问题，数据库端代码当然是与数据库相关的。但是如果是做工程型项目，基本不存在移植问题
重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）
如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。
```

### 触发器
```
https://zhuanlan.zhihu.com/p/133291633



```

### 常用SQL语句
```
1、sql语句的分类
    数据定义语言DDL
        CREATE，DROP，ALTER
    数据查询语言DQL
        SELECT
    数据操纵语言DML
        INSERT，UPDATE，DELETE
    数据控制功能DCL
        GRANT，REVOKE，COMMIT，ROLLBACK

    DQL与DML共同构建了多数初级程序员常用的增删改查操作

2、键
    (1) 主键
        数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合
        一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值(Null)
    (2) 外键
        在一个表中存在的另一个表的主键称此表的外键
        外键并不是通过列名实现的，而是通过定义外键约束实现的
        保持数据一致性，完整性，主要目的是控制存储在外键表中的数据
        1) 定义外键
            ALTER TABLE students
                ADD CONSTRAINT fk_class_id  // 外键约束的名称fk_class_id可以任意
                FOREIGN KEY (class_id)      // 指定了class_id作为外键
                REFERENCES classes (id);    // 指定了这个外键将关联到classes表的id列(classes表的主键)
        2) 删除外键
            ALTER TABLE students DROP FOREIGN KEY fk_class_id;
        3) 降低性能
            外键约束会降低数据库的性能，可不设置外键约束，而是仅靠应用程序自身来保证逻辑的正确性

3、约束
    NOT NULL: 用于控制字段的内容一定不能为空(NULL)
    UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束
    PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个
    FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一
    CHECK: 用于控制字段的值范围

4、关联查询
    // R表有ABC三列，S表有CD两列
    交叉连接(CROSS JOIN)
        select r.*,s.* from r,s
    内连接(INNER JOIN)
        select r.*,s.* from r inner join s on r.c=s.c
    外连接(LEFT JOIN/RIGHT JOIN)
        select r.*,s.* from r left join s on r.c=s.c
        select r.*,s.* from r right join s on r.c=s.c

5、子查询
    一条SQL语句的查询结果做为另一条查询语句的条件或查询结果
    (1) 子查询是单行单列的情况，结果集是一个值，父查询使用：=、 <、 > 等运算符
        select  * from * where a=(select * from *)
    (2) 子查询是多行单列的情况，结果集类似于一个数组，父查询使用：in 运算符
        select  * from * where a in (select * from *)
    (3) 子查询是多行多列的情况，结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表
        
6、删除
    删除表  drop
    删除部分数据行  delete
    保留表而删除所有数据    truncate
```

### SQL优化
```
https://database.51cto.com/art/202008/624194.htm

1、原则
    减少数据访问: 设置合理的字段类型，启用压缩，通过索引访问等减少磁盘 IO
    返回更少的数据：只返回需要的字段和数据分页处理，减少磁盘 IO 及网络 IO
    减少交互次数: 批量 DML 操作，函数存储等减少数据连接次数
    减少服务器 CPU 开销: 尽量减少数据库排序操作以及全表查询，减少 CPU 内存占用
    利用更多资源：使用表分区，可以增加并行操作，更大限度利用 CPU 资源

2、sql优化
    最大化利用索引
    尽可能避免全表扫描
    减少无效数据的查询

3、
(1) 尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描
    // 例如
    SELECT * FROM t WHERE username LIKE '%陈%' 
    // 优化方式：尽量在字段后面使用模糊查询
    SELECT * FROM t WHERE username LIKE '陈%' 

(2) 尽量避免使用 in 和 not in，会导致引擎走全表扫描
    // 例如
    SELECT * FROM t WHERE id IN (2,3) 
    // 优化方式：如果是连续数值，可以用 between 代替
    SELECT * FROM t WHERE id BETWEEN 2 AND 3 
    // 如果是子查询，可以用 exists 代替
    select * from A where exists (select * from B where B.id = A.id)

(3) 尽量避免使用 or，会导致数据库引擎放弃索引进行全表扫描
    // 例如
    SELECT * FROM t WHERE id = 1 OR id = 3 
    // 优化方式：可以用 union 代替 or
    SELECT * FROM t WHERE id = 1  
        UNION  
    SELECT * FROM t WHERE id = 3 

(4) 尽量避免进行 null 值的判断，会导致数据库引擎放弃索引进行全表扫描
    SELECT * FROM t WHERE score IS NULL 
    优化方式：可以给字段添加默认值 0，对 0 值进行判断
    SELECT * FROM t WHERE score = 0 

(5) 尽量避免在 where 条件中等号的左侧进行表达式、函数操作，会导致数据库引擎放弃索引进行全表扫描
    SELECT * FROM T WHERE score/10 = 9  // 全表扫描
    // 可以将表达式、函数操作移动到等号右侧
    SELECT * FROM T WHERE score = 10*9  // 走索引

(6) 查询条件不能用 <> 或者 !=
    使用索引列作为条件进行查询时，需要避免使用<>或者!=等判断条件
    如确实业务需要，使用到不等于符号，需要在重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替

(7) 注意复合索引的使用
    例如索引是key index (a,b,c)，可以支持a、a,b、a,b,c3种组合进行查找，但不支持b,c进行索引查找
    select * from test where a=? and b=? and c=?  //查询效率最高，索引全覆盖
    select * from test where a=? and b=?          //索引覆盖a和b
    select * from test where b=? and c=?          //没有a列，不走索引，索引失效

(8) 隐式类型转换造成不使用索引

(9) order by 条件要与 where 中条件一致，否则 order by 不会利用索引进行排序
    // 不走age索引  
    SELECT * FROM t order by age;  
    // 走age索引  
    SELECT * FROM t where age > 0 order by age; 
    // 这个结论不仅对 order by 有效，对其他需要排序的操作也有效。比如 group by 、union 、distinct 等

(10) select的优化
    1) 避免出现 select *
        select * 操作在任何类型数据库中都不是一个好的编写习惯
        使用 select * 取出全部列，会让优化器无法完成索引覆盖扫描这类优化，会影响优化器对执行计划的选择，也会增加网络带宽消耗，更会带来额外的 I/O，内存和 CPU 消耗
        建议提出业务实际需要的列数，将指定列名以取代 select *

    2) 避免出现不确定结果的函数
        特定针对主从复制这类业务场景
        由于原理上从库复制的是主库执行的语句，使用如 now()、rand()、sysdate()、current_user() 等不确定结果的函数很容易导致主库与从库相应的数据不一致。
        另外不确定值的函数，产生的 SQL 语句无法利用 query cache

    3) 多表关联查询时，小表在前，大表在后
        在 MySQL 中，执行 from 后的表关联查询是从左往右执行的(Oracle 相反)，第一张表会涉及到全表扫描。
        所以将小表放在前面，先扫小表，扫描快效率较高，在扫描后面的大表，或许只扫描大表的前 100 行就符合返回条件并 return 了
        例如：表 1 有 50 条数据，表 2 有 30 亿条数据；如果全表扫描表 2，很耗时

    4) 用 where 字句替换 HAVING 字句

    5) 调整 Where 字句中的连接顺序
        MySQL 采用从左往右，自上而下的顺序解析 where 子句
        根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集

(11) 增删改 DML 语句优化
    1) 大批量插入数据
        同时执行大量的插入，建议使用多个值的INSERT语句，这比使用分开 INSERT 语句快，一般情况下批量插入效率有几倍的差别
        // 慢
        insert into T values(1,2);   
        insert into T values(1,3);  
        insert into T values(1,4); 
        // 快
        Insert into T values(1,2),(1,3),(1,4);  
        // 原因
        减少 SQL 语句解析的操作；可以减少网络传输的 IO
    2) 适当使用 commit
        适当使用 commit 可以释放事务占用的资源而减少消耗，commit 后能释放的资源如下
        > 事务占用的 undo 数据块
        > 事务在 redo log 中记录的数据块
        > 释放事务施加的，减少锁争用影响性能。特别是在需要使用 delete 删除大量数据的时候，必须分解删除量并定期 commit
    
(12) 对于复杂的查询，可以使用中间临时表暂存数据

(13) 优化 group by 语句
    默认情况下，MySQL 会对 GROUP BY 分组的所有值进行排序，GROUP BY col1,col2... 查询的方法如同在查询中指定"ORDER BY col1,col2 ..."
    如果显式包括一个包含相同的列的 ORDER BY 子句，MySQL 可以毫不减速地对它进行优化，尽管仍然进行排序
    因此，如果查询包括 GROUP BY 但你并不想对分组的值进行排序，你可以指定 ORDER BY NULL 禁止排序。
    SELECT col1, col2, COUNT(*) FROM table GROUP BY col1, col2 ORDER BY NULL ;

```

### 大数据库优化思路
```
> 优化shema、sql语句+索引
> 第二加缓存，memcached, redis
> 主从复制，读写分离
> 垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统
> 水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表
```

### mysql分页
```
https://cloud.tencent.com/developer/article/1449076

// 第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目
// 检索记录行 6-15 
SELECT * FROM table LIMIT 5,10

(1) 超大分页
    select * from user limit 1000000,10

    上述过程非常慢，'limit 1000000,10'的语法实际上是mysql查找到前1000010条数据，之后丢弃前面的1000000行，性能很低
    随着offset的增大,性能越来越差

    用索引id优化
    select * from user where id >= 1000000 order by id limit 100
    效率非常快，因为主键上是有索引的
    
    但是这样有个缺点，就是ID必须是连续的(被删除的条目有空洞)，并且查询不能有where语句，因为where语句会造成过滤数据

(2) 带where的超大分页
    select * from table where age > 20 limit 1000000,10
    上述没有利用索引

    select * from table where id in (select id from table where age > 20 and  limit 1000000,10)

// 总结
// 不带条件
select * from order where id >= 10000 order by id limit 50
// 带条件
select * from table where id >= (select id from table where 条件 order by id limit 10000,1) limit 50
// id不连续
select * from table where 条件 and id >= (select id from table where 条件 order by id limit 10000,1) limit 50
```

### 数据库优化
```
(1) 将字段很多的表分解成多个表
    对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表
    因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢

(2) 增加中间表
    对于需要经常联合查询的表，可以建立中间表以提高查询效率
    通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询

(3) 大表优化
    当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下
    1) 限定数据的范围
        禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内
    2) 读/写分离
        经典的数据库拆分方案，主库负责写，从库负责读；
    3) 缓存
        使用MySQL的缓存，另外对重量级、更新少的数据可以考虑使用应用级别的缓存
        详见数据库缓存，但是不建议用。大多都用外部缓存redis等
    4) 分库分表
```

### 分库分表
```
(1) 垂直拆分
    指数据表列的拆分，把一张列比较多的表拆分为多张表，跟业务挂钩
    > 优点
        可以使得行数据变小，在查询时减少读取的Block数，减少I/O次数
        垂直分区可以简化表的结构，易于维护
    > 缺点
        扩展性差，有些分表的策略基于应用层的逻辑算法，一旦逻辑算法改变，整个分表逻辑都会改变
        管理冗余列，查询所有数据需要join操作
        垂直分区会让事务变得更加复杂
(2) 水平拆分
    保持数据表结构不变，通过某种策略存储数据分片
    这样每一片数据分散到不同的表或者库中，达到了分布式的目的
    水平拆分可以支撑非常大的数据量
    > 优点
        性能
    > 缺点
        给应用增加复杂度，通常查询时需要多个表名，查询所有数据都需UNION操作
        在许多数据库应用中，这种复杂度会超过它带来的优点，查询时会增加读一个索引层的磁盘次数
    详见分布式章节
```
